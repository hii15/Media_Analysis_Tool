import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
from scipy.stats import beta
from sklearn.linear_model import LinearRegression

# --- ì„¤ì • ---
st.set_page_config(page_title="Ad Analytics System v2", layout="wide")
st.title("ğŸ¯ ê´‘ê³  ë§¤ì²´ í†µê³„ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("**Empirical Bayes & CUSUM ê¸°ë°˜ ì†Œì¬ ì„±ê³¼ ë¶„ì„**")
st.markdown("---")

# --- ë°ì´í„° ë¡œë“œ ---
def load_and_clean_data(uploaded_file):
    try:
        if uploaded_file.name.endswith('.xlsx'):
            all_sheets = pd.read_excel(uploaded_file, sheet_name=None)
            df = pd.concat(all_sheets.values(), ignore_index=True)
        else:
            df = pd.read_csv(uploaded_file, sep='\t' if uploaded_file.name.endswith('.tsv') else ',')
        
        df.columns = [c.strip() for c in df.columns]
        mapping = {
            'ë‚ ì§œ': ['ë‚ ì§œ', 'ì¼ì', 'date'], 
            'ë§¤ì²´': ['ë§¤ì²´', 'media'],
            'ìƒí’ˆ': ['ìƒí’ˆëª…', 'ìƒí’ˆ', 'product'], 
            'ì†Œì¬': ['ì†Œì¬ëª…', 'ì†Œì¬', 'material'],
            'ë…¸ì¶œ': ['ë…¸ì¶œìˆ˜', 'ë…¸ì¶œ', 'impressions'], 
            'í´ë¦­': ['í´ë¦­ìˆ˜', 'í´ë¦­', 'clicks'], 
            'ë¹„ìš©': ['ë¹„ìš©', 'ì§€ì¶œ', 'cost']
        }
        
        final_df = pd.DataFrame()
        for k, v in mapping.items():
            for col in v:
                if col in df.columns: 
                    final_df[k] = df[col]
                    break
        
        final_df['ë‚ ì§œ'] = pd.to_datetime(final_df['ë‚ ì§œ'], errors='coerce')
        for col in ['ë…¸ì¶œ', 'í´ë¦­', 'ë¹„ìš©']:
            final_df[col] = pd.to_numeric(
                final_df[col].astype(str).str.replace(r'[^\d.]', '', regex=True), 
                errors='coerce'
            ).fillna(0)
        
        final_df['CTR(%)'] = (final_df['í´ë¦­'] / (final_df['ë…¸ì¶œ'] + 1e-9) * 100)
        final_df['CPC'] = final_df['ë¹„ìš©'] / (final_df['í´ë¦­'] + 1e-9)
        final_df['ID'] = "[" + final_df['ìƒí’ˆ'].astype(str) + "] " + final_df['ì†Œì¬'].astype(str)
        
        return final_df.dropna(subset=['ë‚ ì§œ']).sort_values(['ID', 'ë‚ ì§œ'])
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

# --- Empirical Bayes ---
def analyze_empirical_bayes(df):
    global_ctr = df['í´ë¦­'].sum() / (df['ë…¸ì¶œ'].sum() + 1e-9)
    id_stats = df.groupby('ID').agg({'í´ë¦­': 'sum', 'ë…¸ì¶œ': 'sum', 'ë¹„ìš©': 'sum'})
    id_ctrs = id_stats['í´ë¦­'] / (id_stats['ë…¸ì¶œ'] + 1e-9)
    var_ctr = max(id_ctrs.var(), 1e-7)
    
    kappa = (global_ctr * (1 - global_ctr) / var_ctr) - 1
    kappa = np.clip(kappa, 10, 1000)
    
    alpha_0, beta_0 = global_ctr * kappa, (1 - global_ctr) * kappa
    
    agg = id_stats.reset_index()
    agg['post_alpha'] = alpha_0 + agg['í´ë¦­']
    agg['post_beta'] = beta_0 + (agg['ë…¸ì¶œ'] - agg['í´ë¦­'])
    agg['exp_ctr'] = agg['post_alpha'] / (agg['post_alpha'] + agg['post_beta'])
    agg['raw_ctr'] = agg['í´ë¦­'] / (agg['ë…¸ì¶œ'] + 1e-9)
    
    samples = np.random.beta(
        agg['post_alpha'].values[:, None], 
        agg['post_beta'].values[:, None], 
        size=(len(agg), 5000)
    )
    agg['prob_is_best'] = np.bincount(
        np.argmax(samples, axis=0), 
        minlength=len(agg)
    ) / 5000
    
    max_date = df['ë‚ ì§œ'].max()
    date_7d_ago = max_date - timedelta(days=6)
    last_7d = df[df['ë‚ ì§œ'] >= date_7d_ago]
    last_costs = last_7d.groupby('ID')['ë¹„ìš©'].sum() / 7
    agg = agg.merge(last_costs.rename('avg_cost_7d'), on='ID', how='left').fillna(0)
    
    return agg, (alpha_0, beta_0, kappa, global_ctr)

# --- CUSUM ---
def get_binomial_cusum(clicks, imps, p0):
    p1 = np.clip(p0 * 0.85, 1e-6, 1-1e-6)
    p0 = np.clip(p0, 1e-6, 1-1e-6)
    llr = clicks * np.log(p1/p0) + (imps - clicks) * np.log((1-p1)/(1-p0))
    s = 0
    cusum = []
    for val in llr:
        s = min(0, s + val)
        cusum.append(s)
    return np.array(cusum)

@st.cache_data
def estimate_h_via_arl(p0, imps_series, target_arl=30, sims=500):
    p1 = np.clip(p0 * 0.85, 1e-6, 1-1e-6)
    p0_clip = np.clip(p0, 1e-6, 1-1e-6)
    llr_success = np.log(p1 / p0_clip)
    llr_failure = np.log((1 - p1) / (1 - p0_clip))
    
    h_candidates = np.arange(1.0, 30.0, 0.5)
    
    for h in h_candidates:
        run_lengths = []
        for _ in range(sims):
            s, t = 0, 0
            while t < 500:
                t += 1
                n = np.random.choice(imps_series) if len(imps_series) > 0 else 100000
                c = np.random.binomial(int(n), p0_clip)
                s = min(0, s + (c * llr_success + (int(n) - c) * llr_failure))
                if s < -h:
                    break
            run_lengths.append(t)
        
        actual_arl = np.mean(run_lengths)
        if actual_arl >= target_arl:
            return h, actual_arl
    
    return h_candidates[-1], np.mean(run_lengths)

# --- UI ---
uploaded_file = st.file_uploader("ğŸ“‚ ìº í˜ì¸ ë°ì´í„° ì—…ë¡œë“œ (CSV/XLSX/TSV)", type=['csv', 'xlsx', 'tsv'])

if uploaded_file:
    df = load_and_clean_data(uploaded_file)
    
    if not df.empty:
        res_agg, (a0, b0, k_est, global_ctr) = analyze_empirical_bayes(df)
        ids = sorted(df['ID'].unique())
        
        # ëª¨ë“œ ì„ íƒ
        st.markdown("---")
        analysis_mode = st.radio(
            "ğŸ“Š ë¶„ì„ ëª¨ë“œ ì„ íƒ",
            ["ğŸ¯ ì‹¤ë¬´ ëª¨ë“œ (ê¶Œì¥)", "ğŸ”¬ ì „ë¬¸ê°€ ëª¨ë“œ"],
            horizontal=True,
            help="ì‹¤ë¬´ ëª¨ë“œ: ì¼ìƒ ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ í•µì‹¬ ê¸°ëŠ¥ë§Œ | ì „ë¬¸ê°€ ëª¨ë“œ: í†µê³„ ë¶„ì„ ë° ì§„ë‹¨ ë„êµ¬ í¬í•¨"
        )
        
        # íƒ­ êµ¬ì„±
        if analysis_mode == "ğŸ¯ ì‹¤ë¬´ ëª¨ë“œ (ê¶Œì¥)":
            tabs = st.tabs(["ğŸ“Š ì„±ê³¼ ìš”ì•½", "ğŸ¯ ì˜¤ëŠ˜ì˜ ì•¡ì…˜", "â° ì†Œì¬ ìˆ˜ëª… ì˜ˆì¸¡", "ğŸ“„ ì£¼ê°„ ë¦¬í¬íŠ¸"])
        else:
            tabs = st.tabs(["ğŸ“Š Executive Summary", "ğŸ¯ ì˜¤ëŠ˜ì˜ ì•¡ì…˜", "â° ì†Œì¬ ìˆ˜ëª… ì˜ˆì¸¡", "ğŸ§¬ Bayesian Analysis", "ğŸ“‰ CUSUM", "ğŸ® ì˜ˆì‚° ì‹œë®¬ë ˆì´í„°", "ğŸ“„ ì£¼ê°„ ë¦¬í¬íŠ¸"])
        
        # ====================
        # TAB 0: ì„±ê³¼ ìš”ì•½
        # ====================
        with tabs[0]:
            st.markdown("### ğŸ“Š í•µì‹¬ ì§€í‘œ ìš”ì•½")
            
            if analysis_mode == "ğŸ¯ ì‹¤ë¬´ ëª¨ë“œ (ê¶Œì¥)":
                st.info("ğŸ’¡ **ì‹¤ë¬´ ëª¨ë“œ**: ì¼ìƒ ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ í•µì‹¬ ì •ë³´ë§Œ í‘œì‹œí•©ë‹ˆë‹¤. í†µê³„ ë¶„ì„ì´ í•„ìš”í•˜ë©´ 'ì „ë¬¸ê°€ ëª¨ë“œ'ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("ì „ì²´ í‰ê·  CTR", f"{global_ctr*100:.2f}%")
            col2.metric("ë¶„ì„ ê¸°ê°„", f"{(df['ë‚ ì§œ'].max() - df['ë‚ ì§œ'].min()).days}ì¼")
            col3.metric("ì´ ì†Œì¬ ìˆ˜", len(ids))
            col4.metric("ì´ ì§‘í–‰ ë¹„ìš©", f"{df['ë¹„ìš©'].sum():,.0f}ì›")
            
            with st.expander("â„¹ï¸ CTR(Click-Through Rate)ì´ë€?"):
                st.markdown("""
                **CTR = (í´ë¦­ìˆ˜ / ë…¸ì¶œìˆ˜) Ã— 100%**
                
                ê´‘ê³ ê°€ 1000ë²ˆ ë…¸ì¶œë˜ì–´ 10ë²ˆ í´ë¦­ë˜ì—ˆë‹¤ë©´ CTR = 1.0%
                - ë†’ì„ìˆ˜ë¡: ê´‘ê³ ê°€ ì‚¬ìš©ìì—ê²Œ ë§¤ë ¥ì 
                - ë‚®ì„ìˆ˜ë¡: ì†Œì¬ ê°œì„  í•„ìš” ë˜ëŠ” íƒ€ê²ŸíŒ… ë¬¸ì œ
                - ì—…ê³„ í‰ê· : ë””ìŠ¤í”Œë ˆì´ 0.5~1%, ê²€ìƒ‰ê´‘ê³  2~5%
                """)
            
            st.markdown("---")
            st.markdown("### ğŸ† ìµœê³  ì„±ê³¼ ì†Œì¬ í™•ë¥ ")
            st.markdown("*Bayesian ì‚¬í›„í™•ë¥  ê¸°ë°˜ - 5000íšŒ Monte Carlo ì‹œë®¬ë ˆì´ì…˜*")
            
            with st.expander("â„¹ï¸ ì´ í™•ë¥ ì€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜ìš”?"):
                st.markdown("""
                **"ê° ì†Œì¬ê°€ ì‹¤ì œë¡œ ìµœê³  CTRì„ ê°€ì§ˆ í™•ë¥ "**
                
                ì˜ˆì‹œ:
                - ì†Œì¬ A: 65% â†’ 100ë²ˆ ì¤‘ 65ë²ˆì€ Aê°€ ìµœê³ 
                - ì†Œì¬ B: 25% â†’ 100ë²ˆ ì¤‘ 25ë²ˆì€ Bê°€ ìµœê³ 
                - ì†Œì¬ C: 10% â†’ 100ë²ˆ ì¤‘ 10ë²ˆì€ Cê°€ ìµœê³ 
                
                âš ï¸ **ì£¼ì˜ì‚¬í•­:**
                - ì´ëŠ” **í˜„ì¬ ë°ì´í„° ê¸°ì¤€** í™•ë¥ ì…ë‹ˆë‹¤
                - í–¥í›„ ì„±ê³¼ë¥¼ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
                - í™•ë¥ ì´ ë¹„ìŠ·í•˜ë©´ â†’ ë” ë§ì€ ë°ì´í„° í•„ìš”
                - ê³¼ë„í•œ ì§‘ì¤‘ íˆ¬ìëŠ” ìœ„í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
                """)
            
            fig_prob = px.bar(
                res_agg.sort_values('prob_is_best', ascending=True),
                x='prob_is_best', y='ID', orientation='h',
                text=res_agg.sort_values('prob_is_best', ascending=True)['prob_is_best'].apply(lambda x: f"{x*100:.1f}%"),
                title="ê° ì†Œì¬ê°€ ìµœê³  CTRì¼ í™•ë¥ "
            )
            fig_prob.update_traces(textposition='outside')
            fig_prob.update_xaxes(title="í™•ë¥ ", tickformat='.0%')
            st.plotly_chart(fig_prob, use_container_width=True)
            
            st.info("""
            **ğŸ“– í•´ì„:**
            - ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ì†Œì¬ê°€ ì‹¤ì œë¡œ ìµœê³  ì„±ê³¼ì¼ ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ìŠµë‹ˆë‹¤
            - í™•ë¥ ì´ ë¹„ìŠ·í•˜ë©´ â†’ ì†Œì¬ ê°„ ì°¨ì´ê°€ ë¯¸ë¯¸í•˜ê±°ë‚˜ ë” ë§ì€ ë°ì´í„° í•„ìš”
            - í™•ë¥ ì´ ëª…í™•í•˜ê²Œ ì°¨ì´ë‚˜ë©´ â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì„±ê³¼ ì°¨ì´ ì¡´ì¬
            """)
            
            st.markdown("---")
            st.markdown("### ğŸ“ˆ ì†Œì¬ë³„ ìƒì„¸ ì„±ê³¼")
            
            display_df = res_agg[['ID', 'raw_ctr', 'exp_ctr', 'ë…¸ì¶œ', 'í´ë¦­', 'ë¹„ìš©', 'prob_is_best']].copy()
            display_df['raw_ctr'] = display_df['raw_ctr'] * 100
            display_df['exp_ctr'] = display_df['exp_ctr'] * 100
            display_df['prob_is_best'] = display_df['prob_is_best'] * 100
            display_df.columns = ['ì†Œì¬', 'ì›ë³¸CTR(%)', 'ë³´ì •CTR(%)', 'ë…¸ì¶œìˆ˜', 'í´ë¦­ìˆ˜', 'ë¹„ìš©', 'ìµœê³ í™•ë¥ ']
            
            st.dataframe(
                display_df.style.format({
                    'ì›ë³¸CTR(%)': '{:.2f}',
                    'ë³´ì •CTR(%)': '{:.2f}',
                    'ë…¸ì¶œìˆ˜': '{:,.0f}',
                    'í´ë¦­ìˆ˜': '{:,.0f}',
                    'ë¹„ìš©': '{:,.0f}ì›',
                    'ìµœê³ í™•ë¥ ': '{:.1f}%'
                }).background_gradient(subset=['ë³´ì •CTR(%)'], cmap='RdYlGn'),
                use_container_width=True
            )
            
            with st.expander("â„¹ï¸ ì›ë³¸CTR vs ë³´ì •CTR ì°¨ì´"):
                st.markdown("""
                **ì›ë³¸CTR:** ê° ì†Œì¬ì˜ ì‹¤ì œ í´ë¦­ë¥  (í´ë¦­/ë…¸ì¶œ)
                **ë³´ì •CTR:** Empirical Bayesë¡œ ê·¹ë‹¨ê°’ì„ ì™„í™”í•œ CTR
                
                ì˜ˆì‹œ:
                - ì†Œì¬ A: ë…¸ì¶œ 100ë§Œ, í´ë¦­ 5000 â†’ ì›ë³¸ 0.5%
                - ì†Œì¬ B: ë…¸ì¶œ 100, í´ë¦­ 10 â†’ ì›ë³¸ 10% (!)
                
                ì†Œì¬ BëŠ” ë°ì´í„°ê°€ ì ì–´ì„œ ìš°ì—°íˆ ë†’ì„ ê°€ëŠ¥ì„± í¼
                â†’ ë³´ì •CTRì€ ì „ì²´ í‰ê·  ìª½ìœ¼ë¡œ ì¡°ì • (ì˜ˆ: 2.1%)
                
                **ì–¸ì œ ì°¨ì´ê°€ í¬ë‚˜?**
                - ë…¸ì¶œìˆ˜ê°€ ì ì„ìˆ˜ë¡
                - ì „ì²´ í‰ê· ê³¼ ì°¨ì´ê°€ í´ìˆ˜ë¡
                """)
        
        # ====================
        # TAB 1: ì˜¤ëŠ˜ì˜ ì•¡ì…˜
        # ====================
        with tabs[1]:
            st.markdown("### ğŸ¯ ì˜¤ëŠ˜ì˜ ì•¡ì…˜ ë¦¬ìŠ¤íŠ¸")
            st.markdown(f"**ë¶„ì„ ê¸°ì¤€ì¼: {df['ë‚ ì§œ'].max().strftime('%Yë…„ %mì›” %dì¼')}**")
            
            with st.expander("â„¹ï¸ ì´ íƒ­ì€ ë¬´ì—‡ì„ í•˜ë‚˜ìš”?"):
                st.markdown("""
                **ë§¤ì¼ ì•„ì¹¨ í™•ì¸í•  ì˜ì‚¬ê²°ì • ì²´í¬ë¦¬ìŠ¤íŠ¸**
                
                ê° ì†Œì¬ë¥¼:
                - ğŸ”´ ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”
                - ğŸŸ¡ ì£¼ì˜ ê´€ì°°
                - ğŸŸ¢ ì¦ì•¡ ê²€í† 
                - âšª í˜„ìƒ ìœ ì§€
                
                4ê°€ì§€ë¡œ ë¶„ë¥˜í•˜ì—¬ ìš°ì„ ìˆœìœ„ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
                
                **íŒë‹¨ ê¸°ì¤€:**
                1. CUSUM ì´ìƒ ê°ì§€ (í†µê³„ì  í•˜ë½)
                2. ìµœê·¼ 3ì¼ ì¶”ì„¸ (ìƒìŠ¹/í•˜ë½)
                3. Bayesian ìµœê³  í™•ë¥  (ì„±ê³¼ ì‹ ë¢°ë„)
                """)
            
            st.markdown("---")
            
            actions = []
            for _, material in res_agg.iterrows():
                mat_id = material['ID']
                mat_data = df[df['ID'] == mat_id].sort_values('ë‚ ì§œ')
                
                if len(mat_data) >= 3:
                    recent_3 = mat_data.tail(3)['CTR(%)']
                    trend_change = (recent_3.iloc[-1] - recent_3.iloc[0]) / recent_3.iloc[0] if recent_3.iloc[0] > 0 else 0
                else:
                    trend_change = 0
                
                recent_ctr = mat_data.tail(3)['CTR(%)'].mean()
                baseline_ctr = material['exp_ctr'] * 100
                cusum_alert = recent_ctr < baseline_ctr * 0.85
                
                if cusum_alert and trend_change < -0.1:
                    status, priority = "ğŸ”´ ì¦‰ì‹œ ì¤‘ë‹¨ ê¶Œì¥", 1
                    reason = f"ê¸°ì¤€ì„  ëŒ€ë¹„ 15% ì´ìƒ í•˜ë½, 3ì¼ ì¶”ì„¸ {trend_change*100:.1f}%"
                    action = "ì˜ˆì‚° ì¬ë°°ë¶„ ë˜ëŠ” ì†Œì¬ êµì²´"
                elif trend_change < -0.05:
                    status, priority = "ğŸŸ¡ ëª¨ë‹ˆí„°ë§ ê°•í™”", 2
                    reason = f"3ì¼ ì¶”ì„¸ {trend_change*100:.1f}% í•˜ë½"
                    action = "1~2ì¼ ì¶”ê°€ ê´€ì°° í›„ ì¡°ì¹˜"
                elif material['prob_is_best'] > 0.4 and trend_change > 0.05:
                    status, priority = "ğŸŸ¢ ì˜ˆì‚° ì¦ì•¡ ê²€í† ", 3
                    reason = f"ìµœê³  í™•ë¥  {material['prob_is_best']*100:.0f}%, 3ì¼ ì¶”ì„¸ +{trend_change*100:.1f}%"
                    action = "ì ì§„ì  ì¦ì•¡ í…ŒìŠ¤íŠ¸ (+20~30%)"
                else:
                    status, priority = "âšª í˜„ìƒ ìœ ì§€", 4
                    reason, action = "ì•ˆì •ì  ì„±ê³¼ ìœ ì§€ ì¤‘", "ì •ê¸° ëª¨ë‹ˆí„°ë§"
                
                actions.append({
                    'ID': mat_id, 'status': status, 'priority': priority,
                    'reason': reason, 'action': action, 'current_cost': material['avg_cost_7d']
                })
            
            for _, action in pd.DataFrame(actions).sort_values('priority').iterrows():
                st.markdown(f"### {action['status']}")
                st.markdown(f"**ì†Œì¬:** {action['ID']}")
                st.markdown(f"**í˜„ì¬ ì¼í‰ê·  ë¹„ìš©:** {action['current_cost']:,.0f}ì›")
                st.markdown(f"**íŒë‹¨ ê·¼ê±°:** {action['reason']}")
                st.markdown(f"**ê¶Œì¥ ì¡°ì¹˜:** {action['action']}")
                st.markdown("---")
        
        # ====================
        # TAB 2: ì†Œì¬ ìˆ˜ëª… ì˜ˆì¸¡
        # ====================
        with tabs[2]:
            st.markdown("### â° ì†Œì¬ ìˆ˜ëª… ì˜ˆì¸¡")
            
            with st.expander("â„¹ï¸ ì†Œì¬ ìˆ˜ëª…ì´ë€?"):
                st.markdown("""
                **ì†Œì¬ í”¼ë¡œë„ (Creative Fatigue)**
                
                ê°™ì€ ê´‘ê³ ë¥¼ ë°˜ë³µ ë…¸ì¶œí•˜ë©´:
                - ì‚¬ìš©ìê°€ ë¬´ì‹œí•˜ê¸° ì‹œì‘
                - CTR ì ì§„ì  í•˜ë½
                - ë¹„ìš© íš¨ìœ¨ ì•…í™”
                
                **ìˆ˜ëª… ì˜ˆì¸¡ ë°©ë²•:**
                - ìµœê·¼ ì¶”ì„¸ë¥¼ ì„ í˜• íšŒê·€ë¡œ ë¶„ì„
                - í˜„ì¬ CTRì˜ 50%ê¹Œì§€ ë–¨ì–´ì§€ëŠ” ì‹œì  ì¶”ì •
                - "D-day" í˜•íƒœë¡œ êµì²´ ê¶Œì¥ì¼ ì œì‹œ
                
                âš ï¸ **ì£¼ì˜:**
                - ë‹¨ìˆœ ì„ í˜• ê°€ì • (ì‹¤ì œëŠ” ë¹„ì„ í˜•ì¼ ìˆ˜ ìˆìŒ)
                - ì™¸ë¶€ ìš”ì¸(ì‹œì¦Œ, ê²½ìŸì‚¬) ë¯¸ë°˜ì˜
                - ì°¸ê³ ìš©ìœ¼ë¡œë§Œ í™œìš©
                """)
            
            st.markdown("---")
            
            for mat_id in ids:
                mat_data = df[df['ID'] == mat_id].sort_values('ë‚ ì§œ')
                
                if len(mat_data) < 5:
                    st.warning(f"{mat_id}: ë°ì´í„° ë¶€ì¡± (5ì¼ ì´ìƒ í•„ìš”)")
                    continue
                
                X = np.arange(len(mat_data)).reshape(-1, 1)
                y = mat_data['CTR(%)'].values
                model = LinearRegression().fit(X, y)
                slope = model.coef_[0]
                current_ctr = y[-1]
                threshold_ctr = current_ctr * 0.5
                
                if slope < -0.001:
                    days_left = max(0, int((current_ctr - threshold_ctr) / abs(slope)))
                    
                    if days_left == 0:
                        lifespan_status = "âš ï¸ êµì²´ ê¶Œì¥ (í•œê³„ ë„ë‹¬)"
                    elif days_left <= 3:
                        lifespan_status = f"ğŸ”´ D-{days_left} (ê¸´ê¸‰)"
                    elif days_left <= 7:
                        lifespan_status = f"ğŸŸ¡ D-{days_left} (ì£¼ì˜)"
                    else:
                        lifespan_status = f"ğŸŸ¢ D-{days_left} (ì•ˆì •)"
                else:
                    lifespan_status = "âœ… ì•ˆì •ì  (í•˜ë½ ì¶”ì„¸ ì—†ìŒ)"
                    days_left = None
                
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.markdown(f"### {mat_id}")
                    st.markdown(f"**ìˆ˜ëª… ìƒíƒœ:** {lifespan_status}")
                    st.markdown(f"**í˜„ì¬ CTR:** {current_ctr:.2f}%")
                    st.markdown(f"**ì¼í‰ê·  í•˜ë½ë¥ :** {slope:.4f}%p")
                    if days_left is not None and days_left > 0:
                        rec_date = df['ë‚ ì§œ'].max() + timedelta(days=days_left)
                        st.markdown(f"**êµì²´ ê¶Œì¥ì¼:** {rec_date.strftime('%Y-%m-%d')}")
                
                with col2:
                    fig_mini = go.Figure()
                    fig_mini.add_trace(go.Scatter(y=y, mode='lines+markers', name='ì‹¤ì œ CTR'))
                    trend_line = model.predict(X)
                    fig_mini.add_trace(go.Scatter(y=trend_line, mode='lines', name='ì¶”ì„¸', line=dict(dash='dash')))
                    fig_mini.update_layout(height=200, showlegend=False, margin=dict(l=0, r=0, t=0, b=0))
                    st.plotly_chart(fig_mini, use_container_width=True)
                
                st.markdown("---")
        
        # ====================
        # TAB 3: Bayesian (ì „ë¬¸ê°€ ëª¨ë“œ)
        # ====================
        if analysis_mode == "ğŸ”¬ ì „ë¬¸ê°€ ëª¨ë“œ":
            with tabs[3]:
                st.markdown("### ğŸ§¬ Empirical Bayes ë°©ë²•ë¡ ")
                
                with st.expander("â„¹ï¸ Empirical Bayesë€? (ì´ˆë³´ììš© ì„¤ëª…)"):
                    st.markdown("""
                    **ë¬¸ì œ ìƒí™©:**
                    - ì†Œì¬ A: ë…¸ì¶œ 100ë§Œ, í´ë¦­ 5000 â†’ CTR 0.50%
                    - ì†Œì¬ B: ë…¸ì¶œ 100, í´ë¦­ 5 â†’ CTR 5.00% (10ë°°!)
                    
                    ì†Œì¬ Bê°€ ì •ë§ 10ë°° ì¢‹ì„ê¹Œìš”? **ì•„ë‹™ë‹ˆë‹¤.** ë°ì´í„°ê°€ ì ì–´ì„œ ìš°ì—°ì¼ ê°€ëŠ¥ì„± ë†’ìŠµë‹ˆë‹¤.
                    
                    **Empirical Bayes í•´ê²°ì±…:**
                    1. ì „ì²´ í‰ê·  CTRì„ "ì‚¬ì „ ë¯¿ìŒ"ìœ¼ë¡œ ì„¤ì •
                    2. ê° ì†Œì¬ì˜ ì‹¤ì œ ë°ì´í„°ì™€ ê²°í•©
                    3. ê·¹ë‹¨ì ì¸ ê°’ì„ ì „ì²´ í‰ê·  ìª½ìœ¼ë¡œ "ë‹¹ê¹€"
                    
                    **ê²°ê³¼:**
                    - ë°ì´í„° ë§ì€ ì†Œì¬ â†’ ê±°ì˜ ê·¸ëŒ€ë¡œ
                    - ë°ì´í„° ì ì€ ì†Œì¬ â†’ ì „ì²´ í‰ê· ì— ê°€ê¹ê²Œ ë³´ì •
                    
                    ì´ë ‡ê²Œ í•˜ë©´ "ìš´ ì¢‹ê²Œ ë†’ì€" ì†Œì¬ì— ì†ì§€ ì•ŠìŠµë‹ˆë‹¤!
                    """)
                
                st.markdown(f"""
                **í•µì‹¬ ê°œë…:**
                - ì†Œí‘œë³¸ì—ì„œ CTRì€ ë³€ë™ì„±ì´ í½ë‹ˆë‹¤
                - ì „ì²´ í‰ê· ì„ ì‚¬ì „ ì •ë³´ë¡œ í™œìš©í•´ ê·¹ë‹¨ê°’ì„ ë³´ì •í•©ë‹ˆë‹¤
                - "ì „ì²´ì ìœ¼ë¡œ CTRì´ {global_ctr*100:.2f}%ì¸ë°, ì´ ì†Œì¬ë§Œ {global_ctr*100*3:.1f}%ëŠ” ì˜ì‹¬ìŠ¤ëŸ½ë‹¤"
                """)
                
                col1, col2, col3 = st.columns(3)
                col1.metric("Prior Î±â‚€", f"{a0:.1f}")
                col2.metric("Prior Î²â‚€", f"{b0:.1f}")
                col3.metric("ì‹ ë¢°ë„ Îº (Kappa)", f"{k_est:.1f}")
                
                with st.expander("â„¹ï¸ Îº(Kappa) ê°’ì´ë€?"):
                    st.markdown(f"""
                    **Îº(Kappa) = ì‚¬ì „ ì •ë³´ì˜ ê°•ë„**
                    
                    Îºê°€ í¬ë©´ â†’ ì „ì²´ í‰ê· ì„ ë” ì‹ ë¢° (ë³´ìˆ˜ì  í‰ê°€)
                    Îºê°€ ì‘ìœ¼ë©´ â†’ ê°œë³„ ì†Œì¬ ë°ì´í„°ë¥¼ ë” ì‹ ë¢°
                    
                    **í˜„ì¬ ê°’: {k_est:.1f}**
                    - Îº = 10 ì •ë„: ê°œë³„ ë°ì´í„° ì¤‘ì‹œ
                    - Îº = 100 ì •ë„: ê· í˜•
                    - Îº = 1000 ì •ë„: ì „ì²´ í‰ê·  ì¤‘ì‹œ
                    
                    ì ì • ë²”ìœ„: 10~1000 (í˜„ì¬ {'âœ… ì ì ˆ' if 10 < k_est < 1000 else 'âš ï¸ ì¡°ì • í•„ìš”'})
                    
                    âš ï¸ **ê¸°ìˆ ì  í•œê³„:**
                    í˜„ì¬ ÎºëŠ” ê´€ì¸¡ CTR ë¶„ì‚° ê¸°ë°˜ (Method of Moments)
                    ë…¸ì¶œìˆ˜ ì°¨ì´ê°€ í° ê²½ìš° ê³¼ì†Œ ì¶”ì • ê°€ëŠ¥
                    """)
                
                st.markdown("---")
                st.markdown("### ğŸ“Š ì‚¬í›„í™•ë¥  ë¶„í¬ (Posterior Distribution)")
                
                with st.expander("â„¹ï¸ ì‚¬í›„í™•ë¥  ë¶„í¬ë€?"):
                    st.markdown("""
                    **ì´ ê·¸ë˜í”„ëŠ” "ê° ì†Œì¬ì˜ ì§„ì§œ CTR ë²”ìœ„"ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤**
                    
                    **ë¶„í¬ê°€ ì¢ìœ¼ë©´:**
                    - ë°ì´í„°ê°€ ë§ê±°ë‚˜ ì¼ê´€ì„±ì´ ë†’ìŒ
                    - "ì´ ì†Œì¬ì˜ ì§„ì§œ ì„±ê³¼ë¥¼ í™•ì‹ í•¨"
                    
                    **ë¶„í¬ê°€ ë„“ìœ¼ë©´:**
                    - ë°ì´í„°ê°€ ì ê±°ë‚˜ ë³€ë™ì„±ì´ í¼
                    - "ë” ë§ì€ í…ŒìŠ¤íŠ¸ í•„ìš”"
                    
                    **ë¶„í¬ê°€ ê²¹ì¹˜ë©´:**
                    - ì†Œì¬ ê°„ ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ëª…í™•í•˜ì§€ ì•ŠìŒ
                    
                    **ğŸ’¡ Tip:** ê·¸ë˜í”„ ìœ„ì— ë§ˆìš°ìŠ¤ë¥¼ ì˜¬ë¦¬ë©´ ê° ê³¡ì„ ì˜ ì†Œì¬ëª…ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
                    """)
                
                fig_post = go.Figure()
                colors = px.colors.qualitative.Set2
                for idx, (_, row) in enumerate(res_agg.iterrows()):
                    x = np.linspace(0, 0.03, 500)
                    y = beta.pdf(x, row['post_alpha'], row['post_beta'])
                    fig_post.add_trace(go.Scatter(
                        x=x*100, y=y, name=row['ID'],
                        mode='lines', fill='tozeroy', opacity=0.6,
                        line=dict(color=colors[idx % len(colors)], width=3),
                        hovertemplate='<b>%{fullData.name}</b><br>CTR: %{x:.2f}%<extra></extra>'
                    ))
                
                fig_post.update_layout(
                    title="ê° ì†Œì¬ì˜ ì‹¤ì œ CTR ë¶„í¬ ì¶”ì •",
                    xaxis_title="CTR (%)",
                    yaxis_title="í™•ë¥  ë°€ë„",
                    hovermode='closest',
                    legend=dict(orientation="v", yanchor="top", y=1, xanchor="left", x=1.02)
                )
                st.plotly_chart(fig_post, use_container_width=True)
        
        # ====================
        # TAB 4: CUSUM (ì „ë¬¸ê°€ ëª¨ë“œ)
        # ====================
        if analysis_mode == "ğŸ”¬ ì „ë¬¸ê°€ ëª¨ë“œ":
            with tabs[4]:
                st.markdown("### ğŸ“‰ CUSUM ê¸°ë°˜ ì´ìƒ ê°ì§€")
                st.markdown("**Cumulative Sum Control Chart - ì„±ê³¼ í•˜ë½ ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ**")
                
                with st.expander("â„¹ï¸ CUSUMì´ë€? (ì´ˆë³´ììš© ì„¤ëª…)"):
                    st.markdown("""
                    **CUSUM = Cumulative SUM (ëˆ„ì  í•©ê³„)**
                    
                    **ë¬¸ì œ ìƒí™©:**
                    - ì–´ì œ CTR: 0.45%, ì˜¤ëŠ˜ CTR: 0.43%
                    - ì´ê²Œ ì •ìƒ ë³€ë™ì¼ê¹Œ, ë¬¸ì œ ì‹ í˜¸ì¼ê¹Œ?
                    
                    **CUSUMì˜ í•´ê²°ì±…:**
                    - ê¸°ì¤€ì„  ëŒ€ë¹„ "ëˆ„ì  í¸ì°¨"ë¥¼ ê³„ì‚°
                    - ì‘ì€ ë³€í™”ë„ ëˆ„ì ë˜ë©´ í° ì‹ í˜¸ê°€ ë¨
                    - ì„ê³„ê°’ ëŒíŒŒ â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ë³€í™”!
                    
                    **ì¥ì :**
                    - ì‘ì€ í•˜ë½ë„ ë¹ ë¥´ê²Œ ê°ì§€
                    - ì¼ì‹œì  ë…¸ì´ì¦ˆëŠ” ë¬´ì‹œ
                    - ëª…í™•í•œ ê²½ë³´ ê¸°ì¤€
                    """)
                
                t_id = st.selectbox("ë¶„ì„í•  ì†Œì¬ ì„ íƒ", ids)
                sub = df[df['ID'] == t_id].sort_values('ë‚ ì§œ')
                
                if len(sub) >= 7:
                    p0_val = sub.head(7)['í´ë¦­'].sum() / (sub.head(7)['ë…¸ì¶œ'].sum() + 1e-9)
                    st.info(f"**ê¸°ì¤€ì„  ì„¤ì •:** ì´ˆê¸° 7ì¼ í‰ê·  CTR = {p0_val*100:.2f}%")
                else:
                    p0_val = sub['í´ë¦­'].sum() / (sub['ë…¸ì¶œ'].sum() + 1e-9)
                    st.warning(f"ë°ì´í„° ë¶€ì¡±: ì „ì²´ í‰ê·  CTR = {p0_val*100:.2f}% ì‚¬ìš©")
                
                cusum_vals = get_binomial_cusum(sub['í´ë¦­'].values, sub['ë…¸ì¶œ'].values, p0_val)
                
                with st.spinner('ì„ê³„ê°’ ê³„ì‚° ì¤‘... (Monte Carlo ì‹œë®¬ë ˆì´ì…˜)'):
                    h_threshold, achieved_arl = estimate_h_via_arl(p0_val, sub['ë…¸ì¶œ'].values)
                h_threshold = -h_threshold
                
                fig_cusum = go.Figure()
                fig_cusum.add_trace(go.Scatter(x=sub['ë‚ ì§œ'], y=cusum_vals, mode='lines+markers', name='CUSUM', line=dict(color='blue', width=2)))
                fig_cusum.add_hline(y=h_threshold, line_dash="dash", line_color="red", annotation_text=f"ì„ê³„ê°’ h={-h_threshold:.2f} (ARLâ‰ˆ{achieved_arl:.0f}ì¼)")
                fig_cusum.update_layout(title=f"{t_id} - CUSUM ì¶”ì„¸", xaxis_title="ë‚ ì§œ", yaxis_title="CUSUM ê°’")
                st.plotly_chart(fig_cusum, use_container_width=True)
                
                if cusum_vals[-1] < h_threshold:
                    st.error(f"âš ï¸ **ì„±ê³¼ í•˜ë½ ê°ì§€!**\n\ní˜„ì¬ CUSUM: {cusum_vals[-1]:.2f}\nê¶Œì¥ ì¡°ì¹˜: ì†Œì¬ êµì²´ ë˜ëŠ” ì˜ˆì‚° ì¶•ì†Œ ê²€í† ")
                elif cusum_vals[-1] < h_threshold * 0.5:
                    st.warning(f"âš¡ **ì£¼ì˜ í•„ìš”**\n\ní˜„ì¬ CUSUM: {cusum_vals[-1]:.2f}\nëª¨ë‹ˆí„°ë§ ê°•í™” í•„ìš”")
                else:
                    st.success(f"âœ… **ì •ìƒ ë²”ìœ„**\n\ní˜„ì¬ CUSUM: {cusum_vals[-1]:.2f}\nì„±ê³¼ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ ì¤‘")
                
                with st.expander("â„¹ï¸ CUSUM ë°©ë²•ë¡  ìƒì„¸"):
                    st.markdown(f"""
                    **ì„ê³„ê°’ h = {-h_threshold:.2f}** (Monte Carlo 500íšŒ ì‹œë®¬ë ˆì´ì…˜)
                    **ëª©í‘œ ARL = 30ì¼** (ì •ìƒ ìƒíƒœì—ì„œ í‰ê·  30ì¼ë§ˆë‹¤ 1íšŒ ì˜¤ê²½ë³´)
                    **ë‹¬ì„± ARL = {achieved_arl:.0f}ì¼**
                    
                    **ì‘ë™ ì›ë¦¬:**
                    - ê¸°ì¤€ì„ ({p0_val*100:.2f}%) ëŒ€ë¹„ "ëˆ„ì  í¸ì°¨" ê³„ì‚°
                    - ê°’ì´ ìŒìˆ˜ë¡œ ë–¨ì–´ì§ˆìˆ˜ë¡ â†’ ì„±ê³¼ í•˜ë½ ì‹ í˜¸
                    - ì„ê³„ê°’ ëŒíŒŒ ì‹œ â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ë³€í™”
                    """)
        
        # ====================
        # TAB 5: ì˜ˆì‚° ì‹œë®¬ë ˆì´í„° (ì „ë¬¸ê°€ ëª¨ë“œ)
        # ====================
        if analysis_mode == "ğŸ”¬ ì „ë¬¸ê°€ ëª¨ë“œ":
            with tabs[5]:
                st.markdown("### ğŸ® ì¸í„°ë™í‹°ë¸Œ ì˜ˆì‚° ì‹œë®¬ë ˆì´í„°")
                
                with st.expander("â„¹ï¸ ì´ ë„êµ¬ì˜ ëª©ì ê³¼ í•œê³„"):
                    st.markdown("""
                    **ëª©ì :**
                    "ì´ ì˜ˆì‚°ì„ ì–´ë–»ê²Œ ë°°ë¶„í• ê¹Œ?" ì‹œë®¬ë ˆì´ì…˜
                    
                    **ë°©ë²•:**
                    - ìŠ¬ë¼ì´ë”ë¡œ ì†Œì¬ë³„ ë°°ë¶„ ë¹„ìœ¨ ì¡°ì •
                    - ì‹¤ì‹œê°„ìœ¼ë¡œ ì˜ˆìƒ ì„±ê³¼ ê³„ì‚°
                    
                    âš ï¸ **ì¤‘ìš”í•œ í•œê³„:**
                    - **ì„ í˜• ê°€ì •**: ì˜ˆì‚° 2ë°° = ë…¸ì¶œ 2ë°° (ì‹¤ì œëŠ” X)
                    - **CTR ë¶ˆë³€ ê°€ì •**: ë…¸ì¶œ ëŠ˜ë ¤ë„ CTR ë™ì¼ (ì‹¤ì œëŠ” í•˜ë½ ê°€ëŠ¥)
                    - **ì¸ê³¼ ë¬´ì‹œ**: ì˜ˆì‚° ì¦ì•¡ì´ ì„±ê³¼ ë³´ì¥ ì•ˆ í•¨
                    
                    **ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²•:**
                    - "ëŒ€ëµì  ë°©í–¥ì„±" íƒìƒ‰
                    - ì‹¤ì œ ì ìš© ì‹œ ì ì§„ì  í…ŒìŠ¤íŠ¸ í•„ìˆ˜
                    - A/B í…ŒìŠ¤íŠ¸ë¡œ ê²€ì¦
                    """)
                
                st.markdown("---")
                total_budget = st.number_input("ì´ ì¼ì˜ˆì‚° (ì›)", min_value=0, value=int(res_agg['avg_cost_7d'].sum()), step=100000)
                
                st.markdown("### ì†Œì¬ë³„ ì˜ˆì‚° ë°°ë¶„")
                allocations = {}
                for _, material in res_agg.iterrows():
                    mat_id = material['ID']
                    current_pct = material['avg_cost_7d'] / res_agg['avg_cost_7d'].sum() * 100
                    allocations[mat_id] = st.slider(f"{mat_id}", 0, 100, int(current_pct), key=f"slider_{mat_id}")
                
                total_pct = sum(allocations.values())
                
                if abs(total_pct - 100) > 1:
                    st.error(f"âš ï¸ ì´ ë°°ë¶„: {total_pct}% (100%ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤)")
                else:
                    st.success(f"âœ… ì´ ë°°ë¶„: {total_pct}%")
                    
                    st.markdown("---")
                    st.markdown("### ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼")
                    
                    sim_results = []
                    for mat_id, pct in allocations.items():
                        material = res_agg[res_agg['ID'] == mat_id].iloc[0]
                        allocated_budget = total_budget * (pct / 100)
                        
                        current_avg_cost = material['avg_cost_7d']
                        if current_avg_cost > 0:
                            scale_factor = allocated_budget / current_avg_cost
                            expected_clicks = material['í´ë¦­'] / 7 * scale_factor
                            expected_impressions = material['ë…¸ì¶œ'] / 7 * scale_factor
                        else:
                            expected_clicks = 0
                            expected_impressions = 0
                        
                        sim_results.append({
                            'ì†Œì¬': mat_id,
                            'ë°°ë¶„(%)': pct,
                            'ë°°ë¶„ê¸ˆì•¡': allocated_budget,
                            'ì˜ˆìƒí´ë¦­': int(expected_clicks),
                            'ì˜ˆìƒë…¸ì¶œ': int(expected_impressions),
                            'CTR': material['exp_ctr'] * 100
                        })
                    
                    sim_df = pd.DataFrame(sim_results)
                    st.dataframe(
                        sim_df.style.format({
                            'ë°°ë¶„(%)': '{:.1f}%',
                            'ë°°ë¶„ê¸ˆì•¡': '{:,.0f}ì›',
                            'ì˜ˆìƒí´ë¦­': '{:,.0f}íšŒ',
                            'ì˜ˆìƒë…¸ì¶œ': '{:,.0f}íšŒ',
                            'CTR': '{:.2f}%'
                        }),
                        use_container_width=True
                    )
                    
                    col1, col2, col3 = st.columns(3)
                    col1.metric("ì´ ì˜ˆì‚°", f"{total_budget:,.0f}ì›")
                    col2.metric("ì˜ˆìƒ ì´ í´ë¦­", f"{sim_df['ì˜ˆìƒí´ë¦­'].sum():,.0f}íšŒ")
                    col3.metric("ì˜ˆìƒ í‰ê·  CPC", f"{total_budget / sim_df['ì˜ˆìƒí´ë¦­'].sum():,.0f}ì›" if sim_df['ì˜ˆìƒí´ë¦­'].sum() > 0 else "N/A")
        
        # ====================
        # TAB 6(ì‹¤ë¬´) / TAB 6(ì „ë¬¸ê°€): ì£¼ê°„ ë¦¬í¬íŠ¸
        # ====================
        report_idx = 3 if analysis_mode == "ğŸ¯ ì‹¤ë¬´ ëª¨ë“œ (ê¶Œì¥)" else 6
        with tabs[report_idx]:
            st.markdown("### ğŸ“„ ì£¼ê°„ ì„±ê³¼ ë¦¬í¬íŠ¸")
            
            date_range = st.date_input("ë¶„ì„ ê¸°ê°„ ì„ íƒ", value=(df['ë‚ ì§œ'].min().date(), df['ë‚ ì§œ'].max().date()), max_value=df['ë‚ ì§œ'].max().date())
            
            if len(date_range) == 2:
                start_date, end_date = date_range
                period_df = df[(df['ë‚ ì§œ'].dt.date >= start_date) & (df['ë‚ ì§œ'].dt.date <= end_date)]
                
                if len(period_df) == 0:
                    st.warning("ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.markdown(f"**ë¶„ì„ ê¸°ê°„: {start_date} ~ {end_date} ({(end_date - start_date).days + 1}ì¼)**")
                    st.markdown("---")
                    
                    st.markdown("### âœ¨ í•µì‹¬ ìš”ì•½")
                    col1, col2, col3, col4 = st.columns(4)
                    
                    total_cost = period_df['ë¹„ìš©'].sum()
                    total_clicks = period_df['í´ë¦­'].sum()
                    total_impressions = period_df['ë…¸ì¶œ'].sum()
                    avg_ctr = total_clicks / total_impressions * 100 if total_impressions > 0 else 0
                    avg_cpc = total_cost / total_clicks if total_clicks > 0 else 0
                    
                    col1.metric("ì´ ì§‘í–‰ë¹„", f"{total_cost:,.0f}ì›")
                    col2.metric("ì´ í´ë¦­ìˆ˜", f"{total_clicks:,}íšŒ")
                    col3.metric("í‰ê·  CTR", f"{avg_ctr:.2f}%")
                    col4.metric("í‰ê·  CPC", f"{avg_cpc:,.0f}ì›")
                    
                    st.markdown("---")
                    st.markdown("### ğŸ’° ì˜ˆì‚° ì§‘í–‰ í˜„í™©")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**ğŸ“± ë§¤ì²´ë³„**")
                        if 'ë§¤ì²´' in period_df.columns:
                            media_summary = period_df.groupby('ë§¤ì²´')['ë¹„ìš©'].sum().sort_values(ascending=False)
                            for media, cost in media_summary.items():
                                pct = cost / total_cost * 100
                                st.write(f"â”œâ”€ {media}: {cost:,.0f}ì› ({pct:.1f}%)")
                    
                    with col2:
                        st.markdown("**ğŸ“¦ ìƒí’ˆë³„**")
                        product_summary = period_df.groupby('ìƒí’ˆ')['ë¹„ìš©'].sum().sort_values(ascending=False)
                        for product, cost in product_summary.items():
                            pct = cost / total_cost * 100
                            st.write(f"â”œâ”€ {product}: {cost:,.0f}ì› ({pct:.1f}%)")
                    
                    st.markdown("**ğŸ¨ ì†Œì¬ë³„**")
                    material_summary = period_df.groupby('ID')['ë¹„ìš©'].sum().sort_values(ascending=False)
                    for mat_id, cost in material_summary.items():
                        pct = cost / total_cost * 100
                        st.write(f"â”œâ”€ {mat_id}: {cost:,.0f}ì› ({pct:.1f}%)")
                    
                    st.markdown("---")
                    st.markdown("### ğŸ† ì„±ê³¼ ë¶„ì„")
                    
                    col1, col2 = st.columns(2)
                    
                    material_perf = period_df.groupby('ID').agg({'í´ë¦­': 'sum', 'ë…¸ì¶œ': 'sum', 'ë¹„ìš©': 'sum'})
                    material_perf['CTR'] = material_perf['í´ë¦­'] / material_perf['ë…¸ì¶œ'] * 100
                    material_perf['CPC'] = material_perf['ë¹„ìš©'] / material_perf['í´ë¦­']
                    
                    with col1:
                        st.markdown("**ğŸ¥‡ ë² ìŠ¤íŠ¸ ì†Œì¬ (CTR ê¸°ì¤€)**")
                        best = material_perf.nlargest(1, 'CTR').iloc[0]
                        st.success(f"""
                        **{material_perf.nlargest(1, 'CTR').index[0]}**
                        - CTR: {best['CTR']:.2f}%
                        - ì´ í´ë¦­: {int(best['í´ë¦­']):,}íšŒ
                        - ì´ ë¹„ìš©: {int(best['ë¹„ìš©']):,}ì›
                        """)
                    
                    with col2:
                        st.markdown("**âš ï¸ ê°œì„  í•„ìš” ì†Œì¬ (CTR ê¸°ì¤€)**")
                        worst = material_perf.nsmallest(1, 'CTR').iloc[0]
                        st.warning(f"""
                        **{material_perf.nsmallest(1, 'CTR').index[0]}**
                        - CTR: {worst['CTR']:.2f}%
                        - ì´ í´ë¦­: {int(worst['í´ë¦­']):,}íšŒ
                        - ì´ ë¹„ìš©: {int(worst['ë¹„ìš©']):,}ì›
                        """)
    else:
        st.warning("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    st.info("ğŸ‘† ìƒë‹¨ì—ì„œ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")