import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
from scipy.stats import beta
from sklearn.linear_model import LinearRegression

st.set_page_config(page_title="Ad Analytics System v2", layout="wide")
st.title("ğŸ¯ ê´‘ê³  ë§¤ì²´ í†µê³„ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("**Empirical Bayes & CUSUM ê¸°ë°˜ ì†Œì¬ ì„±ê³¼ ë¶„ì„**")
st.markdown("---")

def load_and_clean_data(uploaded_file):
    try:
        if uploaded_file.name.endswith('.xlsx'):
            all_sheets = pd.read_excel(uploaded_file, sheet_name=None)
            df = pd.concat(all_sheets.values(), ignore_index=True)
        else:
            df = pd.read_csv(uploaded_file, sep='\t' if uploaded_file.name.endswith('.tsv') else ',')
        
        df.columns = [c.strip() for c in df.columns]
        mapping = {
            'ë‚ ì§œ': ['ë‚ ì§œ', 'ì¼ì', 'date'], 
            'ë§¤ì²´': ['ë§¤ì²´', 'media'],
            'ìƒí’ˆ': ['ìƒí’ˆëª…', 'ìƒí’ˆ', 'product'], 
            'ì†Œì¬': ['ì†Œì¬ëª…', 'ì†Œì¬', 'material'],
            'ë…¸ì¶œ': ['ë…¸ì¶œìˆ˜', 'ë…¸ì¶œ', 'impressions'], 
            'í´ë¦­': ['í´ë¦­ìˆ˜', 'í´ë¦­', 'clicks'], 
            'ë¹„ìš©': ['ë¹„ìš©', 'ì§€ì¶œ', 'cost']
        }
        
        final_df = pd.DataFrame()
        for k, v in mapping.items():
            for col in v:
                if col in df.columns: 
                    final_df[k] = df[col]
                    break
        
        final_df['ë‚ ì§œ'] = pd.to_datetime(final_df['ë‚ ì§œ'], errors='coerce')
        for col in ['ë…¸ì¶œ', 'í´ë¦­', 'ë¹„ìš©']:
            final_df[col] = pd.to_numeric(
                final_df[col].astype(str).str.replace(r'[^\d.]', '', regex=True), 
                errors='coerce'
            ).fillna(0)
        
        final_df['CTR(%)'] = (final_df['í´ë¦­'] / (final_df['ë…¸ì¶œ'] + 1e-9) * 100)
        final_df['CPC'] = final_df['ë¹„ìš©'] / (final_df['í´ë¦­'] + 1e-9)
        final_df['ID'] = "[" + final_df['ìƒí’ˆ'].astype(str) + "] " + final_df['ì†Œì¬'].astype(str)
        
        return final_df.dropna(subset=['ë‚ ì§œ']).sort_values(['ID', 'ë‚ ì§œ'])
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def analyze_empirical_bayes(df):
    global_ctr = df['í´ë¦­'].sum() / (df['ë…¸ì¶œ'].sum() + 1e-9)
    id_stats = df.groupby('ID').agg({'í´ë¦­': 'sum', 'ë…¸ì¶œ': 'sum', 'ë¹„ìš©': 'sum'})
    id_ctrs = id_stats['í´ë¦­'] / (id_stats['ë…¸ì¶œ'] + 1e-9)
    var_ctr = max(id_ctrs.var(), 1e-7)
    
    kappa = (global_ctr * (1 - global_ctr) / var_ctr) - 1
    kappa = np.clip(kappa, 10, 1000)
    
    alpha_0, beta_0 = global_ctr * kappa, (1 - global_ctr) * kappa
    
    agg = id_stats.reset_index()
    agg['post_alpha'] = alpha_0 + agg['í´ë¦­']
    agg['post_beta'] = beta_0 + (agg['ë…¸ì¶œ'] - agg['í´ë¦­'])
    agg['exp_ctr'] = agg['post_alpha'] / (agg['post_alpha'] + agg['post_beta'])
    agg['raw_ctr'] = agg['í´ë¦­'] / (agg['ë…¸ì¶œ'] + 1e-9)
    
    samples = np.random.beta(
        agg['post_alpha'].values[:, None], 
        agg['post_beta'].values[:, None], 
        size=(len(agg), 5000)
    )
    agg['prob_is_best'] = np.bincount(
        np.argmax(samples, axis=0), 
        minlength=len(agg)
    ) / 5000
    
    max_date = df['ë‚ ì§œ'].max()
    date_7d_ago = max_date - timedelta(days=6)
    last_7d = df[df['ë‚ ì§œ'] >= date_7d_ago]
    last_costs = last_7d.groupby('ID')['ë¹„ìš©'].sum() / 7
    agg = agg.merge(last_costs.rename('avg_cost_7d'), on='ID', how='left').fillna(0)
    
    return agg, (alpha_0, beta_0, kappa, global_ctr)

def get_binomial_cusum(clicks, imps, p0):
    p1 = np.clip(p0 * 0.85, 1e-6, 1-1e-6)
    p0 = np.clip(p0, 1e-6, 1-1e-6)
    llr = clicks * np.log(p1/p0) + (imps - clicks) * np.log((1-p1)/(1-p0))
    s = 0
    cusum = []
    for val in llr:
        s = min(0, s + val)
        cusum.append(s)
    return np.array(cusum)

@st.cache_data
def estimate_h_via_arl(p0, imps_series, target_arl=30, sims=500):
    p1 = np.clip(p0 * 0.85, 1e-6, 1-1e-6)
    p0_clip = np.clip(p0, 1e-6, 1-1e-6)
    llr_success = np.log(p1 / p0_clip)
    llr_failure = np.log((1 - p1) / (1 - p0_clip))
    
    h_candidates = np.arange(1.0, 30.0, 0.5)
    
    for h in h_candidates:
        run_lengths = []
        for _ in range(sims):
            s, t = 0, 0
            while t < 500:
                t += 1
                n = np.random.choice(imps_series) if len(imps_series) > 0 else 100000
                c = np.random.binomial(int(n), p0_clip)
                s = min(0, s + (c * llr_success + (int(n) - c) * llr_failure))
                if s < -h:
                    break
            run_lengths.append(t)
        
        actual_arl = np.mean(run_lengths)
        if actual_arl >= target_arl:
            return h, actual_arl
    
    return h_candidates[-1], np.mean(run_lengths)

def get_confidence_level(material, df):
    mat_id = material['ID']
    mat_data = df[df['ID'] == mat_id]
    
    data_score = 1 if material['ë…¸ì¶œ'] > 1000000 else (0.5 if material['ë…¸ì¶œ'] > 100000 else 0)
    
    if len(mat_data) >= 7:
        daily_ctr_std = mat_data['CTR(%)'].std()
        stability_score = 1 if daily_ctr_std < material['exp_ctr'] * 50 else (0.5 if daily_ctr_std < material['exp_ctr'] * 100 else 0)
    else:
        stability_score = 0
    
    total_score = (data_score + stability_score) / 2
    
    if total_score >= 0.7:
        return "ğŸŸ¢ ì‹ ë¢°ë„ ë†’ìŒ", "ì¶©ë¶„í•œ ë°ì´í„°ì™€ ì•ˆì •ì  íŒ¨í„´"
    elif total_score >= 0.4:
        return "ğŸŸ¡ ì‹ ë¢°ë„ ë³´í†µ", "ì¶”ê°€ ê´€ì°° ê¶Œì¥"
    else:
        return "ğŸ”´ ì‹ ë¢°ë„ ë‚®ìŒ", "ë°ì´í„° ë¶€ì¡± ë˜ëŠ” ë³€ë™ì„± ë†’ìŒ"

uploaded_file = st.file_uploader("ğŸ“‚ ìº í˜ì¸ ë°ì´í„° ì—…ë¡œë“œ (CSV/XLSX/TSV)", type=['csv', 'xlsx', 'tsv'])

if uploaded_file:
    df = load_and_clean_data(uploaded_file)
    
    if not df.empty:
        res_agg, (a0, b0, k_est, global_ctr) = analyze_empirical_bayes(df)
        ids = sorted(df['ID'].unique())
        
        st.markdown("---")
        analysis_mode = st.radio(
            "ğŸ“Š ë¶„ì„ ëª¨ë“œ ì„ íƒ",
            ["ğŸ¯ ì‹¤ë¬´ ëª¨ë“œ", "ğŸ“Š ë³´ê³ ìš© ëª¨ë“œ", "ğŸ”¬ ì „ë¬¸ê°€ ëª¨ë“œ"],
            horizontal=True,
            help="ì‹¤ë¬´: ì¼ìƒ ì˜ì‚¬ê²°ì • | ë³´ê³ ìš©: ìƒì‚¬/ì„ì› ë³´ê³  | ì „ë¬¸ê°€: ìƒì„¸ í†µê³„ ë¶„ì„"
        )
        
        if analysis_mode == "ğŸ¯ ì‹¤ë¬´ ëª¨ë“œ":
            tabs = st.tabs(["ğŸ“Š ì„±ê³¼ ìš”ì•½", "ğŸ¯ ì˜ì‚¬ê²°ì • ê°€ì´ë“œ", "â° ì¡°ê¸° ê²½ê³ ", "ğŸ“„ ì£¼ê°„ ë¦¬í¬íŠ¸"])
        elif analysis_mode == "ğŸ“Š ë³´ê³ ìš© ëª¨ë“œ":
            tabs = st.tabs(["ğŸ“‹ ì£¼ìš” ì˜ì‚¬ê²°ì • ì‚¬í•­"])
        else:
            tabs = st.tabs(["ğŸ“Š Executive Summary", "ğŸ¯ ì˜ì‚¬ê²°ì • ê°€ì´ë“œ", "â° ì¡°ê¸° ê²½ê³ ", "ğŸ§¬ Bayesian Analysis", "ğŸ“‰ CUSUM", "ğŸ® ì˜ˆì‚° ì‹œë®¬ë ˆì´í„°", "ğŸ“„ ì£¼ê°„ ë¦¬í¬íŠ¸"])
        
        # TAB 0: ì„±ê³¼ ìš”ì•½ (ì‹¤ë¬´/ì „ë¬¸ê°€ ëª¨ë“œ)
        if analysis_mode != "ğŸ“Š ë³´ê³ ìš© ëª¨ë“œ":
            with tabs[0]:
                st.markdown("### ğŸ“Š í•µì‹¬ ì§€í‘œ ìš”ì•½")
                
                if analysis_mode == "ğŸ¯ ì‹¤ë¬´ ëª¨ë“œ":
                    st.info("ğŸ’¡ **ì‹¤ë¬´ ëª¨ë“œ**: ì¼ìƒ ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ í•µì‹¬ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
                
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("ì „ì²´ í‰ê·  CTR", f"{global_ctr*100:.2f}%")
                col2.metric("ë¶„ì„ ê¸°ê°„", f"{(df['ë‚ ì§œ'].max() - df['ë‚ ì§œ'].min()).days}ì¼")
                col3.metric("ì´ ì†Œì¬ ìˆ˜", len(ids))
                col4.metric("ì´ ì§‘í–‰ ë¹„ìš©", f"{df['ë¹„ìš©'].sum():,.0f}ì›")
                
                with st.expander("â„¹ï¸ CTR(Click-Through Rate)ì´ë€?"):
                    st.markdown("""
                    **CTR = (í´ë¦­ìˆ˜ / ë…¸ì¶œìˆ˜) Ã— 100%**
                    
                    ê´‘ê³ ê°€ 1000ë²ˆ ë…¸ì¶œë˜ì–´ 10ë²ˆ í´ë¦­ë˜ì—ˆë‹¤ë©´ CTR = 1.0%
                    - ë†’ì„ìˆ˜ë¡: ê´‘ê³ ê°€ ì‚¬ìš©ìì—ê²Œ ë§¤ë ¥ì 
                    - ë‚®ì„ìˆ˜ë¡: ì†Œì¬ ê°œì„  í•„ìš” ë˜ëŠ” íƒ€ê²ŸíŒ… ë¬¸ì œ
                    - ì—…ê³„ í‰ê· : ë””ìŠ¤í”Œë ˆì´ 0.5~1%, ê²€ìƒ‰ê´‘ê³  2~5%
                    """)
                
                st.markdown("---")
                st.markdown("### ğŸ† ìµœê³  ì„±ê³¼ ì†Œì¬ í™•ë¥ ")
                
                with st.expander("â„¹ï¸ ì´ í™•ë¥ ì€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜ìš”?"):
                    st.markdown("""
                    **"ê° ì†Œì¬ê°€ ì‹¤ì œë¡œ ìµœê³  CTRì„ ê°€ì§ˆ í™•ë¥ "**
                    
                    âš ï¸ **ì£¼ì˜ì‚¬í•­:**
                    - ì´ëŠ” **í˜„ì¬ ë°ì´í„° ê¸°ì¤€** í™•ë¥ ì…ë‹ˆë‹¤
                    - í–¥í›„ ì„±ê³¼ë¥¼ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
                    - í™•ë¥ ì´ ë¹„ìŠ·í•˜ë©´ â†’ ë” ë§ì€ ë°ì´í„° í•„ìš”
                    """)
                
                fig_prob = px.bar(
                    res_agg.sort_values('prob_is_best', ascending=True),
                    x='prob_is_best', y='ID', orientation='h',
                    text=res_agg.sort_values('prob_is_best', ascending=True)['prob_is_best'].apply(lambda x: f"{x*100:.1f}%")
                )
                fig_prob.update_xaxes(tickformat='.0%')
                st.plotly_chart(fig_prob, use_container_width=True)
                
                st.markdown("---")
                st.markdown("### ğŸ“ˆ ì†Œì¬ë³„ ìƒì„¸ ì„±ê³¼")
                
                display_df = res_agg[['ID', 'raw_ctr', 'exp_ctr', 'ë…¸ì¶œ', 'í´ë¦­', 'ë¹„ìš©', 'prob_is_best']].copy()
                display_df['raw_ctr'] = display_df['raw_ctr'] * 100
                display_df['exp_ctr'] = display_df['exp_ctr'] * 100
                display_df['prob_is_best'] = display_df['prob_is_best'] * 100
                display_df.columns = ['ì†Œì¬', 'ì›ë³¸CTR(%)', 'ë³´ì •CTR(%)', 'ë…¸ì¶œìˆ˜', 'í´ë¦­ìˆ˜', 'ë¹„ìš©', 'ìµœê³ í™•ë¥ ']
                
                st.dataframe(
                    display_df.style.format({
                        'ì›ë³¸CTR(%)': '{:.2f}',
                        'ë³´ì •CTR(%)': '{:.2f}',
                        'ë…¸ì¶œìˆ˜': '{:,.0f}',
                        'í´ë¦­ìˆ˜': '{:,.0f}',
                        'ë¹„ìš©': '{:,.0f}ì›',
                        'ìµœê³ í™•ë¥ ': '{:.1f}%'
                    }).background_gradient(subset=['ë³´ì •CTR(%)'], cmap='RdYlGn'),
                    use_container_width=True
                )
        
        # TAB 1: ì˜ì‚¬ê²°ì • ê°€ì´ë“œ (ì‹¤ë¬´/ì „ë¬¸ê°€) ë˜ëŠ” ë³´ê³ ìš© ëª¨ë“œ ë©”ì¸
        report_idx = 0 if analysis_mode == "ğŸ“Š ë³´ê³ ìš© ëª¨ë“œ" else 1
        with tabs[report_idx]:
            if analysis_mode == "ğŸ“Š ë³´ê³ ìš© ëª¨ë“œ":
                st.markdown("### ğŸ“‹ ì£¼ìš” ì˜ì‚¬ê²°ì • ì‚¬í•­")
                st.markdown(f"**ë¶„ì„ ê¸°ì¤€: {df['ë‚ ì§œ'].max().strftime('%Yë…„ %mì›” %dì¼')}**")
                st.markdown("---")
            else:
                st.markdown("### ğŸ¯ ì˜ì‚¬ê²°ì • ê°€ì´ë“œ")
                st.markdown(f"**ë¶„ì„ ê¸°ì¤€ì¼: {df['ë‚ ì§œ'].max().strftime('%Yë…„ %mì›” %dì¼')}**")
                
                with st.expander("â„¹ï¸ ì´ ê°€ì´ë“œëŠ” ë¬´ì—‡ì„ í•˜ë‚˜ìš”?"):
                    st.markdown("""
                    **ë§¤ì¼ í™•ì¸í•˜ëŠ” ì˜ì‚¬ê²°ì • ì°¸ê³  ìë£Œ**
                    
                    ê° ì†Œì¬ì˜ ìƒíƒœë¥¼ 4ê°€ì§€ë¡œ ë¶„ë¥˜:
                    - ğŸ”´ ê²€í†  í•„ìš”
                    - ğŸŸ¡ ì£¼ì˜ ê´€ì°°
                    - ğŸŸ¢ ì¦ì•¡ ê²€í† 
                    - âšª í˜„ìƒ ìœ ì§€
                    
                    **íŒë‹¨ ê¸°ì¤€:**
                    1. CUSUM ì´ìƒ ê°ì§€ (í†µê³„ì  í•˜ë½)
                    2. ìµœê·¼ 3ì¼ ì¶”ì„¸
                    3. Bayesian ìµœê³  í™•ë¥ 
                    """)
            
            st.markdown("---")
            
            actions = []
            for _, material in res_agg.iterrows():
                mat_id = material['ID']
                mat_data = df[df['ID'] == mat_id].sort_values('ë‚ ì§œ')
                
                if len(mat_data) >= 3:
                    recent_3 = mat_data.tail(3)['CTR(%)']
                    trend_change = (recent_3.iloc[-1] - recent_3.iloc[0]) / recent_3.iloc[0] if recent_3.iloc[0] > 0 else 0
                else:
                    trend_change = 0
                
                recent_ctr = mat_data.tail(3)['CTR(%)'].mean()
                baseline_ctr = material['exp_ctr'] * 100
                cusum_alert = recent_ctr < baseline_ctr * 0.85
                
                if len(mat_data) >= 7:
                    p0_cusum = mat_data.head(7)['í´ë¦­'].sum() / (mat_data.head(7)['ë…¸ì¶œ'].sum() + 1e-9)
                else:
                    p0_cusum = mat_data['í´ë¦­'].sum() / (mat_data['ë…¸ì¶œ'].sum() + 1e-9)
                
                cusum_vals = get_binomial_cusum(mat_data['í´ë¦­'].values, mat_data['ë…¸ì¶œ'].values, p0_cusum)
                h_th, _ = estimate_h_via_arl(p0_cusum, mat_data['ë…¸ì¶œ'].values, sims=200)
                cusum_breach = cusum_vals[-1] < -h_th
                
                conf_level, conf_reason = get_confidence_level(material, df)
                
                if (cusum_alert or cusum_breach) and trend_change < -0.1:
                    status, priority = "ğŸ”´ ê²€í†  í•„ìš”", 1
                    reason = f"ìµœê·¼ ì„±ê³¼ í•˜ë½ ê°ì§€ (3ì¼ ì¶”ì„¸ {trend_change*100:.1f}%)"
                    if cusum_breach:
                        reason += " + CUSUM ì„ê³„ê°’ ëŒíŒŒ"
                    action = "ì„±ê³¼ ë¶„ì„ ë° ëŒ€ì•ˆ ê²€í† "
                elif trend_change < -0.05:
                    status, priority = "ğŸŸ¡ ì£¼ì˜ ê´€ì°°", 2
                    reason = f"í•˜ë½ ì¶”ì„¸ ê´€ì°° ì¤‘ (3ì¼ ì¶”ì„¸ {trend_change*100:.1f}%)"
                    action = "ì¶”ê°€ ëª¨ë‹ˆí„°ë§"
                elif material['prob_is_best'] > 0.4 and trend_change > 0.05:
                    status, priority = "ğŸŸ¢ ì¦ì•¡ ê²€í† ", 3
                    reason = f"ìš°ìˆ˜ ì„±ê³¼ ìœ ì§€ (ìµœê³  í™•ë¥  {material['prob_is_best']*100:.0f}%, 3ì¼ ì¶”ì„¸ +{trend_change*100:.1f}%)"
                    action = "ì ì§„ì  ì¦ì•¡ í…ŒìŠ¤íŠ¸"
                else:
                    status, priority = "âšª í˜„ìƒ ìœ ì§€", 4
                    reason = "ì•ˆì •ì  ì„±ê³¼ ìœ ì§€ ì¤‘"
                    action = "ì •ê¸° ëª¨ë‹ˆí„°ë§"
                
                actions.append({
                    'ID': mat_id, 'status': status, 'priority': priority,
                    'reason': reason, 'action': action,
                    'current_cost': material['avg_cost_7d'],
                    'confidence': conf_level, 'conf_reason': conf_reason
                })
            
            actions_df = pd.DataFrame(actions).sort_values('priority')
            
            if analysis_mode == "ğŸ“Š ë³´ê³ ìš© ëª¨ë“œ":
                priority_actions = actions_df[actions_df['priority'] <= 2]
                
                if len(priority_actions) > 0:
                    for idx, action in priority_actions.iterrows():
                        st.markdown(f"## {idx+1}. {action['ID']}")
                        st.markdown(f"**ìƒíƒœ:** {action['status']}")
                        st.markdown(f"**ë¶„ì„ ê²°ê³¼:** {action['reason']}")
                        st.markdown(f"**ì œì•ˆ ì‚¬í•­:** {action['action']}")
                        st.markdown(f"**ì‹ ë¢°ë„:** {action['confidence']} ({action['conf_reason']})")
                        st.markdown(f"**í˜„ì¬ ì¼í‰ê·  ë¹„ìš©:** {action['current_cost']:,.0f}ì›")
                        st.markdown("---")
                else:
                    st.success("âœ… ëª¨ë“  ì†Œì¬ê°€ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ ì¤‘ì…ë‹ˆë‹¤.")
                
                st.markdown("### ğŸ“Š ì „ì²´ ì†Œì¬ í˜„í™©")
                status_counts = actions_df['status'].value_counts()
                for status, count in status_counts.items():
                    st.write(f"{status}: {count}ê°œ")
            else:
                for _, action in actions_df.iterrows():
                    st.markdown(f"### {action['status']}")
                    st.markdown(f"**ì†Œì¬:** {action['ID']}")
                    st.markdown(f"**í˜„ì¬ ì¼í‰ê·  ë¹„ìš©:** {action['current_cost']:,.0f}ì›")
                    st.markdown(f"**ë¶„ì„ ê²°ê³¼:** {action['reason']}")
                    st.markdown(f"**ì œì•ˆ ì‚¬í•­:** {action['action']}")
                    st.markdown(f"**ì‹ ë¢°ë„:** {action['confidence']}")
                    st.markdown("---")
        
        # TAB 2: ì¡°ê¸° ê²½ê³  (ì‹¤ë¬´/ì „ë¬¸ê°€ ëª¨ë“œ)
        if analysis_mode != "ğŸ“Š ë³´ê³ ìš© ëª¨ë“œ":
            warning_idx = 1 if analysis_mode == "ğŸ“Š ë³´ê³ ìš© ëª¨ë“œ" else 2
            with tabs[warning_idx]:
                st.markdown("### â° ì¡°ê¸° ê²½ê³  ì§€í‘œ")
                
                with st.expander("â„¹ï¸ ì¡°ê¸° ê²½ê³ ë€?"):
                    st.markdown("""
                    **ì†Œì¬ í”¼ë¡œë„ (Creative Fatigue) ì¡°ê¸° ê°ì§€**
                    
                    ê°™ì€ ê´‘ê³ ë¥¼ ë°˜ë³µ ë…¸ì¶œí•˜ë©´ CTRì´ ì ì§„ì ìœ¼ë¡œ í•˜ë½í•©ë‹ˆë‹¤.
                    ì´ ì§€í‘œëŠ” í†µê³„ì  ì¶”ì„¸ ë¶„ì„ìœ¼ë¡œ ì ì¬ì  ë¬¸ì œë¥¼ ì¡°ê¸°ì— í¬ì°©í•©ë‹ˆë‹¤.
                    
                    âš ï¸ **ì£¼ì˜:**
                    - ì„ í˜• íšŒê·€ ê¸°ë°˜ì˜ ë‹¨ìˆœ ì¶”ì •
                    - ì°¸ê³ ìš©ìœ¼ë¡œë§Œ í™œìš©
                    - ì™¸ë¶€ ìš”ì¸(ì‹œì¦Œ, ê²½ìŸì‚¬) ë¯¸ë°˜ì˜
                    """)
                
                st.markdown("---")
                
                for mat_id in ids:
                    mat_data = df[df['ID'] == mat_id].sort_values('ë‚ ì§œ')
                    
                    if len(mat_data) < 5:
                        st.warning(f"{mat_id}: ë°ì´í„° ë¶€ì¡± (5ì¼ ì´ìƒ í•„ìš”)")
                        continue
                    
                    X = np.arange(len(mat_data)).reshape(-1, 1)
                    y = mat_data['CTR(%)'].values
                    model = LinearRegression().fit(X, y)
                    slope = model.coef_[0]
                    current_ctr = y[-1]
                    
                    if slope < -0.001:
                        days_left = max(0, int((current_ctr - current_ctr * 0.5) / abs(slope)))
                        
                        if days_left == 0:
                            lifespan_status = "âš ï¸ êµì²´ ê²€í† "
                        elif days_left <= 3:
                            lifespan_status = f"ğŸ”´ ì£¼ì˜ (ì¶”ì • D-{days_left})"
                        elif days_left <= 7:
                            lifespan_status = f"ğŸŸ¡ ê´€ì°° (ì¶”ì • D-{days_left})"
                        else:
                            lifespan_status = f"ğŸŸ¢ ì•ˆì • (ì¶”ì • D-{days_left})"
                    else:
                        lifespan_status = "âœ… í•˜ë½ ì¶”ì„¸ ì—†ìŒ"
                        days_left = None
                    
                    col1, col2 = st.columns([2, 1])
                    with col1:
                        st.markdown(f"### {mat_id}")
                        st.markdown(f"**ìƒíƒœ:** {lifespan_status}")
                        st.markdown(f"**í˜„ì¬ CTR:** {current_ctr:.2f}%")
                        st.markdown(f"**ì¼í‰ê·  ë³€í™”ìœ¨:** {slope:.4f}%p")
                        if days_left is not None and days_left > 0:
                            st.markdown(f"**ì°¸ê³ :** ì„ í˜• ì¶”ì„¸ ê¸°ì¤€ ì¶”ì •")
                    
                    with col2:
                        fig_mini = go.Figure()
                        fig_mini.add_trace(go.Scatter(y=y, mode='lines+markers', name='ì‹¤ì œ CTR'))
                        trend_line = model.predict(X)
                        fig_mini.add_trace(go.Scatter(y=trend_line, mode='lines', name='ì¶”ì„¸', line=dict(dash='dash')))
                        fig_mini.update_layout(height=200, showlegend=False, margin=dict(l=0, r=0, t=0, b=0))
                        st.plotly_chart(fig_mini, use_container_width=True)
                    
                    st.markdown("---")
        
        # TAB 3: Bayesian (ì „ë¬¸ê°€ ëª¨ë“œë§Œ)
        if analysis_mode == "ğŸ”¬ ì „ë¬¸ê°€ ëª¨ë“œ":
            with tabs[3]:
                st.markdown("### ğŸ§¬ Empirical Bayes ë°©ë²•ë¡ ")
                
                col1, col2, col3 = st.columns(3)
                col1.metric("Prior Î±â‚€", f"{a0:.1f}")
                col2.metric("Prior Î²â‚€", f"{b0:.1f}")
                col3.metric("Îº (Kappa)", f"{k_est:.1f}")
                
                fig_post = go.Figure()
                colors = px.colors.qualitative.Set2
                for idx, (_, row) in enumerate(res_agg.iterrows()):
                    x = np.linspace(0, 0.03, 500)
                    y = beta.pdf(x, row['post_alpha'], row['post_beta'])
                    fig_post.add_trace(go.Scatter(
                        x=x*100, y=y, name=row['ID'],
                        mode='lines', fill='tozeroy', opacity=0.6,
                        line=dict(color=colors[idx % len(colors)], width=3)
                    ))
                
                fig_post.update_layout(
                    title="ê° ì†Œì¬ì˜ ì‹¤ì œ CTR ë¶„í¬ ì¶”ì •",
                    xaxis_title="CTR (%)",
                    yaxis_title="í™•ë¥  ë°€ë„"
                )
                st.plotly_chart(fig_post, use_container_width=True)
        
        # TAB 4: CUSUM (ì „ë¬¸ê°€ ëª¨ë“œë§Œ)
        if analysis_mode == "ğŸ”¬ ì „ë¬¸ê°€ ëª¨ë“œ":
            with tabs[4]:
                st.markdown("### ğŸ“‰ CUSUM ì´ìƒ ê°ì§€")
                
                t_id = st.selectbox("ì†Œì¬ ì„ íƒ", ids)
                sub = df[df['ID'] == t_id].sort_values('ë‚ ì§œ')
                
                if len(sub) >= 7:
                    p0_val = sub.head(7)['í´ë¦­'].sum() / (sub.head(7)['ë…¸ì¶œ'].sum() + 1e-9)
                else:
                    p0_val = sub['í´ë¦­'].sum() / (sub['ë…¸ì¶œ'].sum() + 1e-9)
                
                cusum_vals = get_binomial_cusum(sub['í´ë¦­'].values, sub['ë…¸ì¶œ'].values, p0_val)
                h_threshold, achieved_arl = estimate_h_via_arl(p0_val, sub['ë…¸ì¶œ'].values)
                h_threshold = -h_threshold
                
                fig_cusum = go.Figure()
                fig_cusum.add_trace(go.Scatter(x=sub['ë‚ ì§œ'], y=cusum_vals, mode='lines+markers', name='CUSUM'))
                fig_cusum.add_hline(y=h_threshold, line_dash="dash", line_color="red")
                st.plotly_chart(fig_cusum, use_container_width=True)
                
                if cusum_vals[-1] < h_threshold:
                    st.error(f"âš ï¸ ì„±ê³¼ í•˜ë½ ê°ì§€ (CUSUM: {cusum_vals[-1]:.2f})")
                else:
                    st.success(f"âœ… ì •ìƒ ë²”ìœ„ (CUSUM: {cusum_vals[-1]:.2f})")
        
        # TAB 5: ì˜ˆì‚° ì‹œë®¬ë ˆì´í„° (ì „ë¬¸ê°€ ëª¨ë“œë§Œ)
        if analysis_mode == "ğŸ”¬ ì „ë¬¸ê°€ ëª¨ë“œ":
            with tabs[5]:
                st.markdown("### ğŸ® ì˜ˆì‚° ì‹œë®¬ë ˆì´í„°")
                
                st.error("""
                ğŸš¨ **ì¤‘ìš”: ì´ ì‹œë®¬ë ˆì´í„°ëŠ” ì‹¤ì œ ì˜ˆì‚° ê³„íš ë„êµ¬ê°€ ì•„ë‹™ë‹ˆë‹¤**
                
                **ì™œ ì‹¤ì œ ì˜ì‚¬ê²°ì •ì— ì‚¬ìš©í•˜ë©´ ì•ˆ ë˜ë‚˜ìš”?**
                
                1. **ì„ í˜• ê°€ì •ì˜ í•œê³„**: ì˜ˆì‚° 2ë°° â‰  ë…¸ì¶œ 2ë°° (ê²½ìŸ ì…ì°°, CPC ìƒìŠ¹ ë¯¸ë°˜ì˜)
                2. **CTR ë¶ˆë³€ ê°€ì •**: ë…¸ì¶œ ì¦ê°€ â†’ CTR í•˜ë½ (íƒ€ê²Ÿ í™•ì¥ íš¨ê³¼ ë¯¸ë°˜ì˜)
                3. **ì•Œê³ ë¦¬ì¦˜ í•™ìŠµ ì˜í–¥ ë¬´ì‹œ**: êµ¬ê¸€ ì•Œê³ ë¦¬ì¦˜ ìµœì í™” ê³¼ì • ë¯¸ë°˜ì˜
                
                **ìš©ë„**: "ë§Œì•½ ì´ë ‡ê²Œ í•˜ë©´?" íƒìƒ‰ìš© ì‹œë‚˜ë¦¬ì˜¤ë§Œ ê°€ëŠ¥
                
                **ì‹¤ì œ ì˜ˆì‚° ì¡°ì • ì‹œ:**
                - ì ì§„ì  ì¦ì•¡ í…ŒìŠ¤íŠ¸ (10~20%)
                - 1ì£¼ì¼ ê´€ì°° í›„ ì¶”ê°€ ì¡°ì •
                - A/B í…ŒìŠ¤íŠ¸ë¡œ ì¸ê³¼ íš¨ê³¼ ê²€ì¦
                """)
                
                st.markdown("---")
                total_budget = st.number_input("ì´ ì¼ì˜ˆì‚° (ì›)", min_value=0, value=int(res_agg['avg_cost_7d'].sum()), step=100000)
                
                st.markdown("### ì†Œì¬ë³„ ì˜ˆì‚° ë°°ë¶„")
                allocations = {}
                for _, material in res_agg.iterrows():
                    mat_id = material['ID']
                    current_pct = material['avg_cost_7d'] / res_agg['avg_cost_7d'].sum() * 100 if res_agg['avg_cost_7d'].sum() > 0 else 0
                    allocations[mat_id] = st.slider(f"{mat_id}", 0, 100, int(current_pct), key=f"slider_{mat_id}")
                
                total_pct = sum(allocations.values())
                
                if abs(total_pct - 100) > 1:
                    st.error(f"âš ï¸ ì´ ë°°ë¶„: {total_pct}% (100%ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤)")
                else:
                    st.success(f"âœ… ì´ ë°°ë¶„: {total_pct}%")
                    
                    st.markdown("---")
                    st.markdown("### ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ (ì°¸ê³ ìš©)")
                    
                    sim_results = []
                    for mat_id, pct in allocations.items():
                        material = res_agg[res_agg['ID'] == mat_id].iloc[0]
                        allocated_budget = total_budget * (pct / 100)
                        
                        current_avg_cost = material['avg_cost_7d']
                        if current_avg_cost > 0:
                            scale_factor = allocated_budget / current_avg_cost
                            expected_clicks = material['í´ë¦­'] / 7 * scale_factor
                            expected_impressions = material['ë…¸ì¶œ'] / 7 * scale_factor
                        else:
                            expected_clicks = 0
                            expected_impressions = 0
                        
                        sim_results.append({
                            'ì†Œì¬': mat_id,
                            'ë°°ë¶„(%)': pct,
                            'ë°°ë¶„ê¸ˆì•¡': allocated_budget,
                            'ì˜ˆìƒí´ë¦­': int(expected_clicks),
                            'ì˜ˆìƒë…¸ì¶œ': int(expected_impressions),
                            'CTR': material['exp_ctr'] * 100
                        })
                    
                    sim_df = pd.DataFrame(sim_results)
                    st.dataframe(
                        sim_df.style.format({
                            'ë°°ë¶„(%)': '{:.1f}%',
                            'ë°°ë¶„ê¸ˆì•¡': '{:,.0f}ì›',
                            'ì˜ˆìƒí´ë¦­': '{:,.0f}íšŒ',
                            'ì˜ˆìƒë…¸ì¶œ': '{:,.0f}íšŒ',
                            'CTR': '{:.2f}%'
                        }),
                        use_container_width=True
                    )
                    
                    st.warning("âš ï¸ ìœ„ ìˆ˜ì¹˜ëŠ” ì„ í˜• ê°€ì • ê¸°ë°˜ ì¶”ì •ì¹˜ì´ë©° ì‹¤ì œ ê²°ê³¼ì™€ í¬ê²Œ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # TAB 6: ì£¼ê°„ ë¦¬í¬íŠ¸
        report_tab_idx = 3 if analysis_mode == "ğŸ¯ ì‹¤ë¬´ ëª¨ë“œ" else (1 if analysis_mode == "ğŸ“Š ë³´ê³ ìš© ëª¨ë“œ" else 6)
        
        if analysis_mode != "ğŸ“Š ë³´ê³ ìš© ëª¨ë“œ":
            with tabs[report_tab_idx]:
                st.markdown("### ğŸ“„ ì£¼ê°„ ì„±ê³¼ ë¦¬í¬íŠ¸")
                
                date_range = st.date_input("ë¶„ì„ ê¸°ê°„ ì„ íƒ", value=(df['ë‚ ì§œ'].min().date(), df['ë‚ ì§œ'].max().date()), max_value=df['ë‚ ì§œ'].max().date())
                
                if len(date_range) == 2:
                    start_date, end_date = date_range
                    period_df = df[(df['ë‚ ì§œ'].dt.date >= start_date) & (df['ë‚ ì§œ'].dt.date <= end_date)]
                    
                    if len(period_df) == 0:
                        st.warning("ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.markdown(f"**ë¶„ì„ ê¸°ê°„: {start_date} ~ {end_date} ({(end_date - start_date).days + 1}ì¼)**")
                        st.markdown("---")
                        
                        st.markdown("### âœ¨ í•µì‹¬ ìš”ì•½")
                        col1, col2, col3, col4 = st.columns(4)
                        
                        total_cost = period_df['ë¹„ìš©'].sum()
                        total_clicks = period_df['í´ë¦­'].sum()
                        total_impressions = period_df['ë…¸ì¶œ'].sum()
                        avg_ctr = total_clicks / total_impressions * 100 if total_impressions > 0 else 0
                        avg_cpc = total_cost / total_clicks if total_clicks > 0 else 0
                        
                        col1.metric("ì´ ì§‘í–‰ë¹„", f"{total_cost:,.0f}ì›")
                        col2.metric("ì´ í´ë¦­ìˆ˜", f"{total_clicks:,}íšŒ")
                        col3.metric("í‰ê·  CTR", f"{avg_ctr:.2f}%")
                        col4.metric("í‰ê·  CPC", f"{avg_cpc:,.0f}ì›")
                        
                        st.markdown("---")
                        st.markdown("### ğŸ’° ì˜ˆì‚° ì§‘í–‰ í˜„í™©")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("**ğŸ“± ë§¤ì²´ë³„**")
                            if 'ë§¤ì²´' in period_df.columns:
                                media_summary = period_df.groupby('ë§¤ì²´')['ë¹„ìš©'].sum().sort_values(ascending=False)
                                for media, cost in media_summary.items():
                                    pct = cost / total_cost * 100
                                    st.write(f"â”œâ”€ {media}: {cost:,.0f}ì› ({pct:.1f}%)")
                        
                        with col2:
                            st.markdown("**ğŸ“¦ ìƒí’ˆë³„**")
                            product_summary = period_df.groupby('ìƒí’ˆ')['ë¹„ìš©'].sum().sort_values(ascending=False)
                            for product, cost in product_summary.items():
                                pct = cost / total_cost * 100
                                st.write(f"â”œâ”€ {product}: {cost:,.0f}ì› ({pct:.1f}%)")
                        
                        st.markdown("**ğŸ¨ ì†Œì¬ë³„**")
                        material_summary = period_df.groupby('ID')['ë¹„ìš©'].sum().sort_values(ascending=False)
                        for mat_id, cost in material_summary.items():
                            pct = cost / total_cost * 100
                            st.write(f"â”œâ”€ {mat_id}: {cost:,.0f}ì› ({pct:.1f}%)")
                        
                        st.markdown("---")
                        st.markdown("### ğŸ† ì„±ê³¼ ë¶„ì„")
                        
                        col1, col2 = st.columns(2)
                        
                        material_perf = period_df.groupby('ID').agg({'í´ë¦­': 'sum', 'ë…¸ì¶œ': 'sum', 'ë¹„ìš©': 'sum'})
                        material_perf['CTR'] = material_perf['í´ë¦­'] / material_perf['ë…¸ì¶œ'] * 100
                        material_perf['CPC'] = material_perf['ë¹„ìš©'] / material_perf['í´ë¦­']
                        
                        with col1:
                            st.markdown("**ğŸ¥‡ ë² ìŠ¤íŠ¸ ì†Œì¬ (CTR ê¸°ì¤€)**")
                            best = material_perf.nlargest(1, 'CTR').iloc[0]
                            st.success(f"""
                            **{material_perf.nlargest(1, 'CTR').index[0]}**
                            - CTR: {best['CTR']:.2f}%
                            - ì´ í´ë¦­: {int(best['í´ë¦­']):,}íšŒ
                            - ì´ ë¹„ìš©: {int(best['ë¹„ìš©']):,}ì›
                            """)
                        
                        with col2:
                            st.markdown("**âš ï¸ ê°œì„  ê²€í†  ì†Œì¬ (CTR ê¸°ì¤€)**")
                            worst = material_perf.nsmallest(1, 'CTR').iloc[0]
                            st.warning(f"""
                            **{material_perf.nsmallest(1, 'CTR').index[0]}**
                            - CTR: {worst['CTR']:.2f}%
                            - ì´ í´ë¦­: {int(worst['í´ë¦­']):,}íšŒ
                            - ì´ ë¹„ìš©: {int(worst['ë¹„ìš©']):,}ì›
                            """)
    else:
        st.warning("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    st.info("ğŸ‘† ìƒë‹¨ì—ì„œ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")