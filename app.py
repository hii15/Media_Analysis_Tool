import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
from scipy.stats import beta
from statsmodels.tsa.seasonal import seasonal_decompose

# --- [0. ì‹œìŠ¤í…œ ê¸°ë³¸ ì„¤ì •] ---
st.set_page_config(page_title="Ad Intelligence System v36.1", layout="wide")

st.title("ðŸ›¡ï¸ ë§¤ì²´ ë¼ì´ë¸Œ ê´€ë ¨ ì˜ì‚¬ê²°ì • ë³´ì¡° ë„êµ¬")
st.markdown("---")

# --- [1. ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ë ˆì´ì–´] ---
def load_and_clean_data(uploaded_file):
    """
    ë°ì´í„° ë¡œë“œ ë° ì •ì œ: CTRì€ ë¶„ëª¨/ë¶„ìžë¥¼ ë³´ì¡´í•œ ìƒíƒœì—ì„œ ê³„ì‚°í•˜ì—¬ í†µê³„ì  ì™œê³¡ì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    try:
        if uploaded_file.name.endswith('.xlsx'):
            all_sheets = pd.read_excel(uploaded_file, sheet_name=None)
            df = pd.concat(all_sheets.values(), ignore_index=True)
        else:
            df = pd.read_csv(uploaded_file)
        
        df.columns = [c.strip() for c in df.columns]
        mapping = {
            'ë‚ ì§œ': ['ë‚ ì§œ', 'ì¼ìž'], 'ìƒí’ˆ': ['ìƒí’ˆëª…', 'ìƒí’ˆ'], 'ì†Œìž¬': ['ì†Œìž¬ëª…', 'ì†Œìž¬'],
            'ë…¸ì¶œ': ['ë…¸ì¶œìˆ˜', 'ë…¸ì¶œ'], 'í´ë¦­': ['í´ë¦­ìˆ˜', 'í´ë¦­'], 'ì¡°íšŒ': ['ì¡°íšŒìˆ˜', 'ì¡°íšŒ'], 'ë¹„ìš©': ['ë¹„ìš©', 'ì§€ì¶œ']
        }
        
        final_df = pd.DataFrame()
        for k, v in mapping.items():
            for col in v:
                if col in df.columns: final_df[k] = df[col]; break
        
        final_df['ë‚ ì§œ'] = pd.to_datetime(final_df['ë‚ ì§œ'], errors='coerce')
        for col in ['ë…¸ì¶œ', 'í´ë¦­', 'ì¡°íšŒ', 'ë¹„ìš©']:
            final_df[col] = pd.to_numeric(final_df[col].astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce').fillna(0)
        
        final_df['CTR(%)'] = (final_df['í´ë¦­'] / (final_df['ë…¸ì¶œ'] + 1e-9) * 100)
        final_df['ID'] = "[" + final_df['ìƒí’ˆ'].astype(str).str.upper() + "] " + final_df['ì†Œìž¬'].astype(str)
        return final_df.dropna(subset=['ë‚ ì§œ']).sort_values(['ID', 'ë‚ ì§œ'])
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}"); return pd.DataFrame()

# --- [2. í†µê³„ ì—”ì§„ í•¨ìˆ˜ ì •ì˜] ---
def analyze_empirical_bayes(df):
    """
    Empirical Bayes ë³´ì • ì•Œê³ ë¦¬ì¦˜: ì†Œí‘œë³¸ ë°ì´í„°ì˜ CTR ë³€ë™ì„±ì„ ì™„í™”í•©ë‹ˆë‹¤.
    """
    global_ctr = df['í´ë¦­'].sum() / (df['ë…¸ì¶œ'].sum() + 1e-9)
    # ë¹„ìš©ì€ ì „ì²´ ê¸°ì—¬ë„ íŒŒì•…ì„ ìœ„í•´ sumìœ¼ë¡œ ì§‘ê³„
    id_stats = df.groupby('ID').agg({'í´ë¦­': 'sum', 'ë…¸ì¶œ': 'sum', 'ë¹„ìš©': 'sum'})
    id_ctrs = id_stats['í´ë¦­'] / (id_stats['ë…¸ì¶œ'] + 1e-9)
    var_ctr = max(id_ctrs.var(), 1e-7)
    
    # Kappa(ì‹ ë¢°ë„) ìƒí•œì„ ì„ ë…¸ì¶œìˆ˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ì œí•œí•˜ì—¬ ë°©ì–´ì  ì„¤ê³„ ì ìš©
    kappa = (global_ctr * (1 - global_ctr) / var_ctr) - 1
    kappa = np.clip(kappa, 10, min(1000, df.groupby('ID')['ë…¸ì¶œ'].median()))
    
    alpha_0, beta_0 = global_ctr * kappa, (1 - global_ctr) * kappa
    agg = id_stats.reset_index()
    agg['post_alpha'] = alpha_0 + agg['í´ë¦­']
    agg['post_beta'] = beta_0 + (agg['ë…¸ì¶œ'] - agg['í´ë¦­'])
    agg['exp_ctr'] = agg['post_alpha'] / (agg['post_alpha'] + agg['post_beta'])
    
    # Thompson Sampling: ìš°ìˆ˜ ì†Œìž¬ í™•ë¥ 
    samples = np.random.beta(agg['post_alpha'].values[:, None], 
                             agg['post_beta'].values[:, None], size=(len(agg), 5000))
    agg['prob_is_best'] = np.bincount(np.argmax(samples, axis=0), minlength=len(agg)) / 5000
    
    # ìµœê·¼ 7ì¼ í‰ê·  ë¹„ìš© (ìš´ì˜ ê¸°ì¤€ê°’)
    max_date = df['ë‚ ì§œ'].max()
    last_costs = df[df['ë‚ ì§œ'] >= max_date - timedelta(days=7)].groupby('ID')['ë¹„ìš©'].mean()
    agg = agg.merge(last_costs.rename('avg_cost_7d'), on='ID', how='left').fillna(0)
    return agg, (alpha_0, beta_0, kappa)

def get_binomial_cusum(clicks, imps, p0, p1_ratio=0.85):
    p1 = np.clip(p0 * p1_ratio, 1e-6, 1-1e-6)
    p0 = np.clip(p0, 1e-6, 1-1e-6)
    llr = clicks * np.log(p1/p0) + (imps - clicks) * np.log((1-p1)/(1-p0))
    s = 0
    cusum = []
    for val in llr:
        s = min(0, s + val)
        cusum.append(s)
    return np.array(cusum)

@st.cache_data
def estimate_h_arl(p0, imps_series, target_arl=30, sims=500):
    p1 = np.clip(p0 * 0.85, 1e-6, 1-1e-6)
    p0 = np.clip(p0, 1e-6, 1-1e-6)
    llr_s, llr_f = np.log(p1/p0), np.log((1-p1)/(1-p0))
    for h in np.arange(2.0, 15.0, 1.0):
        rls = []
        for _ in range(sims):
            s, t = 0, 0
            while t < 100:
                t += 1
                n = np.random.choice(imps_series)
                c = np.random.binomial(int(n), p0)
                s = min(0, s + (c * llr_s + (int(n) - c) * llr_f))
                if s < -h: break
            rls.append(t)
        if np.mean(rls) >= target_arl: return h
    return 5.0

# --- [3. ë©”ì¸ UI ë° íƒ­ë³„ ë¡œì§] ---
uploaded_file = st.file_uploader("ìº íŽ˜ì¸ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['csv', 'xlsx'])

if uploaded_file:
    df = load_and_clean_data(uploaded_file)
    if not df.empty:
        res_agg, (a0, b0, k_est) = analyze_empirical_bayes(df)
        ids = sorted(df['ID'].unique())
        
        tabs = st.tabs(["ðŸ“Š í†µí•© ëŒ€ì‹œë³´ë“œ", "ðŸ§¬ í†µê³„ì  ì‹ ë¢°ë„ ë¶„ì„", "ðŸ“‰ ì¶”ì„¸ ë° í•˜ë½ ê°ì§€", "ðŸŽ¯ ì˜ˆì‚° íš¨ìœ¨ ê³¡ì„ "])

        with tabs[0]:
            st.markdown("### ðŸ“Š í†µí•© ëŒ€ì‹œë³´ë“œ")
            st.caption("ë¹„ì¤‘ì€ ëˆ„ì  ê¸°ì—¬ë„(Sum)ë¡œ, ê¸°ëŒ€ CTRì€ ë³´ì •ëœ ì‹¤ë ¥ì¹˜(EB)ë¡œ íŒŒì•…í•©ë‹ˆë‹¤.")
            col1, col2 = st.columns(2)
            metric = col1.selectbox("ë¹„ì¤‘ ë¶„ì„ ì§€í‘œ", ["ë¹„ìš©", "ë…¸ì¶œ", "í´ë¦­"])
            col1.plotly_chart(px.pie(df.groupby('ID')[metric].sum().reset_index(), values=metric, names='ID', hole=0.4), use_container_width=True)
            col2.plotly_chart(px.bar(res_agg, x='ID', y='exp_ctr', title="í†µê³„ ë³´ì •ëœ ê¸°ëŒ€ CTR (%)"), use_container_width=True)

        with tabs[1]:
            st.markdown("### ðŸ§¬ ë¶„ì„ ë°©ë²•ë¡ : Empirical Bayes (ìˆ˜ì¹˜ ë³´ì • ì•Œê³ ë¦¬ì¦˜)")
            st.write("""
            **ì™œ ì´ ë¶„ì„ì´ í•„ìš”í•œê°€ìš”?** ë…¸ì¶œìˆ˜ê°€ ì ì€ ì´ˆê¸° ì†Œìž¬ëŠ” ë‹¨ ëª‡ ë²ˆì˜ í´ë¦­ë§Œìœ¼ë¡œë„ CTRì´ 0%ê°€ ë˜ê±°ë‚˜ ë§¤ìš° ë†’ê²Œ ë‚˜ì˜¤ëŠ” ë“± ìˆ˜ì¹˜ê°€ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤.
            
            **ì–´ë–»ê²Œ í•´ê²°í•˜ë‚˜ìš”?** **Empirical Bayes** ê¸°ë²•ì€ ë°ì´í„° ì „ì²´ì˜ í‰ê· ì„ ì‚¬ì „ ì •ë³´ë¡œ í™œìš©í•©ë‹ˆë‹¤. ë…¸ì¶œì´ ì ì€ ì†Œìž¬ëŠ” ì „ì²´ í‰ê·  ìª½ìœ¼ë¡œ ë³´ì •(Shrinkage)í•˜ê³ , 
            ë…¸ì¶œì´ ì¶©ë¶„ížˆ ìŒ“ì¸ ì†Œìž¬ëŠ” ì‹¤ì œ ìˆ˜ì¹˜ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤. ì‹ ë¢°ë„ ì§€ìˆ˜($\kappa$)ëŠ” ë°ì´í„° ê·œëª¨ì— ì˜í•´ ìƒí•œì´ ì œí•œë˜ë„ë¡ ì„¤ê³„ë˜ì–´ ê³¼ë„í•œ í™•ì‹ ì„ ë°©ì§€í•©ë‹ˆë‹¤.
            """)
            st.info(f"ë°ì´í„° ê¸°ë°˜ ì¶”ì • ì‚¬ì „ ì‹ ë¢°ë„(Îº): {k_est:.2f}")
            fig_post = go.Figure()
            for _, row in res_agg.iterrows():
                samples = np.random.beta(row['post_alpha'], row['post_beta'], 3000)
                fig_post.add_trace(go.Box(x=samples, name=row['ID'], boxpoints=False))
            fig_post.update_layout(title="ì†Œìž¬ë³„ ì„±ê³¼ ì‹ ë¢° êµ¬ê°„", xaxis_title="ê¸°ëŒ€ CTR ë²”ìœ„")
            st.plotly_chart(fig_post, use_container_width=True)

        with tabs[2]:
            st.markdown("### ðŸ“‰ ë¶„ì„ ë°©ë²•ë¡ : ì‹œê³„ì—´ ë¶„í•´ ë° CUSUM í•˜ë½ ê°ì§€")
            st.write("""
            **ë™ì  ê¸°ì¤€ì (p0) ì„¤ì • ë¡œì§:** ë°ì´í„° ê¸°ê°„ì— ë”°ë¼ ê¸°ì¤€ì ì„ ìœ ì—°í•˜ê²Œ ê²°ì •í•©ë‹ˆë‹¤. 
            - **14ì¼ ì´í•˜**: ì¼ë³„ ë³€ë™ì„±ì´ í¬ë¯€ë¡œ, EB ê¸°ë²•ìœ¼ë¡œ ë³´ì •ëœ **'í†µê³„ì  ê¸°ëŒ€ ì‹¤ë ¥ì¹˜'**ë¥¼ ê¸°ì¤€ì ìœ¼ë¡œ ì‚¼ì•„ ë¦¬ìŠ¤í¬ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
            - **28ì¼ ì´ìƒ**: ìµœê·¼ 14ì¼ì„ ì œì™¸í•œ **'ê³¼ê±° ì•ˆì • êµ¬ê°„ì˜ í‰ê· '**ì„ ê¸°ì¤€ì ìœ¼ë¡œ ì‚¼ì•„ í˜„ìž¬ì˜ í•˜ë½ ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
            """)
            
            t_id = st.selectbox("ë¶„ì„ ëŒ€ìƒ ì†Œìž¬ ì„ íƒ", ids)
            sub = df[df['ID'] == t_id].sort_values('ë‚ ì§œ')
            exp_ctr = res_agg[res_agg['ID'] == t_id]['exp_ctr'].values[0]
            
            # ë°ì´í„° ê¸¸ì´ì— ë”°ë¥¸ p0 ì„¤ì • ì „ëžµ
            if len(sub) >= 28:
                stable_period = sub[sub['ë‚ ì§œ'] < (sub['ë‚ ì§œ'].max() - timedelta(days=14))]
                p0_val = stable_period['í´ë¦­'].sum() / (stable_period['ë…¸ì¶œ'].sum() + 1e-9)
                strategy_txt = "ê³¼ê±° ì•ˆì • êµ¬ê°„ ê¸°ì¤€"
            else:
                p0_val = exp_ctr # ë°ì´í„°ê°€ ì ì„ ë• ë³´ì •ëœ ì‹¤ë ¥ì¹˜ ì‚¬ìš©
                strategy_txt = "í†µê³„ì  ë³´ì • í‰ê·  ê¸°ì¤€"
            
            st.caption(f"í˜„ìž¬ ì„ íƒëœ ê¸°ì¤€ì  ì„¤ì • ë°©ì‹: **{strategy_txt}** (p0 = {p0_val:.4f})")
            
            # CUSUM ì‹œê°í™”
            h_opt = estimate_h_arl(p0_val, sub['ë…¸ì¶œ'].values)
            cusum_v = get_binomial_cusum(sub['í´ë¦­'].values, sub['ë…¸ì¶œ'].values, p0_val)
            fig_cusum = go.Figure()
            fig_cusum.add_trace(go.Scatter(x=sub['ë‚ ì§œ'], y=cusum_v, name="í•˜ë½ ì‹ í˜¸ ëˆ„ì ì¹˜", fill='tozeroy', line_color='red'))
            fig_cusum.add_hline(y=-h_opt, line_dash="dash", line_color="black", annotation_text="í•˜ë½ ê²½ê³„ì„ ")
            fig_cusum.update_layout(title=f"ì†Œìž¬ ì„±ê³¼ ë“œë¦¬í”„íŠ¸ íƒì§€ (ê¸°ì¤€: {strategy_txt})")
            st.plotly_chart(fig_cusum, use_container_width=True)

        with tabs[3]:
            st.markdown("### ðŸŽ¯ ë¶„ì„ ë°©ë²•ë¡ : ì˜ˆì‚° íš¨ìœ¨ ë° ì‹¤í—˜ì  ìµœì í™”")
            st.write("""
            **ë¹„ìš© íƒ„ë ¥ì„± ë¶„ì„:** ì§‘í–‰ ê·œëª¨(ìµœê·¼ 7ì¼ í‰ê· ) ëŒ€ë¹„ ìœ ìž… íš¨ìœ¨(CTR)ì˜ ë¶„í¬ë¥¼ íŒŒì•…í•˜ì—¬ í•œê³„ íš¨ìœ¨ ì§€ì ì„ íƒìƒ‰í•©ë‹ˆë‹¤.
            
            **ì£¼ì˜ì‚¬í•­:** ë³¸ ì˜ˆì‚° ì œì•ˆì€ **ë¹„ìš© ëŒ€ë¹„ ìœ ìž… íš¨ìœ¨**ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚°ì¶œëœ ì‹¤í—˜ì  ì§€í‘œìž…ë‹ˆë‹¤. ì‹¤ì œ ìš´ì˜ ì‹œì—ëŠ” ì†Œìž¬ì˜ ì •ì„±ì  ê°€ì¹˜ë¥¼ ë°˜ë“œì‹œ ë³‘í–‰ ê²€í† í•´ì•¼ í•˜ë©°, ë³¸ ì‹œìŠ¤í…œì€ ìžë™ ì§‘í–‰ì„ ì „ì œë¡œ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            """)
            fig_scatter = px.scatter(res_agg, x='avg_cost_7d', y='exp_ctr', size='ë…¸ì¶œ', color='ID',
                                     labels={'avg_cost_7d': 'ìµœê·¼ 7ì¼ í‰ê·  ë¹„ìš©', 'exp_ctr': 'ê¸°ëŒ€ CTR'},
                                     title="ë¹„ìš© íš¨ìœ¨ í”„ë¡ í‹°ì–´ (ìš°ìƒë‹¨ ì†Œìž¬ê°€ ê³ íš¨ìœ¨)")
            st.plotly_chart(fig_scatter, use_container_width=True)
            
            if st.button("ì‹¤í—˜ì  ì˜ˆì‚° ë°°ë¶„ ì •ì±… ì‹¤í–‰"):
                # ì˜ˆì‚° ëŒ€ë¹„ íš¨ìœ¨(Efficiency) ìŠ¤ì½”ì–´ ê³„ì‚°
                res_agg['score'] = res_agg['exp_ctr'] / (res_agg['avg_cost_7d'] + 1e-9)
                avg_s = res_agg['score'].mean() + 1e-9
                res_agg['proposed'] = res_agg['avg_cost_7d'] * (res_agg['score'] / avg_s)
                res_agg['ìµœì¢…ì œì•ˆì•¡'] = res_agg.apply(lambda r: np.clip(r['proposed'], r['avg_cost_7d']*0.7, r['avg_cost_7d']*1.3), axis=1)
                st.table(res_agg[['ID', 'exp_ctr', 'ìµœì¢…ì œì•ˆì•¡']].style.format({'exp_ctr': '{:.4f}', 'ìµœì¢…ì œì•ˆì•¡': '{:,.0f}'}))