import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import re

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="In-house Marketing BI", layout="wide")

# --- [ì‚¬ì´ë“œë°”] ì„¤ì • ë° ë°ì´í„° ê´€ë¦¬ ---
with st.sidebar:
    st.header("ğŸ’¾ ë°ì´í„° ë° ë¶„ì„ ì„¤ì •")
    # ì†Œì¬ë³„ ìë™ ì±„ìš°ê¸° ëª¨ë“œ (ë§¤ì²´+ìƒí’ˆ+ì†Œì¬ ê¸°ì¤€)
    auto_date_mode = st.checkbox("ğŸ“… ì†Œì¬ë³„ ë‚ ì§œ ìë™ ì±„ìš°ê¸°", value=True)
    
    st.divider()
    
    # 1. íŒŒì¼ ì—…ë¡œë“œ ë¡œì§ (ì •í™•í•œ ë“¤ì—¬ì“°ê¸° ì ìš©)
    uploaded_file = st.file_uploader("ğŸ“‚ ì €ì¥ëœ CSV ë¶ˆëŸ¬ì˜¤ê¸°", type=["csv"])
    if uploaded_file is not None:
        try:
            input_df = pd.read_csv(uploaded_file)
            input_df['ë‚ ì§œ'] = pd.to_datetime(input_df['ë‚ ì§œ'], errors='coerce').dt.date
            
            required_cols = ["ë‚ ì§œ", "ë§¤ì²´", "ìƒí’ˆëª…", "ì†Œì¬ëª…", "ë…¸ì¶œìˆ˜", "í´ë¦­ìˆ˜", "ë¹„ìš©"]
            if all(col in input_df.columns for col in required_cols):
                if st.button("ğŸ“¥ ë°ì´í„° ì ìš©í•˜ê¸°"):
                    st.session_state.db = input_df
                    st.success("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
                    st.rerun()
            else:
                st.error("CSV í˜•ì‹ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

    st.divider()
    n_iterations = st.select_slider("ì‹œë®¬ë ˆì´ì…˜ ë°˜ë³µ íšŸìˆ˜", options=[1000, 5000, 10000], value=5000)

st.title("ğŸ¯ ë°ì´í„° ê¸°ë°˜ ë§ˆì¼€íŒ… ë¶„ì„íˆ´")

# --- [ìœ í‹¸ë¦¬í‹°] ê°•ë ¥í•œ ë°ì´í„° ì •ì œ í•¨ìˆ˜ ---
def clean_and_process(df_list, auto_date):
    combined = pd.concat(df_list, ignore_index=True)
    if combined.empty:
        return combined
    
    final_chunks = []
    # ë§¤ì²´, ìƒí’ˆëª…, ì†Œì¬ëª…ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ ë‚ ì§œ ì²˜ë¦¬
    for keys, group in combined.groupby(['ë§¤ì²´', 'ìƒí’ˆëª…', 'ì†Œì¬ëª…']):
        group = group.reset_index(drop=True)
        
        # ë‚ ì§œ ìë™ ì™„ì„±
        if auto_date and not group.empty:
            start_date = pd.to_datetime(group.loc[0, 'ë‚ ì§œ'], errors='coerce')
            if pd.notnull(start_date):
                group['ë‚ ì§œ'] = [start_date + timedelta(days=i) for i in range(len(group))]
        else:
            group['ë‚ ì§œ'] = pd.to_datetime(group['ë‚ ì§œ'], errors='coerce')
        
        final_chunks.append(group)
    
    df = pd.concat(final_chunks, ignore_index=True)
    df = df.dropna(subset=['ë‚ ì§œ'])
    
    # [í•µì‹¬] ì›í™” ê¸°í˜¸, ì½¤ë§ˆ ë“± ëª¨ë“  íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ìˆ«ìë¡œ ë³€í™˜
    for col in ['ë…¸ì¶œìˆ˜', 'í´ë¦­ìˆ˜', 'ë¹„ìš©']:
        # ìˆ«ìì™€ ë§ˆì¹¨í‘œ(.)ë¥¼ ì œì™¸í•œ ëª¨ë“  ë¬¸ì ì œê±° ë¡œì§
        df[col] = df[col].astype(str).str.replace(r'[^\d.]', '', regex=True)
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
    
    df['CTR(%)'] = (df['í´ë¦­ìˆ˜'] / df['ë…¸ì¶œìˆ˜'] * 100).round(2).fillna(0.0)
    df['ID'] = "[" + df['ë§¤ì²´'].astype(str) + "] " + df['ìƒí’ˆëª…'].astype(str) + "_" + df['ì†Œì¬ëª…'].astype(str)
    return df

# --- [ë¶„ì„] ë² ì´ì§€ì•ˆ ì—°ì‚° ---
def run_analysis(df, item_a, item_b, iterations):
    res = df.groupby('ID').agg({'í´ë¦­ìˆ˜':'sum', 'ë…¸ì¶œìˆ˜':'sum'})
    a, b = res.loc[item_a], res.loc[item_b]
    samples_a = np.random.beta(max(a['í´ë¦­ìˆ˜'], 0)+1, max(a['ë…¸ì¶œìˆ˜']-a['í´ë¦­ìˆ˜'], 0)+1, iterations)
    samples_b = np.random.beta(max(b['í´ë¦­ìˆ˜'], 0)+1, max(b['ë…¸ì¶œìˆ˜']-b['í´ë¦­ìˆ˜'], 0)+1, iterations)
    return (samples_a > samples_b).mean(), samples_a, samples_b

# --- [ë°ì´í„°] ì„¸ì…˜ ê´€ë¦¬ ë° ì…ë ¥ë¶€ ---
if 'db' not in st.session_state:
    st.session_state.db = pd.DataFrame([{
        "ë‚ ì§œ": datetime.now().date(), "ë§¤ì²´": "ë„¤ì´ë²„", "ìƒí’ˆëª…": "", 
        "ì†Œì¬ëª…": "", "ë…¸ì¶œìˆ˜": "0", "í´ë¦­ìˆ˜": "0", "ë¹„ìš©": "0"
    }])

media_list = ["ë„¤ì´ë²„", "ì¹´ì¹´ì˜¤", "êµ¬ê¸€", "ë©”íƒ€", "ìœ íŠœë¸Œ", "SOOP", "ë””ì‹œì¸ì‚¬ì´ë“œ", "ì¸ë²¤", "ë£¨ë¦¬ì›¹"]
tabs = st.tabs(media_list)
all_edited_data = []

for i, m in enumerate(media_list):
    with tabs[i]:
        curr_df = st.session_state.db[st.session_state.db['ë§¤ì²´'] == m].copy()
        if curr_df.empty:
            curr_df = pd.DataFrame([{"ë‚ ì§œ": datetime.now().date(), "ë§¤ì²´": m, "ìƒí’ˆëª…": "", "ì†Œì¬ëª…": "", "ë…¸ì¶œìˆ˜": "0", "í´ë¦­ìˆ˜": "0", "ë¹„ìš©": "0"}])
        
        # ì—‘ì…€ ë³µë¶™ ì‹œ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ëª¨ë‘ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬
        curr_df['ë‚ ì§œ'] = pd.to_datetime(curr_df['ë‚ ì§œ'], errors='coerce').dt.date

        edited = st.data_editor(
            curr_df,
            num_rows="dynamic",
            use_container_width=True,
            key=f"editor_tab_{m}",
            column_config={
                "ë‚ ì§œ": st.column_config.DateColumn("ì‹œì‘ì¼(ì†Œì¬ë‹¨ìœ„ ì²«ì¤„)"),
                "ë¹„ìš©": st.column_config.TextColumn("ë¹„ìš©(â‚©)"),
                "ë…¸ì¶œìˆ˜": st.column_config.TextColumn("ë…¸ì¶œìˆ˜"),
                "í´ë¦­ìˆ˜": st.column_config.TextColumn("í´ë¦­ìˆ˜")
            }
        )
        all_edited_data.append(edited)

# --- [ì‹¤í–‰ ë²„íŠ¼] ---
if st.button("ğŸš€ ë°ì´í„° ì €ì¥ ë° ì†Œì¬ë³„ ë¶„ì„ ì‹¤í–‰", use_container_width=True):
    try:
        # ë°ì´í„° ì •ì œ ë° ë‚ ì§œ ì±„ìš°ê¸° ìˆ˜í–‰
        st.session_state.db = clean_and_process(all_edited_data, auto_date_mode)
        st.success("ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()
    except Exception as e:
        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- [ë¦¬í¬íŠ¸] ì‹œê°í™” ---
final_df = st.session_state.db
if not final_df.empty and 'ID' in final_df.columns and len(final_df['ID'].unique()) >= 2:
    st.divider()
    p_list = sorted(final_df['ID'].unique())
    c1, c2 = st.columns(2)
    with c1: 
        item_a = st.selectbox("ê¸°ì¤€ ìƒí’ˆ(A)", p_list, index=0)
    with c2: 
        item_b = st.selectbox("ë¹„êµ ëŒ€ìƒ(B)", p_list, index=1)
    
    try:
        prob, s_a, s_b = run_analysis(final_df, item_a, item_b, n_iterations)
        
        m1, m2 = st.columns(2)
        m1.metric(f"{item_b} ìŠ¹ë¦¬ í™•ë¥ ", f"{prob*100:.1f}%")
        
        fig = go.Figure()
        fig.add_trace(go.Histogram(x=s_a, name=item_a, opacity=0.6))
        fig.add_trace(go.Histogram(x=s_b, name=item_b, opacity=0.6))
        fig.update_layout(barmode='overlay', title="ì†Œì¬ë³„ CTR ì„±ê³¼ ë¶„í¬ ë¹„êµ")
        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„ì„ ì‹œê°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì—ëŸ¬: {e})")