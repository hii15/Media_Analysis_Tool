import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
from scipy.stats import beta

# --- ì„¤ì • ---
st.set_page_config(page_title="Ad Analytics System v2", layout="wide")
st.title("ğŸ¯ ê´‘ê³  ë§¤ì²´ í†µê³„ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("**Empirical Bayes & CUSUM ê¸°ë°˜ ì†Œì¬ ì„±ê³¼ ë¶„ì„**")
st.markdown("---")

# --- ë°ì´í„° ë¡œë“œ ---
def load_and_clean_data(uploaded_file):
    try:
        if uploaded_file.name.endswith('.xlsx'):
            all_sheets = pd.read_excel(uploaded_file, sheet_name=None)
            df = pd.concat(all_sheets.values(), ignore_index=True)
        else:
            df = pd.read_csv(uploaded_file, sep='\t' if uploaded_file.name.endswith('.tsv') else ',')
        
        df.columns = [c.strip() for c in df.columns]
        mapping = {
            'ë‚ ì§œ': ['ë‚ ì§œ', 'ì¼ì', 'date'], 
            'ìƒí’ˆ': ['ìƒí’ˆëª…', 'ìƒí’ˆ', 'product'], 
            'ì†Œì¬': ['ì†Œì¬ëª…', 'ì†Œì¬', 'material'],
            'ë…¸ì¶œ': ['ë…¸ì¶œìˆ˜', 'ë…¸ì¶œ', 'impressions'], 
            'í´ë¦­': ['í´ë¦­ìˆ˜', 'í´ë¦­', 'clicks'], 
            'ë¹„ìš©': ['ë¹„ìš©', 'ì§€ì¶œ', 'cost']
        }
        
        final_df = pd.DataFrame()
        for k, v in mapping.items():
            for col in v:
                if col in df.columns: 
                    final_df[k] = df[col]
                    break
        
        final_df['ë‚ ì§œ'] = pd.to_datetime(final_df['ë‚ ì§œ'], errors='coerce')
        for col in ['ë…¸ì¶œ', 'í´ë¦­', 'ë¹„ìš©']:
            final_df[col] = pd.to_numeric(
                final_df[col].astype(str).str.replace(r'[^\d.]', '', regex=True), 
                errors='coerce'
            ).fillna(0)
        
        final_df['CTR(%)'] = (final_df['í´ë¦­'] / (final_df['ë…¸ì¶œ'] + 1e-9) * 100)
        final_df['CPC'] = final_df['ë¹„ìš©'] / (final_df['í´ë¦­'] + 1e-9)
        final_df['ID'] = "[" + final_df['ìƒí’ˆ'].astype(str) + "] " + final_df['ì†Œì¬'].astype(str)
        
        return final_df.dropna(subset=['ë‚ ì§œ']).sort_values(['ID', 'ë‚ ì§œ'])
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

# --- Empirical Bayes ë¶„ì„ ---
def analyze_empirical_bayes(df):
    global_ctr = df['í´ë¦­'].sum() / (df['ë…¸ì¶œ'].sum() + 1e-9)
    id_stats = df.groupby('ID').agg({'í´ë¦­': 'sum', 'ë…¸ì¶œ': 'sum', 'ë¹„ìš©': 'sum'})
    id_ctrs = id_stats['í´ë¦­'] / (id_stats['ë…¸ì¶œ'] + 1e-9)
    var_ctr = max(id_ctrs.var(), 1e-7)
    
    kappa = (global_ctr * (1 - global_ctr) / var_ctr) - 1
    kappa = np.clip(kappa, 10, 1000)
    
    alpha_0, beta_0 = global_ctr * kappa, (1 - global_ctr) * kappa
    
    agg = id_stats.reset_index()
    agg['post_alpha'] = alpha_0 + agg['í´ë¦­']
    agg['post_beta'] = beta_0 + (agg['ë…¸ì¶œ'] - agg['í´ë¦­'])
    agg['exp_ctr'] = agg['post_alpha'] / (agg['post_alpha'] + agg['post_beta'])
    agg['raw_ctr'] = agg['í´ë¦­'] / (agg['ë…¸ì¶œ'] + 1e-9)
    
    # ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
    samples = np.random.beta(
        agg['post_alpha'].values[:, None], 
        agg['post_beta'].values[:, None], 
        size=(len(agg), 5000)
    )
    agg['prob_is_best'] = np.bincount(
        np.argmax(samples, axis=0), 
        minlength=len(agg)
    ) / 5000
    
    # ìµœê·¼ 7ì¼ í‰ê·  ë¹„ìš©
    max_date = df['ë‚ ì§œ'].max()
    last_costs = df[df['ë‚ ì§œ'] >= max_date - timedelta(days=7)].groupby('ID')['ë¹„ìš©'].mean()
    agg = agg.merge(last_costs.rename('avg_cost_7d'), on='ID', how='left').fillna(0)
    
    return agg, (alpha_0, beta_0, kappa, global_ctr)

# --- CUSUM ë¶„ì„ ---
def get_binomial_cusum(clicks, imps, p0):
    p1 = np.clip(p0 * 0.85, 1e-6, 1-1e-6)
    p0 = np.clip(p0, 1e-6, 1-1e-6)
    llr = clicks * np.log(p1/p0) + (imps - clicks) * np.log((1-p1)/(1-p0))
    s = 0
    cusum = []
    for val in llr:
        s = min(0, s + val)
        cusum.append(s)
    return np.array(cusum)

@st.cache_data
def estimate_h_via_arl(p0, imps_series, target_arl=30, sims=1000):
    """
    ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ëª©í‘œ ARLì„ ë‹¬ì„±í•˜ëŠ” h ì¶”ì •
    
    Parameters:
    - p0: ê¸°ì¤€ CTR (ì •ìƒ ìƒíƒœ)
    - imps_series: ë…¸ì¶œìˆ˜ ìƒ˜í”Œ (ì‹¤ì œ ë°ì´í„°ì—ì„œ ì¶”ì¶œ)
    - target_arl: ëª©í‘œ í‰ê·  ëŸ° ê¸¸ì´ (ì¼)
    - sims: ì‹œë®¬ë ˆì´ì…˜ ë°˜ë³µ íšŸìˆ˜
    
    Returns:
    - h: ì„ê³„ê°’
    - actual_arl: ì‹¤ì œ ë‹¬ì„±ëœ ARL
    """
    p1 = np.clip(p0 * 0.85, 1e-6, 1-1e-6)
    p0_clip = np.clip(p0, 1e-6, 1-1e-6)
    llr_success = np.log(p1 / p0_clip)
    llr_failure = np.log((1 - p1) / (1 - p0_clip))
    
    # h í›„ë³´ ë²”ìœ„ë¥¼ ë™ì ìœ¼ë¡œ ì„¤ì •
    h_candidates = np.arange(1.0, 30.0, 0.5)
    
    for h in h_candidates:
        run_lengths = []
        
        for _ in range(sims):
            s = 0
            t = 0
            max_iter = 500  # ì¶©ë¶„íˆ ê¸´ ì‹œë®¬ë ˆì´ì…˜
            
            while t < max_iter:
                t += 1
                # ì‹¤ì œ ë…¸ì¶œ ë¶„í¬ì—ì„œ ìƒ˜í”Œë§
                n = np.random.choice(imps_series) if len(imps_series) > 0 else 100000
                c = np.random.binomial(int(n), p0_clip)
                
                # CUSUM ì—…ë°ì´íŠ¸
                s = min(0, s + (c * llr_success + (int(n) - c) * llr_failure))
                
                if s < -h:
                    break
            
            run_lengths.append(t)
        
        actual_arl = np.mean(run_lengths)
        
        # ëª©í‘œ ARLì— ë„ë‹¬í•˜ë©´ ë°˜í™˜
        if actual_arl >= target_arl:
            return h, actual_arl
    
    # ëª» ì°¾ìœ¼ë©´ ìµœëŒ€ê°’ ë°˜í™˜ (ê²½ê³ ì™€ í•¨ê»˜)
    return h_candidates[-1], np.mean(run_lengths)

# --- UI ---
uploaded_file = st.file_uploader(
    "ğŸ“‚ ìº í˜ì¸ ë°ì´í„° ì—…ë¡œë“œ (CSV/XLSX/TSV)", 
    type=['csv', 'xlsx', 'tsv']
)

if uploaded_file:
    df = load_and_clean_data(uploaded_file)
    
    if not df.empty:
        res_agg, (a0, b0, k_est, global_ctr) = analyze_empirical_bayes(df)
        ids = sorted(df['ID'].unique())
        
        # íƒ­ êµ¬ì„±
        tabs = st.tabs([
            "ğŸ“Š Executive Summary", 
            "ğŸ§¬ Bayesian Analysis", 
            "ğŸ“‰ Trend & Anomaly Detection",
            "ğŸ’° Budget Optimization"
        ])
        
        # ====================
        # TAB 1: Executive Summary
        # ====================
        with tabs[0]:
            st.markdown("### ğŸ“Š í•µì‹¬ ì§€í‘œ ìš”ì•½")
            
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("ì „ì²´ í‰ê·  CTR", f"{global_ctr*100:.2f}%")
            col2.metric("ë¶„ì„ ê¸°ê°„", f"{(df['ë‚ ì§œ'].max() - df['ë‚ ì§œ'].min()).days}ì¼")
            col3.metric("ì´ ì†Œì¬ ìˆ˜", len(ids))
            col4.metric("ì´ ì§‘í–‰ ë¹„ìš©", f"â‚©{df['ë¹„ìš©'].sum()/10000:.0f}ë§Œ")
            
            st.markdown("---")
            st.markdown("### ğŸ† ìµœê³  ì„±ê³¼ ì†Œì¬ í™•ë¥ ")
            st.markdown("*Bayesian ì‚¬í›„í™•ë¥  ê¸°ë°˜ - 5000íšŒ ì‹œë®¬ë ˆì´ì…˜*")
            
            # í™•ë¥  ë°” ì°¨íŠ¸
            fig_prob = px.bar(
                res_agg.sort_values('prob_is_best', ascending=True),
                x='prob_is_best',
                y='ID',
                orientation='h',
                text=res_agg.sort_values('prob_is_best', ascending=True)['prob_is_best'].apply(lambda x: f"{x*100:.1f}%"),
                title="ê° ì†Œì¬ê°€ ìµœê³  CTRì¼ í™•ë¥ "
            )
            fig_prob.update_traces(textposition='outside')
            fig_prob.update_xaxes(title="í™•ë¥ ", tickformat='.0%')
            st.plotly_chart(fig_prob, use_container_width=True)
            
            st.info(f"""
            **ğŸ“– í•´ì„:**
            - ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ì†Œì¬ê°€ ì‹¤ì œë¡œ ìµœê³  ì„±ê³¼ì¼ ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ìŠµë‹ˆë‹¤
            - í™•ë¥ ì´ ë¹„ìŠ·í•˜ë©´ â†’ ì†Œì¬ ê°„ ì°¨ì´ê°€ ë¯¸ë¯¸í•˜ê±°ë‚˜ ë” ë§ì€ ë°ì´í„° í•„ìš”
            - í™•ë¥ ì´ ëª…í™•í•˜ê²Œ ì°¨ì´ë‚˜ë©´ â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì„±ê³¼ ì°¨ì´ ì¡´ì¬
            """)
            
            st.markdown("---")
            st.markdown("### ğŸ“ˆ ì†Œì¬ë³„ ìƒì„¸ ì„±ê³¼")
            
            display_df = res_agg[['ID', 'raw_ctr', 'exp_ctr', 'ë…¸ì¶œ', 'í´ë¦­', 'ë¹„ìš©', 'prob_is_best']].copy()
            # ë¨¼ì € ê°’ ë³€í™˜
            display_df['raw_ctr'] = display_df['raw_ctr'] * 100
            display_df['exp_ctr'] = display_df['exp_ctr'] * 100
            display_df['prob_is_best'] = display_df['prob_is_best'] * 100
            # ê·¸ ë‹¤ìŒ ì»¬ëŸ¼ëª… ë³€ê²½
            display_df.columns = ['ì†Œì¬', 'ì›ë³¸CTR(%)', 'ë³´ì •CTR(%)', 'ë…¸ì¶œìˆ˜', 'í´ë¦­ìˆ˜', 'ë¹„ìš©', 'ìµœê³ í™•ë¥ ']
            
            st.dataframe(
                display_df.style.format({
                    'ì›ë³¸CTR(%)': '{:.2f}',
                    'ë³´ì •CTR(%)': '{:.2f}',
                    'ë…¸ì¶œìˆ˜': '{:,.0f}',
                    'í´ë¦­ìˆ˜': '{:,.0f}',
                    'ë¹„ìš©': 'â‚©{:,.0f}',
                    'ìµœê³ í™•ë¥ ': '{:.1f}%'
                }).background_gradient(subset=['ë³´ì •CTR(%)'], cmap='RdYlGn'),
                use_container_width=True
            )
        
        # ====================
        # TAB 2: Bayesian Analysis
        # ====================
        with tabs[1]:
            st.markdown("### ğŸ§¬ Empirical Bayes ë°©ë²•ë¡ ")
            
            st.markdown(f"""
            **í•µì‹¬ ê°œë…:**
            - ì†Œí‘œë³¸ì—ì„œ CTRì€ ë³€ë™ì„±ì´ í½ë‹ˆë‹¤ (í´ë¦­ ëª‡ ê°œë¡œ 100% or 0% ê°€ëŠ¥)
            - ì „ì²´ í‰ê· ì„ ì‚¬ì „ ì •ë³´ë¡œ í™œìš©í•´ ê·¹ë‹¨ê°’ì„ ë³´ì •í•©ë‹ˆë‹¤
            - "ì „ì²´ì ìœ¼ë¡œ CTRì´ {global_ctr*100:.2f}%ì¸ë°, ì´ ì†Œì¬ë§Œ {global_ctr*100*3:.1f}%ëŠ” ì˜ì‹¬ìŠ¤ëŸ½ë‹¤"
            """)
            
            col1, col2, col3 = st.columns(3)
            col1.metric("Prior Î±â‚€", f"{a0:.1f}")
            col2.metric("Prior Î²â‚€", f"{b0:.1f}")
            col3.metric("ì‹ ë¢°ë„ Îº", f"{k_est:.1f}")
            
            st.markdown(f"""
            **Îº (Kappa) í•´ì„:**
            - í˜„ì¬ ê°’: **{k_est:.1f}**
            - Îºê°€ í´ìˆ˜ë¡ â†’ ì „ì²´ í‰ê· ì„ ë” ì‹ ë¢° (ë³´ìˆ˜ì  í‰ê°€)
            - Îºê°€ ì‘ì„ìˆ˜ë¡ â†’ ê°œë³„ ì†Œì¬ ë°ì´í„°ë¥¼ ë” ì‹ ë¢°
            - ì ì • ë²”ìœ„: 10~1000 (í˜„ì¬ {'âœ… ì ì ˆ' if 10 < k_est < 1000 else 'âš ï¸ ì¡°ì • í•„ìš”'})
            """)
            
            st.markdown("---")
            st.markdown("### ğŸ“Š ì‚¬í›„í™•ë¥  ë¶„í¬ (Posterior Distribution)")
            
            fig_post = go.Figure()
            for _, row in res_agg.iterrows():
                x = np.linspace(0, 0.03, 500)
                y = beta.pdf(x, row['post_alpha'], row['post_beta'])
                fig_post.add_trace(go.Scatter(
                    x=x*100, y=y, 
                    name=row['ID'],
                    mode='lines',
                    fill='tozeroy',
                    opacity=0.6
                ))
            
            fig_post.update_layout(
                title="ê° ì†Œì¬ì˜ ì‹¤ì œ CTR ë¶„í¬ ì¶”ì •",
                xaxis_title="CTR (%)",
                yaxis_title="í™•ë¥  ë°€ë„",
                hovermode='x unified'
            )
            st.plotly_chart(fig_post, use_container_width=True)
            
            st.info("""
            **ğŸ“– ê·¸ë˜í”„ í•´ì„:**
            - Xì¶•: í•´ë‹¹ ì†Œì¬ì˜ "ì§„ì§œ" CTR ë²”ìœ„
            - Yì¶•: ê° CTRì¼ í™•ë¥  (ë†’ì„ìˆ˜ë¡ ê·¸ ê°’ì¼ ê°€ëŠ¥ì„± ë†’ìŒ)
            - ë¶„í¬ê°€ ì¢ì„ìˆ˜ë¡ â†’ í™•ì‹ ë„ ë†’ìŒ (ë°ì´í„° ë§ê±°ë‚˜ ì¼ê´€ì„± ë†’ìŒ)
            - ë¶„í¬ê°€ ë„“ì„ìˆ˜ë¡ â†’ ë¶ˆí™•ì‹¤ì„± ë†’ìŒ (ë” ë§ì€ í…ŒìŠ¤íŠ¸ í•„ìš”)
            - ë¶„í¬ê°€ ê²¹ì¹˜ë©´ â†’ ì†Œì¬ ê°„ ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ëª…í™•í•˜ì§€ ì•ŠìŒ
            """)
        
        # ====================
        # TAB 3: Trend & CUSUM
        # ====================
        with tabs[2]:
            st.markdown("### ğŸ“‰ CUSUM ê¸°ë°˜ ì´ìƒ ê°ì§€")
            st.markdown("**Cumulative Sum Control Chart - ì„±ê³¼ í•˜ë½ ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ**")
            
            t_id = st.selectbox("ë¶„ì„í•  ì†Œì¬ ì„ íƒ", ids, key='cusum_material')
            sub = df[df['ID'] == t_id].sort_values('ë‚ ì§œ')
            
            # ê¸°ì¤€ CTR ì„¤ì •
            if len(sub) >= 7:
                baseline = sub.head(7)
                p0_val = baseline['í´ë¦­'].sum() / (baseline['ë…¸ì¶œ'].sum() + 1e-9)
                st.info(f"**ê¸°ì¤€ì„  ì„¤ì •:** ì´ˆê¸° 7ì¼ í‰ê·  CTR = {p0_val*100:.2f}%")
            else:
                p0_val = sub['í´ë¦­'].sum() / (sub['ë…¸ì¶œ'].sum() + 1e-9)
                st.warning(f"ë°ì´í„° ë¶€ì¡±: ì „ì²´ í‰ê·  CTR = {p0_val*100:.2f}% ì‚¬ìš©")
            
            # CUSUM ê³„ì‚°
            cusum_vals = get_binomial_cusum(sub['í´ë¦­'].values, sub['ë…¸ì¶œ'].values, p0_val)
            
            # ëª¬í…Œì¹´ë¥¼ë¡œë¡œ ì„ê³„ê°’ ì¶”ì •
            with st.spinner('ì„ê³„ê°’ ê³„ì‚° ì¤‘... (ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜)'):
                h_threshold, achieved_arl = estimate_h_via_arl(
                    p0_val, 
                    sub['ë…¸ì¶œ'].values,
                    target_arl=30,
                    sims=500
                )
            h_threshold = -h_threshold  # CUSUMì€ ìŒìˆ˜ ë°©í–¥ì´ë¯€ë¡œ
            
            # CUSUM ì°¨íŠ¸
            fig_cusum = go.Figure()
            fig_cusum.add_trace(go.Scatter(
                x=sub['ë‚ ì§œ'],
                y=cusum_vals,
                mode='lines+markers',
                name='CUSUM',
                line=dict(color='blue', width=2)
            ))
            fig_cusum.add_hline(
                y=h_threshold, 
                line_dash="dash", 
                line_color="red",
                annotation_text=f"ì„ê³„ê°’ h={-h_threshold:.2f} (ARLâ‰ˆ{achieved_arl:.0f}ì¼)"
            )
            fig_cusum.update_layout(
                title=f"{t_id} - CUSUM ì¶”ì„¸",
                xaxis_title="ë‚ ì§œ",
                yaxis_title="CUSUM ê°’",
                hovermode='x unified'
            )
            st.plotly_chart(fig_cusum, use_container_width=True)
            
            # ì´ìƒ ê°ì§€ ê²°ê³¼
            if cusum_vals[-1] < h_threshold:
                st.error(f"""
                âš ï¸ **ì„±ê³¼ í•˜ë½ ê°ì§€!**
                - í˜„ì¬ CUSUM: {cusum_vals[-1]:.2f}
                - ìµœê·¼ ì„±ê³¼ê°€ ê¸°ì¤€ì„  ëŒ€ë¹„ ìœ ì˜ë¯¸í•˜ê²Œ í•˜ë½í–ˆìŠµë‹ˆë‹¤
                - **ê¶Œì¥ ì¡°ì¹˜:** ì†Œì¬ êµì²´ ë˜ëŠ” ì˜ˆì‚° ì¶•ì†Œ ê²€í† 
                """)
            elif cusum_vals[-1] < h_threshold * 0.5:
                st.warning(f"""
                âš¡ **ì£¼ì˜ í•„ìš”**
                - í˜„ì¬ CUSUM: {cusum_vals[-1]:.2f}
                - í•˜ë½ ì¶”ì„¸ê°€ ê°ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤
                - ëª¨ë‹ˆí„°ë§ ê°•í™” í•„ìš”
                """)
            else:
                st.success(f"""
                âœ… **ì •ìƒ ë²”ìœ„**
                - í˜„ì¬ CUSUM: {cusum_vals[-1]:.2f}
                - ì„±ê³¼ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ ì¤‘
                """)
            
            st.markdown("---")
            st.markdown("### ğŸ“ˆ ì¼ë³„ CTR ì¶”ì´")
            
            fig_daily = go.Figure()
            fig_daily.add_trace(go.Scatter(
                x=sub['ë‚ ì§œ'],
                y=sub['CTR(%)'],
                mode='lines+markers',
                name='ì¼ë³„ CTR',
                line=dict(color='green')
            ))
            fig_daily.add_hline(
                y=p0_val*100,
                line_dash="dot",
                line_color="orange",
                annotation_text="ê¸°ì¤€ CTR"
            )
            fig_daily.update_layout(
                title="ì¼ë³„ CTR ë³€í™”",
                xaxis_title="ë‚ ì§œ",
                yaxis_title="CTR (%)"
            )
            st.plotly_chart(fig_daily, use_container_width=True)
            
            st.info(f"""
            **ğŸ“– CUSUM ë°©ë²•ë¡ :**
            - **ì„ê³„ê°’ h = {-h_threshold:.2f}** (ëª¬í…Œì¹´ë¥¼ë¡œ {500}íšŒ ì‹œë®¬ë ˆì´ì…˜)
            - **ëª©í‘œ ARL = 30ì¼** (ì •ìƒ ìƒíƒœì—ì„œ í‰ê·  30ì¼ë§ˆë‹¤ 1íšŒ ì˜¤ê²½ë³´)
            - **ë‹¬ì„± ARL = {achieved_arl:.0f}ì¼** (ì‹¤ì œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼)
            
            **ì‘ë™ ì›ë¦¬:**
            - ê¸°ì¤€ì„ ({p0_val*100:.2f}%) ëŒ€ë¹„ "ëˆ„ì  í¸ì°¨" ê³„ì‚°
            - ê°’ì´ ìŒìˆ˜ë¡œ ë–¨ì–´ì§ˆìˆ˜ë¡ â†’ ì„±ê³¼ í•˜ë½ ì‹ í˜¸
            - ì„ê³„ê°’ ëŒíŒŒ ì‹œ â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ë³€í™”
            - ì¥ì : ì‘ì€ ë³€í™”ë„ ë¹ ë¥´ê²Œ ê°ì§€ (ì¼ë³„ ë¹„êµë³´ë‹¤ ë¯¼ê°)
            
            **ì™œ ì´ ì„ê³„ê°’ì¸ê°€?**
            - ë„ˆë¬´ ë‚®ìœ¼ë©´ â†’ ì˜¤ê²½ë³´ ë§ìŒ (ì •ìƒì¸ë° ê²½ê³ )
            - ë„ˆë¬´ ë†’ìœ¼ë©´ â†’ ê°ì§€ ëŠ¦ìŒ (ë¬¸ì œ ë†“ì¹¨)
            - ARL 30ì¼ = "ì •ìƒ ìƒíƒœì—ì„œ í•œ ë‹¬ì— í•œ ë²ˆ ì •ë„ë§Œ ì˜¤ê²½ë³´"
            """)
            
            # ========== ì¶”ê°€ ë¶„ì„ ì„¹ì…˜ ==========
            st.markdown("---")
            st.markdown("### ğŸ”¬ ê³ ê¸‰ í†µê³„ ë¶„ì„")
            
            analysis_tab = st.radio(
                "ë¶„ì„ ì„ íƒ:",
                ["ARL ê³¡ì„  (hê°’ì˜ ì˜í–¥)", "ëª©í‘œ ARL ë¹„êµ", "Power ë¶„ì„ (ê°ì§€ ì†ë„)"],
                horizontal=True
            )
            
            if analysis_tab == "ARL ê³¡ì„  (hê°’ì˜ ì˜í–¥)":
                st.markdown("**hê°’ì— ë”°ë¥¸ ARL(ì˜¤ê²½ë³´ ê°„ê²©) ë³€í™”**")
                
                with st.spinner('ARL ê³¡ì„  ê³„ì‚° ì¤‘... (ì•½ 10ì´ˆ ì†Œìš”)'):
                    h_range = np.arange(1.0, 20.0, 1.0)
                    arl_values = []
                    
                    for h_test in h_range:
                        run_lengths = []
                        p1 = np.clip(p0_val * 0.85, 1e-6, 1-1e-6)
                        p0_clip = np.clip(p0_val, 1e-6, 1-1e-6)
                        llr_s = np.log(p1 / p0_clip)
                        llr_f = np.log((1 - p1) / (1 - p0_clip))
                        
                        for _ in range(200):  # ë¹ ë¥¸ ê³„ì‚°ì„ ìœ„í•´ 200íšŒ
                            s = 0
                            t = 0
                            while t < 200:
                                t += 1
                                n = np.random.choice(sub['ë…¸ì¶œ'].values)
                                c = np.random.binomial(int(n), p0_clip)
                                s = min(0, s + (c * llr_s + (int(n) - c) * llr_f))
                                if s < -h_test:
                                    break
                            run_lengths.append(t)
                        
                        arl_values.append(np.mean(run_lengths))
                
                fig_arl = go.Figure()
                fig_arl.add_trace(go.Scatter(
                    x=h_range,
                    y=arl_values,
                    mode='lines+markers',
                    name='ARL',
                    line=dict(color='purple', width=3)
                ))
                fig_arl.add_hline(
                    y=30, 
                    line_dash="dot", 
                    line_color="red",
                    annotation_text="ëª©í‘œ ARL = 30ì¼"
                )
                fig_arl.add_vline(
                    x=-h_threshold,
                    line_dash="dash",
                    line_color="green",
                    annotation_text=f"í˜„ì¬ h = {-h_threshold:.1f}"
                )
                fig_arl.update_layout(
                    title="ì„ê³„ê°’ hì— ë”°ë¥¸ ARL ë³€í™”",
                    xaxis_title="ì„ê³„ê°’ h",
                    yaxis_title="ARL (ì¼)",
                    hovermode='x'
                )
                st.plotly_chart(fig_arl, use_container_width=True)
                
                st.info("""
                **ğŸ“– í•´ì„:**
                - Xì¶•: ì„ê³„ê°’ h (í´ìˆ˜ë¡ ë³´ìˆ˜ì )
                - Yì¶•: ì •ìƒ ìƒíƒœì—ì„œ ì˜¤ê²½ë³´ê¹Œì§€ í‰ê·  ì¼ìˆ˜
                - hê°€ í´ìˆ˜ë¡ â†’ ARL ì¦ê°€ â†’ ì˜¤ê²½ë³´ ê°ì†Œ BUT ê°ì§€ ëŠ¦ì–´ì§
                - ë…¹ìƒ‰ ì„ : í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ hê°’ (ëª©í‘œ ARL 30ì¼ ë‹¬ì„±)
                - ë¹¨ê°„ ì„ : ëª©í‘œ ARL (êµì°¨ì ì´ ìµœì  h)
                """)
            
            elif analysis_tab == "ëª©í‘œ ARL ë¹„êµ":
                st.markdown("**ì„œë¡œ ë‹¤ë¥¸ ARL ëª©í‘œì— ë”°ë¥¸ ì„ê³„ê°’ ë¹„êµ**")
                
                with st.spinner('ë‹¤ì–‘í•œ ARL ì‹œë‚˜ë¦¬ì˜¤ ê³„ì‚° ì¤‘...'):
                    target_arls = [10, 20, 30, 50, 100]
                    comparison_results = []
                    
                    for target in target_arls:
                        h_val, actual = estimate_h_via_arl(
                            p0_val,
                            sub['ë…¸ì¶œ'].values,
                            target_arl=target,
                            sims=300  # ë¹ ë¥¸ ê³„ì‚°
                        )
                        comparison_results.append({
                            'ëª©í‘œARL': target,
                            'ì„ê³„ê°’h': h_val,
                            'ì‹¤ì œARL': actual
                        })
                
                comp_df = pd.DataFrame(comparison_results)
                
                fig_comp = go.Figure()
                fig_comp.add_trace(go.Bar(
                    x=comp_df['ëª©í‘œARL'],
                    y=comp_df['ì„ê³„ê°’h'],
                    name='ì„ê³„ê°’ h',
                    marker_color='lightblue',
                    text=comp_df['ì„ê³„ê°’h'].apply(lambda x: f"{x:.1f}"),
                    textposition='outside'
                ))
                fig_comp.update_layout(
                    title="ëª©í‘œ ARLì— ë”°ë¥¸ í•„ìš” ì„ê³„ê°’",
                    xaxis_title="ëª©í‘œ ARL (ì¼)",
                    yaxis_title="ì„ê³„ê°’ h",
                    showlegend=False
                )
                st.plotly_chart(fig_comp, use_container_width=True)
                
                st.dataframe(
                    comp_df.style.format({
                        'ëª©í‘œARL': '{:.0f}ì¼',
                        'ì„ê³„ê°’h': '{:.2f}',
                        'ì‹¤ì œARL': '{:.1f}ì¼'
                    }).background_gradient(subset=['ì„ê³„ê°’h'], cmap='Blues'),
                    use_container_width=True
                )
                
                st.info("""
                **ğŸ“– ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ:**
                - **ARL 10ì¼**: ê³µê²©ì  ê°ì§€ (ì˜¤ê²½ë³´ ë§ì§€ë§Œ ë¹ ë¦„)
                  â†’ ì‹ ê·œ ì†Œì¬ í…ŒìŠ¤íŠ¸ ì´ˆê¸°, ê³ ë¹„ìš© ìº í˜ì¸
                - **ARL 30ì¼**: ê· í˜•ì¡íŒ ì„¤ì • (ê¶Œì¥)
                  â†’ ì¼ë°˜ì ì¸ ìƒì‹œ ëª¨ë‹ˆí„°ë§
                - **ARL 100ì¼**: ë³´ìˆ˜ì  ê°ì§€ (í™•ì‹¤í•œ ë³€í™”ë§Œ)
                  â†’ ì•ˆì •ì ì¸ ì¥ê¸° ìº í˜ì¸, ê³„ì ˆì„± ë†’ì€ ìƒí’ˆ
                """)
            
            else:  # Power ë¶„ì„
                st.markdown("**ì„±ê³¼ í•˜ë½ ì‹œ ê°ì§€ ì†ë„ ë¶„ì„**")
                st.markdown("*'15% CTR í•˜ë½ì´ ë°œìƒí•˜ë©´ ë©°ì¹  ë§Œì— ê°ì§€í•  ìˆ˜ ìˆë‚˜?'*")
                
                with st.spinner('Power ë¶„ì„ ì‹¤í–‰ ì¤‘...'):
                    decline_scenarios = [0.70, 0.75, 0.80, 0.85, 0.90, 0.95]
                    detection_times = []
                    
                    for decline_ratio in decline_scenarios:
                        p1_scenario = p0_val * decline_ratio
                        p1_clip = np.clip(p1_scenario, 1e-6, 1-1e-6)
                        p0_clip = np.clip(p0_val, 1e-6, 1-1e-6)
                        llr_s = np.log(p1_clip / p0_clip)
                        llr_f = np.log((1 - p1_clip) / (1 - p0_clip))
                        
                        detection_days = []
                        for _ in range(300):
                            s = 0
                            t = 0
                            while t < 100:
                                t += 1
                                n = np.random.choice(sub['ë…¸ì¶œ'].values)
                                c = np.random.binomial(int(n), p1_clip)
                                s = min(0, s + (c * llr_s + (int(n) - c) * llr_f))
                                if s < h_threshold:
                                    break
                            detection_days.append(t)
                        
                        detection_times.append({
                            'í•˜ë½ë¥ ': f"{(1-decline_ratio)*100:.0f}%",
                            'í•˜ë½í›„CTR': p1_scenario * 100,
                            'í‰ê· ê°ì§€ì¼': np.mean(detection_days),
                            'ì¤‘ì•™ê°’': np.median(detection_days),
                            '90%ê°ì§€ì¼': np.percentile(detection_days, 90)
                        })
                
                power_df = pd.DataFrame(detection_times)
                
                fig_power = go.Figure()
                fig_power.add_trace(go.Scatter(
                    x=power_df['í•˜ë½ë¥ '],
                    y=power_df['í‰ê· ê°ì§€ì¼'],
                    mode='lines+markers',
                    name='í‰ê· ',
                    line=dict(color='red', width=3),
                    marker=dict(size=10)
                ))
                fig_power.add_trace(go.Scatter(
                    x=power_df['í•˜ë½ë¥ '],
                    y=power_df['90%ê°ì§€ì¼'],
                    mode='lines+markers',
                    name='90% ë¶„ìœ„',
                    line=dict(color='orange', width=2, dash='dash'),
                    marker=dict(size=8)
                ))
                fig_power.update_layout(
                    title=f"í•˜ë½ ì •ë„ë³„ ê°ì§€ ì†Œìš” ì‹œê°„ (h={-h_threshold:.2f})",
                    xaxis_title="CTR í•˜ë½ë¥ ",
                    yaxis_title="ê°ì§€ê¹Œì§€ ì†Œìš” ì¼ìˆ˜",
                    hovermode='x unified'
                )
                st.plotly_chart(fig_power, use_container_width=True)
                
                st.dataframe(
                    power_df.style.format({
                        'í•˜ë½í›„CTR': '{:.3f}%',
                        'í‰ê· ê°ì§€ì¼': '{:.1f}ì¼',
                        'ì¤‘ì•™ê°’': '{:.1f}ì¼',
                        '90%ê°ì§€ì¼': '{:.1f}ì¼'
                    }).background_gradient(subset=['í‰ê· ê°ì§€ì¼'], cmap='RdYlGn_r'),
                    use_container_width=True
                )
                
                st.info(f"""
                **ğŸ“– í•´ì„:**
                - **30% í•˜ë½** (CTR {p0_val*100:.2f}% â†’ {p0_val*0.7*100:.2f}%): 
                  í‰ê·  {power_df.iloc[0]['í‰ê· ê°ì§€ì¼']:.1f}ì¼ ë§Œì— ê°ì§€
                - **15% í•˜ë½** (CTR {p0_val*100:.2f}% â†’ {p0_val*0.85*100:.2f}%): 
                  í‰ê·  {power_df.iloc[3]['í‰ê· ê°ì§€ì¼']:.1f}ì¼ ë§Œì— ê°ì§€
                - **5% í•˜ë½**: ê°ì§€ê°€ ë§¤ìš° ëŠë¦¼ â†’ ë…¸ì´ì¦ˆì™€ êµ¬ë¶„ ì–´ë ¤ì›€
                
                **ì‹¤ë¬´ ì‹œì‚¬ì :**
                - í° í•˜ë½(20%+)ì€ ë¹ ë¥´ê²Œ ê°ì§€ ê°€ëŠ¥
                - ì‘ì€ í•˜ë½(5~10%)ì€ 2ì£¼ ì´ìƒ ê´€ì°° í•„ìš”
                - 90% ë¶„ìœ„ = "ìµœì•…ì˜ ê²½ìš° ì´ ì •ë„ ê±¸ë¦¼"
                """)
            
        
        # ====================
        # TAB 4: Budget Optimization
        # ====================
        with tabs[3]:
            st.markdown("### ğŸ’° ì˜ˆì‚° íš¨ìœ¨ ë¶„ì„")
            
            res_agg['íš¨ìœ¨ì ìˆ˜'] = res_agg['exp_ctr'] / (res_agg['avg_cost_7d'] / 100000 + 1e-9)
            
            fig_scatter = px.scatter(
                res_agg,
                x='avg_cost_7d',
                y='exp_ctr',
                size='ë…¸ì¶œ',
                color='ID',
                text='ID',
                title="ë¹„ìš© ëŒ€ë¹„ ì„±ê³¼ ë¶„í¬",
                labels={'avg_cost_7d': 'ì¼í‰ê·  ë¹„ìš© (ìµœê·¼ 7ì¼)', 'exp_ctr': 'ë³´ì • CTR'}
            )
            fig_scatter.update_traces(textposition='top center')
            st.plotly_chart(fig_scatter, use_container_width=True)
            
            st.markdown("---")
            st.markdown("### ğŸ¯ ì˜ˆì‚° ì¬ë¶„ë°° ì‹œë®¬ë ˆì´ì…˜")
            
            strategy = st.radio(
                "ì „ëµ ì„ íƒ:",
                ["í˜„ì¬ ìœ ì§€", "ìƒìœ„ ì§‘ì¤‘ (70%)", "íš¨ìœ¨ ë¹„ë¡€ ë°°ë¶„"]
            )
            
            if st.button("ğŸ’¡ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"):
                total_budget = res_agg['avg_cost_7d'].sum()
                
                if strategy == "í˜„ì¬ ìœ ì§€":
                    res_agg['ì œì•ˆì˜ˆì‚°'] = res_agg['avg_cost_7d']
                    
                elif strategy == "ìƒìœ„ ì§‘ì¤‘ (70%)":
                    top2 = res_agg.nlargest(2, 'exp_ctr')['ID'].values
                    res_agg['ì œì•ˆì˜ˆì‚°'] = res_agg.apply(
                        lambda x: total_budget * 0.35 if x['ID'] in top2 else total_budget * 0.15,
                        axis=1
                    )
                    
                else:  # íš¨ìœ¨ ë¹„ë¡€
                    res_agg['ì œì•ˆì˜ˆì‚°'] = (
                        res_agg['íš¨ìœ¨ì ìˆ˜'] / res_agg['íš¨ìœ¨ì ìˆ˜'].sum() * total_budget
                    )
                
                result_df = res_agg[['ID', 'avg_cost_7d', 'ì œì•ˆì˜ˆì‚°', 'exp_ctr']].copy()
                result_df['ë³€í™”ìœ¨'] = (
                    (result_df['ì œì•ˆì˜ˆì‚°'] - result_df['avg_cost_7d']) / result_df['avg_cost_7d'] * 100
                )
                result_df.columns = ['ì†Œì¬', 'í˜„ì¬ ì¼í‰ê· ', 'ì œì•ˆ ì¼í‰ê· ', 'ë³´ì •CTR(%)', 'ë³€í™”ìœ¨(%)']
                
                st.dataframe(
                    result_df.style.format({
                        'í˜„ì¬ ì¼í‰ê· ': 'â‚©{:,.0f}',
                        'ì œì•ˆ ì¼í‰ê· ': 'â‚©{:,.0f}',
                        'ë³´ì •CTR(%)': '{:.2%}',
                        'ë³€í™”ìœ¨(%)': '{:+.1f}%'
                    }).background_gradient(subset=['ë³€í™”ìœ¨(%)'], cmap='RdYlGn'),
                    use_container_width=True
                )
                
                st.success(f"âœ… ì´ ì˜ˆì‚°: â‚©{total_budget:,.0f} (ë³€ë™ ì—†ìŒ)")
    else:
        st.warning("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    st.info("ğŸ‘† ìƒë‹¨ì—ì„œ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")