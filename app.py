import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import re

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="In-house Marketing BI", layout="wide")

# --- [ì‚¬ì´ë“œë°”] ë°ì´í„° ê´€ë¦¬ ë° ì„¤ì • ---
with st.sidebar:
    st.header("ğŸ’¾ ë°ì´í„° ê´€ë¦¬ (Save/Load)")
    
    auto_date_mode = st.checkbox("ğŸ“… ë‚ ì§œ ìë™ ìƒì„± ëª¨ë“œ", value=False, 
                                 help="ì²´í¬í•˜ë©´ ì²« ì¤„ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì•„ë˜ í–‰ë“¤ì˜ ë‚ ì§œë¥¼ í•˜ë£¨ì”© ìë™ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.")
    
    st.divider()
    
    if 'db' in st.session_state and not st.session_state.db.empty:
        csv = st.session_state.db.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“Š í˜„ì¬ ë°ì´í„° CSVë¡œ ë‚´ë³´ë‚´ê¸°",
            data=csv,
            file_name=f"marketing_data_{datetime.now().strftime('%Y%m%d')}.csv",
            mime='text/csv',
        )
    
    st.divider()
    
    uploaded_file = st.file_uploader("ğŸ“‚ ì €ì¥ëœ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°", type=["csv"])
    if uploaded_file is not None:
        try:
            input_df = pd.read_csv(uploaded_file)
            input_df['ë‚ ì§œ'] = pd.to_datetime(input_df['ë‚ ì§œ'], errors='coerce').dt.date
            
            required_cols = ["ë‚ ì§œ", "ë§¤ì²´", "ìƒí’ˆëª…", "ì†Œì¬ëª…", "ë…¸ì¶œìˆ˜", "í´ë¦­ìˆ˜", "ë¹„ìš©"]
            if all(col in input_df.columns for col in required_cols):
                if st.button("ğŸ“¥ ë°ì´í„° ë®ì–´ì“°ê¸° ì ìš©"):
                    st.session_state.db = input_df
                    st.success("ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
                    st.rerun()
            else:
                st.error("CSV íŒŒì¼ í˜•ì‹ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    st.divider()
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    n_iterations = st.select_slider("ì‹œë®¬ë ˆì´ì…˜ ë°˜ë³µ íšŸìˆ˜", options=[1000, 5000, 10000, 50000], value=10000)

st.title("ğŸ¯ ë°ì´í„° ê¸°ë°˜ ë§ˆì¼€íŒ… ë¶„ì„íˆ´")

# --- [ìœ í‹¸ë¦¬í‹°] ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (íŠ¹ìˆ˜ë¬¸ì ì œê±° ë¡œì§ ê°•í™”) ---
def process_data(df, auto_date):
    if df.empty: return df
    df = df.copy()
    
    # 1. ë‚ ì§œ ì²˜ë¦¬
    if auto_date:
        processed_chunks = []
        for media, group in df.groupby('ë§¤ì²´'):
            group = group.reset_index(drop=True)
            if not group.empty:
                first_date = pd.to_datetime(group.loc[0, 'ë‚ ì§œ'], errors='coerce')
                if pd.notnull(first_date):
                    group['ë‚ ì§œ'] = [first_date + timedelta(days=i) for i in range(len(group))]
            processed_chunks.append(group)
        df = pd.concat(processed_chunks, ignore_index=True)
    else:
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce')
        
    df = df.dropna(subset=['ë‚ ì§œ'])
    
    # 2. ìˆ˜ì¹˜ ë°ì´í„° ì²˜ë¦¬ (ì›í™” ê¸°í˜¸, ì½¤ë§ˆ ì œê±°)
    for col in ['ë…¸ì¶œìˆ˜', 'í´ë¦­ìˆ˜', 'ë¹„ìš©']:
        # ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ì(â‚©, \, , ë“±)ë¥¼ ëª¨ë‘ ì œê±°í•˜ëŠ” ì •ê·œì‹ ì ìš©
        df[col] = df[col].astype(str).str.replace(r'[^\d.]', '', regex=True)
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
    
    df['CTR(%)'] = (df['í´ë¦­ìˆ˜'] / df['ë…¸ì¶œìˆ˜'] * 100).round(2).fillna(0.0)
    df['ID'] = "[" + df['ë§¤ì²´'] + "] " + df['ìƒí’ˆëª…']
    return df

# --- [ë¶„ì„] ë² ì´ì§€ì•ˆ ë¡œì§ ---
def run_analysis(df, item_a, item_b, iterations):
    res = df.groupby('ID').agg({'í´ë¦­ìˆ˜':'sum', 'ë…¸ì¶œìˆ˜':'sum'})
    a, b = res.loc[item_a], res.loc[item_b]
    samples_a = np.random.beta(a['í´ë¦­ìˆ˜']+1, a['ë…¸ì¶œìˆ˜']-a['í´ë¦­ìˆ˜']+1, iterations)
    samples_b = np.random.beta(b['í´ë¦­ìˆ˜']+1, b['ë…¸ì¶œìˆ˜']-b['í´ë¦­ìˆ˜']+1, iterations)
    target_ctr = df[df['ID'] == item_b]['CTR(%)']
    mu, sigma = target_ctr.mean(), target_ctr.std() if target_ctr.std() > 0 else target_ctr.mean()*0.1
    future_sims = np.maximum(0, np.random.normal(mu, sigma, (iterations, 7)))
    return (samples_a > samples_b).mean(), samples_a, samples_b, future_sims

# --- [ë°ì´í„°] ì„¸ì…˜ ê´€ë¦¬ ---
if 'db' not in st.session_state:
    st.session_state.db = pd.DataFrame([{"ë‚ ì§œ": datetime.now().date(), "ë§¤ì²´": "ë„¤ì´ë²„", "ìƒí’ˆëª…": "GFA", "ì†Œì¬ëª…": "S1", "ë…¸ì¶œìˆ˜": 10000, "í´ë¦­ìˆ˜": 100, "ë¹„ìš©": 500000}])

media_list = ["ë„¤ì´ë²„", "ì¹´ì¹´ì˜¤", "êµ¬ê¸€", "ë©”íƒ€", "ìœ íŠœë¸Œ", "SOOP", "ë””ì‹œì¸ì‚¬ì´ë“œ", "ì¸ë²¤", "ë£¨ë¦¬ì›¹"]
tabs = st.tabs(media_list)
all_data = []

for i, m in enumerate(media_list):
    with tabs[i]:
        curr_df = st.session_state.db[st.session_state.db['ë§¤ì²´'] == m].copy()
        curr_df['ë‚ ì§œ'] = pd.to_datetime(curr_df['ë‚ ì§œ'], errors='coerce')
        
        if curr_df.empty:
            curr_df = pd.DataFrame([{"ë‚ ì§œ": datetime.now().date(), "ë§¤ì²´": m, "ìƒí’ˆëª…": "", "ì†Œì¬ëª…": "", "ë…¸ì¶œìˆ˜": 0, "í´ë¦­ìˆ˜": 0, "ë¹„ìš©": 0}])
        
        # [ì¤‘ìš”] ì»¬ëŸ¼ íƒ€ì…ì„ í…ìŠ¤íŠ¸(Required for pasting symbols)ì™€ ìˆ«ì ë³‘í–‰ ì„¤ì •
        edited = st.data_editor(
            curr_df, 
            num_rows="dynamic", 
            use_container_width=True, 
            key=f"ed_{m}",
            column_config={
                "ë‚ ì§œ": st.column_config.DateColumn("ë‚ ì§œ", format="YYYY-MM-DD", required=True),
                # ë¹„ìš© ì»¬ëŸ¼ì„ ì¼ì‹œì ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œë„ ë°›ì„ ìˆ˜ ìˆê²Œ í•˜ì—¬ ë¶™ì—¬ë„£ê¸° í—ˆìš©
                "ë¹„ìš©": st.column_config.TextColumn("ë¹„ìš© (â‚©)", help="ì›í™” ê¸°í˜¸ê°€ ìˆì–´ë„ ë¶„ì„ ì‹¤í–‰ ì‹œ ìˆ«ìë¡œ ìë™ ë³€í™˜ë©ë‹ˆë‹¤."),
                "ë…¸ì¶œìˆ˜": st.column_config.NumberColumn("ë…¸ì¶œìˆ˜", format="%d"),
                "í´ë¦­ìˆ˜": st.column_config.NumberColumn("í´ë¦­ìˆ˜", format="%d")
            }
        )
        all_data.append(edited)

if st.button("ğŸš€ í†µí•© ë¶„ì„ ì‹¤í–‰ ë° ë°ì´í„° ì €ì¥", use_container_width=True):
    raw_combined = pd.concat(all_data, ignore_index=True)
    st.session_state.db = process_data(raw_combined, auto_date_mode)
    st.success("ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.rerun()

# --- [ë¦¬í¬íŠ¸] ---
final_df = st.session_state.db
if not final_df.empty and 'ID' in final_df.columns and len(final_df['ID'].unique()) >= 2:
    st.divider()
    p_list = sorted(final_df['ID'].unique())
    item_a = st.selectbox("ë¹„êµ ìƒí’ˆ A (ê¸°ì¤€)", p_list, index=0)
    item_b = st.selectbox("ë¹„êµ ìƒí’ˆ B (ëŒ€ìƒ)", p_list, index=1)
    
    prob, s_a, s_b, f_sims = run_analysis(final_df, item_a, item_b, n_iterations)
    
    c1, c2 = st.columns([1, 2])
    with c1:
        st.metric(f"{item_b} ìŠ¹ë¦¬ í™•ë¥ ", f"{prob*100:.1f}%")
    with c2:
        fig = go.Figure()
        fig.add_trace(go.Histogram(x=s_a, name=item_a, opacity=0.6))
        fig.add_trace(go.Histogram(x=s_b, name=item_b, opacity=0.6))
        fig.update_layout(barmode='overlay', title="CTR ì‚¬í›„ í™•ë¥  ë¶„í¬ ë¹„êµ")
        st.plotly_chart(fig, use_container_width=True)