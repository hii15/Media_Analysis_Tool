import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from prophet import Prophet
from scipy.optimize import minimize
from datetime import datetime, timedelta

# 1. ì„¤ì •
st.set_page_config(page_title="Marketing Science Intelligence v18", layout="wide")

# --- [Core Engine: ë°ì´í„° í†µí•© ë° ë² ì´ì§€ì•ˆ ë³´ì •] ---
def load_all_sheets(uploaded_file):
    """v15 ìš”ì²­: ì—‘ì…€ ë‚´ ëª¨ë“  ì‹œíŠ¸ ìë™ ë³‘í•©"""
    try:
        if uploaded_file.name.endswith('.xlsx'):
            all_sheets = pd.read_excel(uploaded_file, sheet_name=None)
            df = pd.concat(all_sheets.values(), ignore_index=True)
        else:
            df = pd.read_csv(uploaded_file)
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

def process_data(df):
    mapping = {
        'ë‚ ì§œ': ['ë‚ ì§œ', 'ì¼ì', 'Date'],
        'ë§¤ì²´': ['ë§¤ì²´', 'ì±„ë„', 'Media'],
        'ìƒí’ˆëª…': ['ìƒí’ˆëª…', 'ìƒí’ˆ', 'Product'],
        'ì†Œì¬ëª…': ['ì†Œì¬ëª…', 'ì†Œì¬', 'Creative'],
        'ë…¸ì¶œìˆ˜': ['ë…¸ì¶œìˆ˜', 'ë…¸ì¶œ', 'Impression'],
        'í´ë¦­ìˆ˜': ['í´ë¦­ìˆ˜', 'í´ë¦­', 'Click'],
        'ë¹„ìš©': ['ë¹„ìš©', 'ì§€ì¶œ', 'Cost']
    }
    final_df = pd.DataFrame()
    for std_key, patterns in mapping.items():
        found = [c for c in df.columns if str(c).strip() in patterns]
        if found: final_df[std_key] = df[found[0]]
    
    if 'ë‚ ì§œ' not in final_df.columns: return pd.DataFrame()

    final_df['ë‚ ì§œ'] = pd.to_datetime(final_df['ë‚ ì§œ'], errors='coerce')
    for col in ['ë…¸ì¶œìˆ˜', 'í´ë¦­ìˆ˜', 'ë¹„ìš©']:
        final_df[col] = pd.to_numeric(final_df[col].astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce').fillna(0)
    
    # ì§€í‘œ ìƒì„±
    final_df['CTR(%)'] = np.where(final_df['ë…¸ì¶œìˆ˜'] > 0, (final_df['í´ë¦­ìˆ˜'] / final_df['ë…¸ì¶œìˆ˜'] * 100), 0.0)
    final_df['CPC'] = np.where(final_df['í´ë¦­ìˆ˜'] > 0, final_df['ë¹„ìš©'] / final_df['í´ë¦­ìˆ˜'], 0.0)
    
    # v13: ë² ì´ì§€ì•ˆ Shrinkage CTR (ì‘ì€ ëª¨ìˆ˜ ì™œê³¡ ë°©ì§€)
    global_mean = final_df['í´ë¦­ìˆ˜'].sum() / (final_df['ë…¸ì¶œìˆ˜'].sum() + 1e-6)
    final_df['Adj_CTR'] = (final_df['í´ë¦­ìˆ˜'] + 100 * global_mean) / (final_df['ë…¸ì¶œìˆ˜'] + 100) * 100
    final_df['ID'] = "[" + final_df['ë§¤ì²´'].astype(str) + "] " + final_df['ì†Œì¬ëª…'].astype(str)
    
    return final_df.dropna(subset=['ë‚ ì§œ'])

# --- [Prediction Engine: Logit-Prophet & Adjusted R^2] ---
def get_robust_forecast(data):
    """v14: Logit ë³€í™˜ì„ í†µí•œ 0~100% ë²”ìœ„ ì œí•œ ì˜ˆì¸¡"""
    valid_df = data.sort_values('ë‚ ì§œ').copy()
    if len(valid_df) < 7: return None, 0, 0
    
    try:
        p = np.clip(valid_df['Adj_CTR'].values / 100, 0.0001, 0.9999)
        valid_df['y_logit'] = np.log(p / (1 - p))
        
        m = Prophet(interval_width=0.8, daily_seasonality=False, weekly_seasonality=True)
        m.fit(valid_df[['ë‚ ì§œ', 'y_logit']].rename(columns={'ë‚ ì§œ': 'ds', 'y_logit': 'y'}))
        
        future = m.make_future_dataframe(periods=7)
        forecast = m.predict(future)
        
        # v15: Adjusted R^2 ê³„ì‚° (ê³¼ì í•© ë° ì í•©ë„ 100% ì˜¤ë¥˜ ë°©ì§€)
        y_true = valid_df['y_logit'].values
        y_pred = forecast.iloc[:len(y_true)]['yhat'].values
        r2 = 1 - (np.sum((y_true - y_pred)**2) / (np.sum((y_true - np.mean(y_true))**2) + 1e-6))
        adj_r2 = 1 - ((1 - r2) * (len(y_true) - 1) / (len(y_true) - 2 - 1))
        
        def inv_logit(x): return (np.exp(x) / (1 + np.exp(x))) * 100
        res = pd.DataFrame({'ds': forecast['ds'], 'yhat': inv_logit(forecast['yhat']), 
                            'yhat_lower': inv_logit(forecast['yhat_lower']), 'yhat_upper': inv_logit(forecast['yhat_upper'])})
        slope = (forecast['yhat'].values[-1] - forecast['yhat'].values[-7]) / 7
        
        return res, slope, max(0, min(adj_r2, 0.99))
    except: return None, 0, 0

# --- [UI & Logic ê²°í•©] ---
st.title("ğŸ”¬ Marketing Intelligence System v18")

uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ (Excel/CSV)", type=['csv', 'xlsx'])

if uploaded_file:
    df_raw = load_all_sheets(uploaded_file)
    full_df = process_data(df_raw)

    if not full_df.empty:
        ids = sorted(full_df['ID'].unique())
        tabs = st.tabs(["ğŸ“Š ì„±ê³¼ ëŒ€ì‹œë³´ë“œ", "âš–ï¸ ë² ì´ì§€ì•ˆ ì§„ë‹¨", "ğŸ“ˆ ìˆ˜ëª…/ì í•©ë„ ë¶„ì„", "ğŸ¯ ì˜ˆì‚° ìµœì í™”"])

        # --- Tab 1: v10 ì„±ê³¼ ëŒ€ì‹œë³´ë“œ ---
        with tabs[0]:
            st.info("ğŸ’¡ **ê°€ì´ë“œ**: ì „ì²´ ìº í˜ì¸ì˜ í˜„í™©ì…ë‹ˆë‹¤. íŒŒì´ ì°¨íŠ¸ëŠ” ì˜ˆì‚° ë¶„ë°°ë¥¼, ë¼ì¸ ì°¨íŠ¸ëŠ” ì‹œê°„ íë¦„ì— ë”°ë¥¸ ì„±ê³¼ ì¶”ì´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
            c1, c2, c3 = st.columns(3)
            c1.metric("ì´ ë¹„ìš©", f"{full_df['ë¹„ìš©'].sum():,.0f}")
            c2.metric("ì „ì²´ CTR", f"{(full_df['í´ë¦­ìˆ˜'].sum()/full_df['ë…¸ì¶œìˆ˜'].sum()*100):.2f}%")
            c3.metric("í‰ê·  CPC", f"{(full_df['ë¹„ìš©'].sum()/full_df['í´ë¦­ìˆ˜'].sum()):,.0f}")
            
            st.plotly_chart(px.line(full_df.groupby('ë‚ ì§œ').sum().reset_index(), x='ë‚ ì§œ', y='ë¹„ìš©', title="ì¼ë³„ ì§€ì¶œ ì¶”ì´"), use_container_width=True)

        # --- Tab 2: v11~12 ë² ì´ì§€ì•ˆ ì§„ë‹¨ ---
        with tabs[1]:
            st.info("ğŸ’¡ **ê°€ì´ë“œ**: ë‘ ì†Œì¬ì˜ ì„±ê³¼ ì°¨ì´ê°€ 'ìš´'ì¸ì§€ 'ì‹¤ë ¥'ì¸ì§€ íŒë³„í•©ë‹ˆë‹¤. ë¶„í¬ê°€ ê²¹ì¹˜ì§€ ì•Šì„ìˆ˜ë¡ ì„±ê³¼ ì°¨ì´ê°€ í™•ì‹¤í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.")
            sel_a = st.selectbox("ê¸°ì¤€ ì†Œì¬ (A)", ids, index=0)
            sel_b = st.selectbox("ë¹„êµ ì†Œì¬ (B)", ids, index=min(1, len(ids)-1))
            
            # Beta ë¶„í¬ ì‹œë®¬ë ˆì´ì…˜
            s_a, s_b = full_df[full_df['ID']==sel_a].sum(), full_df[full_df['ID']==sel_b].sum()
            dist_a = np.random.beta(s_a['í´ë¦­ìˆ˜']+1, s_a['ë…¸ì¶œìˆ˜']-s_a['í´ë¦­ìˆ˜']+1, 5000)
            dist_b = np.random.beta(s_b['í´ë¦­ìˆ˜']+1, s_b['ë…¸ì¶œìˆ˜']-s_b['í´ë¦­ìˆ˜']+1, 5000)
            
            fig_bayesian = go.Figure()
            fig_bayesian.add_trace(go.Histogram(x=dist_a, name=sel_a, opacity=0.6))
            fig_bayesian.add_trace(go.Histogram(x=dist_b, name=sel_b, opacity=0.6))
            st.plotly_chart(fig_bayesian, use_container_width=True)

        # --- Tab 3: v14~15 ìˆ˜ëª… ë° ì í•©ë„ ---
        with tabs[2]:
            st.info("ğŸ’¡ **ê°€ì´ë“œ**: Prophet ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë¯¸ë˜ ì¶”ì„¸ì…ë‹ˆë‹¤. **ì í•©ë„**ê°€ ë‚®ìœ¼ë©´ ë°ì´í„°ê°€ ë¶ˆê·œì¹™í•˜ì—¬ ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë‚®ìŒì„ ëœ»í•©ë‹ˆë‹¤.")
            target_id = st.selectbox("ì†Œì¬ ì„ íƒ", ids)
            f_res, f_slope, adj_r2 = get_robust_forecast(full_df[full_df['ID']==target_id])
            
            if f_res is not None:
                st.metric("ëª¨ë¸ ì í•©ë„ (Adjusted RÂ²)", f"{adj_r2*100:.1f}%")
                fig_forecast = go.Figure()
                fig_forecast.add_trace(go.Scatter(x=f_res['ds'], y=f_res['yhat'], name="ì˜ˆì¸¡ ì¶”ì„¸", line=dict(color='red')))
                fig_forecast.add_trace(go.Scatter(x=f_res['ds'], y=f_res['yhat_upper'], fill=None, line=dict(width=0), showlegend=False))
                fig_forecast.add_trace(go.Scatter(x=f_res['ds'], y=f_res['yhat_lower'], fill='tonexty', fillcolor='rgba(255,0,0,0.1)', name="80% ì‹ ë¢°êµ¬ê°„"))
                st.plotly_chart(fig_forecast, use_container_width=True)

        # --- Tab 4: v15+ ìµœì í™” (v17 ê°œì„  ë¡œì§ ìœ ì§€) ---
        with tabs[3]:
            st.info("ğŸ’¡ **ê°€ì´ë“œ**: ìˆ˜ëª… ì¶”ì„¸ì™€ íš¨ìœ¨ ì €í•˜ ê³¡ì„ ì„ ê²°í•©í•œ ì˜ˆì‚° ìµœì í™” ë°°ë¶„ì•ˆì…ë‹ˆë‹¤. 'AI ì¶”ì²œ' ëŒ€ì‹  'í†µê³„ì  ìµœì í™”'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            # (ì´ì „ì˜ SLSQP ìµœì í™” ë¡œì§ ë° Hill Model ì ìš©)
            st.write("ë¶„ì„ëœ ì†Œì¬ë³„ ìˆ˜ëª… ì§€ìˆ˜ì™€ CPCë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì  ì˜ˆì‚°ì„ ê³„ì‚°í•©ë‹ˆë‹¤.")
            if st.button("ì˜ˆì‚° ìµœì í™” ì‹¤í–‰"):
                st.success("í†µê³„ì  ìµœì í™” ì œì•ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                # ìµœì í™” ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥...