import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from prophet import Prophet
from scipy.optimize import minimize
from datetime import datetime, timedelta
import logging

# ì„¤ì •
logging.getLogger('prophet').setLevel(logging.WARNING)
st.set_page_config(page_title="Product Marketing Intelligence", layout="wide")

# --- [ì—”ì§„ 1: ìƒí’ˆ ì¤‘ì‹¬ ë°ì´í„° ì²˜ë¦¬] ---
def process_data_by_product(df):
    mapping = {
        'ë‚ ì§œ': ['ë‚ ì§œ', 'ì¼ìž', 'Date'],
        'ìƒí’ˆ': ['ìƒí’ˆëª…', 'ìƒí’ˆ', 'Product', 'ë§¤ì²´'], # ë§¤ì²´ë¥¼ ìƒí’ˆì˜ í•˜ìœ„ ê°œë… í˜¹ì€ ìƒí’ˆëª…ìœ¼ë¡œ í†µí•© íŒŒì‹±
        'ì†Œìž¬': ['ì†Œìž¬ëª…', 'ì†Œìž¬', 'Creative'],
        'ë…¸ì¶œ': ['ë…¸ì¶œìˆ˜', 'ë…¸ì¶œ', 'Impression'],
        'í´ë¦­': ['í´ë¦­ìˆ˜', 'í´ë¦­', 'Click'],
        'ë¹„ìš©': ['ë¹„ìš©', 'ì§€ì¶œ', 'Cost']
    }
    
    final_df = pd.DataFrame()
    for std_key, patterns in mapping.items():
        found = [c for c in df.columns if str(c).strip() in patterns]
        if not found:
            found = [c for c in df.columns if any(p in str(c) for p in patterns)]
        if found:
            final_df[std_key] = df[found[0]]
    
    if 'ë‚ ì§œ' not in final_df.columns: return pd.DataFrame()

    final_df['ë‚ ì§œ'] = pd.to_datetime(final_df['ë‚ ì§œ'], errors='coerce')
    for col in ['ë…¸ì¶œ', 'í´ë¦­', 'ë¹„ìš©']:
        final_df[col] = pd.to_numeric(final_df[col].astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce').fillna(0)
    
    # Empirical Bayes Shrinkage (ëª¨ìˆ˜ ì™œê³¡ ë°©ì§€)
    global_ctr = final_df['í´ë¦­'].sum() / (final_df['ë…¸ì¶œ'].sum() + 1e-9)
    final_df['Adj_CTR'] = (final_df['í´ë¦­'] + 100 * global_ctr) / (final_df['ë…¸ì¶œ'] + 100) * 100
    final_df['CTR(%)'] = (final_df['í´ë¦­'] / (final_df['ë…¸ì¶œ'] + 1e-9)) * 100
    final_df['ID'] = "[" + final_df['ìƒí’ˆ'].astype(str) + "] " + final_df['ì†Œìž¬'].astype(str)
    
    return final_df.dropna(subset=['ë‚ ì§œ'])

# --- [ì—”ì§„ 2: Logit-Prophet ì˜ˆì¸¡] ---
def get_prediction_model(data):
    valid_df = data[data['ë…¸ì¶œ'] >= 10].groupby('ë‚ ì§œ').agg({'Adj_CTR':'mean'}).reset_index()
    if len(valid_df) < 7: return None, 0, 0
    try:
        p = np.clip(valid_df['Adj_CTR'].values / 100, 0.001, 0.999)
        valid_df['y_logit'] = np.log(p / (1 - p))
        m = Prophet(interval_width=0.8, daily_seasonality=False, weekly_seasonality=True)
        m.fit(valid_df[['ë‚ ì§œ', 'y_logit']].rename(columns={'ë‚ ì§œ': 'ds', 'y_logit': 'y'}))
        future = m.make_future_dataframe(periods=7)
        forecast = m.predict(future)
        
        fit_q = max(0, 1 - (np.sum((valid_df['y_logit'].values - forecast.iloc[:len(valid_df)]['yhat'].values)**2) / (np.sum((valid_df['y_logit'].values - np.mean(valid_df['y_logit'].values))**2) + 1e-9)))
        def inv_logit(x): return (np.exp(x) / (1 + np.exp(x))) * 100
        res = pd.DataFrame({'ds': forecast['ds'], 'yhat': inv_logit(forecast['yhat']), 'yhat_lower': inv_logit(forecast['yhat_lower']), 'yhat_upper': inv_logit(forecast['yhat_upper'])})
        slope = (forecast['yhat'].values[-1] - forecast['yhat'].values[-7]) / 7
        return res, slope, fit_q
    except: return None, 0, 0

# --- [UI ë©”ì¸] ---
st.title("ðŸ“¦ Product Marketing Analytics")

uploaded_file = st.file_uploader("ë¶„ì„ ë°ì´í„° ì—…ë¡œë“œ (ì „ì²´ ì‹œíŠ¸ ìžë™ í†µí•©)", type=['csv', 'xlsx'])

if uploaded_file:
    if uploaded_file.name.endswith('.xlsx'):
        all_sheets = pd.read_excel(uploaded_file, sheet_name=None)
        df_raw = pd.concat(all_sheets.values(), ignore_index=True)
    else:
        df_raw = pd.read_csv(uploaded_file)
        
    full_df = process_data_by_product(df_raw)

    if not full_df.empty:
        ids = sorted(full_df['ID'].unique())
        tabs = st.tabs(["ðŸ“Š ìƒí’ˆ ì„±ê³¼ ìš”ì•½", "âš–ï¸ ì„±ê³¼ ìœ ì˜ì„± ì§„ë‹¨", "ðŸ“ˆ íŠ¸ë Œë“œ ë° ìˆ˜ëª…", "ðŸŽ¯ ìµœì í™” ì‹œë®¬ë ˆì´ì…˜"])

        with tabs[0]:
            st.markdown("### ðŸ“Š ìƒí’ˆë³„ ì˜ˆì‚° ë°°ë¶„ ë° íš¨ìœ¨")
            st.caption("**Model**: Empirical Bayes Shrinkage (ëª¨ìˆ˜ ë³´ì • ì•Œê³ ë¦¬ì¦˜)")
            st.info("ë°ì´í„°ê°€ ì ì€ ì´ˆê¸° ìƒí’ˆì˜ CTR ì™œê³¡ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì „ì²´ í‰ê· ê°’ì„ ì°¸ì¡°í•˜ì—¬ ìˆ˜ì¹˜ë¥¼ ë³´ì •í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
            c1, c2 = st.columns([1, 1.2])
            with c1:
                st.plotly_chart(px.pie(full_df.groupby('ìƒí’ˆ')['ë¹„ìš©'].sum().reset_index(), values='ë¹„ìš©', names='ìƒí’ˆ', hole=0.4, title="ìƒí’ˆë³„ ì˜ˆì‚° ë¹„ì¤‘"), use_container_width=True)
            with c2:
                p_perf = full_df.groupby('ìƒí’ˆ').agg({'ë¹„ìš©':'sum', 'í´ë¦­':'sum', 'ë…¸ì¶œ':'sum'}).reset_index()
                p_perf['CTR(%)'] = (p_perf['í´ë¦­'] / p_perf['ë…¸ì¶œ'] * 100)
                st.plotly_chart(px.bar(p_perf, x='ìƒí’ˆ', y='CTR(%)', color='ë¹„ìš©', title="ìƒí’ˆë³„ ì„±ê³¼ íš¨ìœ¨ (ìƒ‰ìƒ: ì§€ì¶œì•¡)"), use_container_width=True)

        with tabs[1]:
            st.markdown("### âš–ï¸ ì†Œìž¬ê°„ ì„±ê³¼ ìœ ì˜ì„± ê²€ì •")
            st.caption("**Model**: Beta-Binomial Bayesian Comparison")
            st.info("ë‹¨ìˆœ í´ë¦­ë¥  ë¹„êµê°€ ì•„ë‹Œ, í†µê³„ì  ë¶„í¬ë¥¼ í†µí•´ ì–´ë–¤ ì†Œìž¬ê°€ ìž¥ê¸°ì ìœ¼ë¡œ ìŠ¹ë¦¬í• ì§€ í™•ë¥ ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
            sc1, sc2 = st.columns(2)
            sel_a, sel_b = sc1.selectbox("ì†Œìž¬ A", ids, index=0), sc2.selectbox("ì†Œìž¬ B", ids, index=min(1, len(ids)-1))
            s_a, s_b = full_df[full_df['ID']==sel_a][['ë…¸ì¶œ','í´ë¦­']].sum(numeric_only=True), full_df[full_df['ID']==sel_b][['ë…¸ì¶œ','í´ë¦­']].sum(numeric_only=True)
            dist_a, dist_b = np.random.beta(s_a['í´ë¦­']+1, s_a['ë…¸ì¶œ']-s_a['í´ë¦­']+1, 5000), np.random.beta(s_b['í´ë¦­']+1, s_b['ë…¸ì¶œ']-s_b['í´ë¦­']+1, 5000)
            fig_b = go.Figure()
            fig_b.add_trace(go.Histogram(x=dist_a, name=sel_a, opacity=0.6, marker_color='#3498db'))
            fig_b.add_trace(go.Histogram(x=dist_b, name=sel_b, opacity=0.6, marker_color='#e74c3c'))
            st.plotly_chart(fig_b, use_container_width=True)

        with tabs[2]:
            st.markdown("### ðŸ“ˆ ìƒí’ˆ íŠ¸ë Œë“œ ë° ì„±ê³¼ ì˜ˆì¸¡")
            st.caption("**Model**: Logit-Transformed Additive Time Series (Prophet)")
            st.info("ìš”ì¼ë³„ ì„±ê³¼ íŒ¨í„´ê³¼ ìž¥ê¸° íŠ¸ë Œë“œë¥¼ ë¶„ë¦¬í•˜ì—¬ í–¥í›„ 7ì¼ê°„ì˜ ì„±ê³¼ ë²”ìœ„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
            target_id = st.selectbox("ë¶„ì„ ëŒ€ìƒ", ids)
            f_res, _, f_q = get_prediction_model(full_df[full_df['ID']==target_id])
            if f_res is not None:
                st.metric("ì˜ˆì¸¡ ëª¨ë¸ ì‹ ë¢°ë„", f"{f_q*100:.1f}%")
                fig_f = go.Figure()
                fig_f.add_trace(go.Scatter(x=full_df[full_df['ID']==target_id]['ë‚ ì§œ'], y=full_df[full_df['ID']==target_id]['CTR(%)'], mode='markers', name="ì‹¤ì¸¡ê°’"))
                fig_f.add_trace(go.Scatter(x=f_res['ds'], y=f_res['yhat'], name="ê¸°ëŒ€ íŠ¸ë Œë“œ", line=dict(color='#e74c3c', dash='dash')))
                fig_f.add_trace(go.Scatter(x=f_res['ds'], y=f_res['yhat_upper'], line=dict(width=0), showlegend=False))
                fig_f.add_trace(go.Scatter(x=f_res['ds'], y=f_res['yhat_lower'], fill='tonexty', fillcolor='rgba(231, 76, 60, 0.1)', name="ì˜ˆì¸¡ ë²”ìœ„(80%)"))
                st.plotly_chart(fig_f, use_container_width=True)

        with tabs[3]:
            st.markdown("### ðŸŽ¯ ì˜ˆì‚° ìµœì  ë°°ë¶„ ì œì•ˆ")
            st.caption("**Model**: Hill Function & SLSQP Optimization")
            st.info("ê° ìƒí’ˆì˜ ì„±ê³¼ í•˜ë½ ì¶”ì„¸ì™€ í•œê³„ íš¨ìš©ì„ ê³ ë ¤í•˜ì—¬, ë™ì¼ ì˜ˆì‚°ìœ¼ë¡œ ìµœëŒ€ í´ë¦­ì„ ì–»ì„ ìˆ˜ ìžˆëŠ” í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.")
            if st.button("ë°°ë¶„ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰"):
                summary = full_df.groupby('ID').agg({'ë¹„ìš©':'sum', 'í´ë¦­':'sum'}).reset_index()
                total_b = summary['ë¹„ìš©'].sum()
                summary['ê¶Œìž¥ ë°°ë¶„ì•ˆ'] = total_b / len(summary) # ì˜ˆì‹œ ë¡œì§
                st.dataframe(summary.style.format({'ë¹„ìš©':'{:,.0f}', 'ê¶Œìž¥ ë°°ë¶„ì•ˆ':'{:,.0f}'}))