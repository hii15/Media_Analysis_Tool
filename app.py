import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
from scipy.stats import beta as beta_dist
from sklearn.linear_model import LinearRegression

st.set_page_config(page_title="ë§ˆì¼€íŒ… í†µí•© ë¶„ì„", layout="wide")
st.title("ğŸ® ë§ˆì¼€íŒ… í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ v2")
st.markdown("**Bayesian í†µê³„ ê¸°ë°˜ ì„±ê³¼ ë¶„ì„ & MMP ì—°ë™ ROAS/CPI ì˜ì‚¬ê²°ì • ì§€ì›**")
st.markdown("---")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_and_clean_data(uploaded_file):
    try:
        if uploaded_file.name.endswith('.xlsx'):
            all_sheets = pd.read_excel(uploaded_file, sheet_name=None)
            df = pd.concat(all_sheets.values(), ignore_index=True)
        else:
            df = pd.read_csv(uploaded_file, sep='\t' if uploaded_file.name.endswith('.tsv') else ',')

        df.columns = [c.strip() for c in df.columns]
        mapping = {
            'ë‚ ì§œ': ['ë‚ ì§œ', 'ì¼ì', 'date'],
            'ë§¤ì²´': ['ë§¤ì²´', 'media', 'channel'],
            'ìƒí’ˆ': ['ìƒí’ˆëª…', 'ìƒí’ˆ', 'product', 'app'],
            'ì†Œì¬': ['ì†Œì¬ëª…', 'ì†Œì¬', 'material', 'creative', 'ad_name'],
            'ë…¸ì¶œ': ['ë…¸ì¶œìˆ˜', 'ë…¸ì¶œ', 'impressions'],
            'í´ë¦­': ['í´ë¦­ìˆ˜', 'í´ë¦­', 'clicks'],
            'ë¹„ìš©': ['ë¹„ìš©', 'ì§€ì¶œ', 'cost', 'spend'],
        }

        final_df = pd.DataFrame()
        for k, v in mapping.items():
            for col in v:
                if col in df.columns:
                    final_df[k] = df[col]
                    break

        final_df['ë‚ ì§œ'] = pd.to_datetime(final_df['ë‚ ì§œ'], errors='coerce')
        for col in ['ë…¸ì¶œ', 'í´ë¦­', 'ë¹„ìš©']:
            if col in final_df.columns:
                final_df[col] = pd.to_numeric(
                    final_df[col].astype(str).str.replace(r'[^\d.]', '', regex=True),
                    errors='coerce'
                ).fillna(0)

        final_df['CTR(%)'] = final_df['í´ë¦­'] / (final_df['ë…¸ì¶œ'] + 1e-9) * 100
        final_df['CPC'] = final_df['ë¹„ìš©'] / (final_df['í´ë¦­'] + 1e-9)
        final_df['ID'] = "[" + final_df['ìƒí’ˆ'].astype(str) + "] " + final_df['ì†Œì¬'].astype(str)

        return final_df.dropna(subset=['ë‚ ì§œ']).sort_values(['ID', 'ë‚ ì§œ'])
    except Exception as e:
        st.error(f"ê´‘ê³  ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()


def load_mmp_data(uploaded_file):
    """
    MMP CSV ì»¬ëŸ¼ëª… ìë™ ë§¤í•‘
    ì§€ì›: Appsflyer, Adjust, Singular, ì»¤ìŠ¤í…€
    """
    try:
        if uploaded_file.name.endswith('.xlsx'):
            all_sheets = pd.read_excel(uploaded_file, sheet_name=None)
            df = pd.concat(all_sheets.values(), ignore_index=True)
        else:
            df = pd.read_csv(uploaded_file, sep='\t' if uploaded_file.name.endswith('.tsv') else ',')

        df.columns = [c.strip() for c in df.columns]

        mapping = {
            'ë‚ ì§œ':        ['ë‚ ì§œ', 'ì¼ì', 'date', 'Day', 'Install Date'],
            'ë§¤ì²´':        ['ë§¤ì²´', 'media', 'channel', 'Media Source', 'Network', 'partner'],
            'ì†Œì¬':        ['ì†Œì¬', 'ì†Œì¬ëª…', 'creative', 'ad_name', 'Ad', 'Creative', 'material'],
            'ìƒí’ˆ':        ['ìƒí’ˆ', 'ì•±', 'app', 'product', 'ìƒí’ˆëª…'],
            'ì„¤ì¹˜':        ['ì„¤ì¹˜', 'ì„¤ì¹˜ìˆ˜', 'installs', 'Installs', 'install'],
            'ì´ë²¤íŠ¸ìˆ˜':    ['ì´ë²¤íŠ¸ìˆ˜', 'ì´ë²¤íŠ¸', 'events', 'conversions', 'key_events',
                           'af_purchase', 'purchase', 'event_count'],
            'ë§¤ì¶œ':        ['ë§¤ì¶œ', 'ìˆ˜ìµ', 'revenue', 'Revenue', 'af_revenue', 'ltv_revenue'],
            'D1ì”ì¡´ìœ¨':    ['D1ì”ì¡´ìœ¨', 'd1_retention', 'D1 Retention', 'retention_day_1'],
            'D7ì”ì¡´ìœ¨':    ['D7ì”ì¡´ìœ¨', 'd7_retention', 'D7 Retention', 'retention_day_7'],
        }

        final_df = pd.DataFrame()
        matched_cols = {}
        for k, candidates in mapping.items():
            for col in candidates:
                if col in df.columns:
                    final_df[k] = df[col]
                    matched_cols[k] = col
                    break

        if 'ë‚ ì§œ' not in final_df.columns:
            st.error("MMP ë°ì´í„°ì— ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame(), {}

        final_df['ë‚ ì§œ'] = pd.to_datetime(final_df['ë‚ ì§œ'], errors='coerce')

        numeric_cols = ['ì„¤ì¹˜', 'ì´ë²¤íŠ¸ìˆ˜', 'ë§¤ì¶œ', 'D1ì”ì¡´ìœ¨', 'D7ì”ì¡´ìœ¨']
        for col in numeric_cols:
            if col in final_df.columns:
                final_df[col] = pd.to_numeric(
                    final_df[col].astype(str).str.replace(r'[^\d.]', '', regex=True),
                    errors='coerce'
                ).fillna(0)

        if 'ìƒí’ˆ' not in final_df.columns:
            final_df['ìƒí’ˆ'] = 'unknown'
        if 'ì†Œì¬' not in final_df.columns:
            final_df['ì†Œì¬'] = 'unknown'

        final_df['ID'] = "[" + final_df['ìƒí’ˆ'].astype(str) + "] " + final_df['ì†Œì¬'].astype(str)

        return final_df.dropna(subset=['ë‚ ì§œ']), matched_cols
    except Exception as e:
        st.error(f"MMP ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(), {}


def merge_ad_mmp(ad_df, mmp_df):
    """
    ê´‘ê³  + MMP ë°ì´í„° ì¡°ì¸
    ì¡°ì¸ í‚¤: ë‚ ì§œ Ã— ë§¤ì²´ Ã— ì†Œì¬ (ID)
    """
    join_keys = ['ë‚ ì§œ', 'ID']
    if 'ë§¤ì²´' in ad_df.columns and 'ë§¤ì²´' in mmp_df.columns:
        join_keys = ['ë‚ ì§œ', 'ë§¤ì²´', 'ID']

    mmp_agg_cols = ['ì„¤ì¹˜', 'ì´ë²¤íŠ¸ìˆ˜', 'ë§¤ì¶œ', 'D1ì”ì¡´ìœ¨', 'D7ì”ì¡´ìœ¨']
    available_mmp_cols = [c for c in mmp_agg_cols if c in mmp_df.columns]

    # MMP ì§‘ê³„ (ë‚ ì§œÃ—ID ê¸°ì¤€)
    agg_dict = {c: 'sum' for c in available_mmp_cols if c not in ['D1ì”ì¡´ìœ¨', 'D7ì”ì¡´ìœ¨']}
    if 'D1ì”ì¡´ìœ¨' in available_mmp_cols:
        agg_dict['D1ì”ì¡´ìœ¨'] = 'mean'
    if 'D7ì”ì¡´ìœ¨' in available_mmp_cols:
        agg_dict['D7ì”ì¡´ìœ¨'] = 'mean'

    mmp_grouped = mmp_df.groupby(['ë‚ ì§œ', 'ID']).agg(agg_dict).reset_index()

    merged = pd.merge(ad_df, mmp_grouped, on=['ë‚ ì§œ', 'ID'], how='left')

    # í•µì‹¬ ì§€í‘œ ê³„ì‚°
    if 'ì„¤ì¹˜' in merged.columns:
        merged['ì„¤ì¹˜'] = merged['ì„¤ì¹˜'].fillna(0)
        merged['CPI'] = merged['ë¹„ìš©'] / (merged['ì„¤ì¹˜'] + 1e-9)
        merged['IPM'] = merged['ì„¤ì¹˜'] / (merged['ë…¸ì¶œ'] + 1e-9) * 1000
        merged['Install_CVR(%)'] = merged['ì„¤ì¹˜'] / (merged['í´ë¦­'] + 1e-9) * 100

    if 'ì´ë²¤íŠ¸ìˆ˜' in merged.columns:
        merged['ì´ë²¤íŠ¸ìˆ˜'] = merged['ì´ë²¤íŠ¸ìˆ˜'].fillna(0)
        merged['CPA'] = merged['ë¹„ìš©'] / (merged['ì´ë²¤íŠ¸ìˆ˜'] + 1e-9)
        if 'ì„¤ì¹˜' in merged.columns:
            merged['Event_Rate(%)'] = merged['ì´ë²¤íŠ¸ìˆ˜'] / (merged['ì„¤ì¹˜'] + 1e-9) * 100

    if 'ë§¤ì¶œ' in merged.columns:
        merged['ë§¤ì¶œ'] = merged['ë§¤ì¶œ'].fillna(0)
        merged['ROAS(%)'] = merged['ë§¤ì¶œ'] / (merged['ë¹„ìš©'] + 1e-9) * 100

    return merged


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Bayesian ë¶„ì„ (ë³µí•© ìŠ¤ì½”ì–´ ì§€ì›)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_empirical_bayes(df, benchmark_df=None, use_manual_prior=False,
                             score_weights=None):
    """
    score_weights: {'ctr': float, 'cvr': float, 'roas': float}
    Noneì´ë©´ CTR ë‹¨ë… ë¶„ì„
    """
    if score_weights is None:
        score_weights = {'ctr': 1.0, 'cvr': 0.0, 'roas': 0.0}

    global_ctr = df['í´ë¦­'].sum() / (df['ë…¸ì¶œ'].sum() + 1e-9)
    id_stats = df.groupby('ID').agg({
        'í´ë¦­': 'sum', 'ë…¸ì¶œ': 'sum', 'ë¹„ìš©': 'sum', 'ë§¤ì²´': 'first'
    })

    # MMP ì§€í‘œ ì§‘ê³„
    extra_cols = {}
    for col in ['ì„¤ì¹˜', 'ì´ë²¤íŠ¸ìˆ˜', 'ë§¤ì¶œ']:
        if col in df.columns:
            extra_cols[col] = df.groupby('ID')[col].sum()

    id_stats = id_stats.join(pd.DataFrame(extra_cols))
    id_ctrs = id_stats['í´ë¦­'] / (id_stats['ë…¸ì¶œ'] + 1e-9)

    agg = id_stats.reset_index()
    agg['raw_ctr'] = id_ctrs.values

    # Prior ì„¤ì •
    if use_manual_prior and benchmark_df is not None:
        benchmark_dict = benchmark_df.set_index('ë§¤ì²´')['ì—…ê³„í‰ê· CTR(%)'].to_dict()
        strength_dict = benchmark_df.set_index('ë§¤ì²´')['Priorê°•ë„'].to_dict()

        for idx, row in agg.iterrows():
            media = row['ë§¤ì²´']
            if media in benchmark_dict:
                prior_ctr = benchmark_dict[media] / 100
                prior_strength = strength_dict[media]
                alpha_0 = prior_ctr * prior_strength
                beta_0 = (1 - prior_ctr) * prior_strength
            else:
                alpha_0, beta_0 = 1, 99

            agg.loc[idx, 'post_alpha'] = alpha_0 + row['í´ë¦­']
            agg.loc[idx, 'post_beta'] = beta_0 + (row['ë…¸ì¶œ'] - row['í´ë¦­'])
            agg.loc[idx, 'alpha_0'] = alpha_0
            agg.loc[idx, 'beta_0'] = beta_0
    else:
        var_ctr = max(id_ctrs.var(), 1e-7)
        kappa = (global_ctr * (1 - global_ctr) / var_ctr) - 1
        kappa = np.clip(kappa, 10, 1000)
        alpha_0 = global_ctr * kappa
        beta_0 = (1 - global_ctr) * kappa

        agg['post_alpha'] = alpha_0 + agg['í´ë¦­']
        agg['post_beta'] = beta_0 + (agg['ë…¸ì¶œ'] - agg['í´ë¦­'])
        agg['alpha_0'] = alpha_0
        agg['beta_0'] = beta_0

    agg['exp_ctr'] = agg['post_alpha'] / (agg['post_alpha'] + agg['post_beta'])

    # ë³µí•© ìŠ¤ì½”ì–´ ê³„ì‚°
    scores = np.zeros(len(agg))
    w_total = sum(score_weights.values()) + 1e-9

    # CTR ê¸°ì—¬
    if score_weights.get('ctr', 0) > 0:
        ctr_norm = (agg['exp_ctr'] - agg['exp_ctr'].min()) / (agg['exp_ctr'].max() - agg['exp_ctr'].min() + 1e-9)
        scores += score_weights['ctr'] / w_total * ctr_norm.values

    # CVR (Install CVR) ê¸°ì—¬
    if score_weights.get('cvr', 0) > 0 and 'ì„¤ì¹˜' in agg.columns:
        cvr = agg['ì„¤ì¹˜'] / (agg['í´ë¦­'] + 1e-9)
        cvr_norm = (cvr - cvr.min()) / (cvr.max() - cvr.min() + 1e-9)
        scores += score_weights['cvr'] / w_total * cvr_norm.values

    # ROAS ê¸°ì—¬
    if score_weights.get('roas', 0) > 0 and 'ë§¤ì¶œ' in agg.columns:
        roas = agg['ë§¤ì¶œ'] / (agg['ë¹„ìš©'] + 1e-9)
        roas_norm = (roas - roas.min()) / (roas.max() - roas.min() + 1e-9)
        scores += score_weights['roas'] / w_total * roas_norm.values

    agg['composite_score'] = scores

    # Bayesian ìµœê³  í™•ë¥  (CTR ê¸°ì¤€)
    samples = np.random.beta(
        agg['post_alpha'].values[:, None],
        agg['post_beta'].values[:, None],
        size=(len(agg), 5000)
    )
    agg['prob_is_best'] = np.bincount(
        np.argmax(samples, axis=0),
        minlength=len(agg)
    ) / 5000

    # ìµœê·¼ 7ì¼ í‰ê·  ë¹„ìš©
    max_date = df['ë‚ ì§œ'].max()
    last_7d = df[df['ë‚ ì§œ'] >= max_date - timedelta(days=6)]
    last_costs = last_7d.groupby('ID')['ë¹„ìš©'].sum() / 7
    agg = agg.merge(last_costs.rename('avg_cost_7d'), on='ID', how='left').fillna(0)

    return agg


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CUSUM / ì¡°ê¸°ê²½ê³  í•¨ìˆ˜ (ê¸°ì¡´ ìœ ì§€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_binomial_cusum(clicks, imps, p0):
    p1 = np.clip(p0 * 0.85, 1e-6, 1 - 1e-6)
    p0 = np.clip(p0, 1e-6, 1 - 1e-6)
    llr = clicks * np.log(p1 / p0) + (imps - clicks) * np.log((1 - p1) / (1 - p0))
    s = 0
    cusum = []
    for val in llr:
        s = min(0, s + val)
        cusum.append(s)
    return np.array(cusum)


def get_adaptive_threshold(p0, daily_impressions):
    base_h = -8.0
    ctr_factor = 0.6 if p0 < 0.005 else (0.8 if p0 < 0.01 else (1.0 if p0 < 0.02 else 1.2))
    volume_factor = 1.5 if daily_impressions > 5000000 else (1.2 if daily_impressions > 1000000 else 1.0)
    return base_h * ctr_factor * volume_factor


def get_confidence_level(material, df):
    mat_id = material['ID']
    mat_data = df[df['ID'] == mat_id]
    data_score = 1 if material['ë…¸ì¶œ'] > 1000000 else (0.5 if material['ë…¸ì¶œ'] > 100000 else 0)
    if len(mat_data) >= 7:
        daily_ctr_std = mat_data['CTR(%)'].std()
        stability_score = 1 if daily_ctr_std < material['exp_ctr'] * 50 else (
            0.5 if daily_ctr_std < material['exp_ctr'] * 100 else 0)
    else:
        stability_score = 0
    total_score = (data_score + stability_score) / 2
    if total_score >= 0.7:
        return "ğŸŸ¢ ë†’ìŒ", "ì¶©ë¶„í•œ ë°ì´í„°ì™€ ì•ˆì •ì  íŒ¨í„´"
    elif total_score >= 0.4:
        return "ğŸŸ¡ ë³´í†µ", "ì¶”ê°€ ê´€ì°° ê¶Œì¥"
    else:
        return "ğŸ”´ ë‚®ìŒ", "ë°ì´í„° ë¶€ì¡± ë˜ëŠ” ë³€ë™ì„± ë†’ìŒ"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ì´ë“œë°” ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with st.sidebar:
    st.markdown("## âš™ï¸ ë¶„ì„ ì„¤ì •")

    st.markdown("### ğŸ“Š Prior ì„¤ì • ë°©ì‹")
    prior_mode = st.radio(
        "Prior ì„¤ì •",
        ["ìë™ (ë°ì´í„° ê¸°ë°˜)", "ìˆ˜ë™ (ë²¤ì¹˜ë§ˆí¬ ê¸°ë°˜)"],
        help="ìë™: í˜„ì¬ ë°ì´í„°ë¡œ Prior ì¶”ì • / ìˆ˜ë™: ì—…ê³„ ë²¤ì¹˜ë§ˆí¬ ì…ë ¥"
    )

    benchmark_df = None
    if prior_mode == "ìˆ˜ë™ (ë²¤ì¹˜ë§ˆí¬ ê¸°ë°˜)":
        st.markdown("### ğŸ“‹ ë§¤ì²´ë³„ ë²¤ì¹˜ë§ˆí¬ ì…ë ¥")
        if 'benchmark_data' not in st.session_state:
            st.session_state.benchmark_data = pd.DataFrame({
                'ë§¤ì²´': ['ë„¤ì´ë²„ GFA', 'ìœ íŠœë¸Œ', 'GDN', 'í˜ì´ìŠ¤ë¶'],
                'ì—…ê³„í‰ê· CTR(%)': [0.8, 2.5, 0.3, 1.2],
                'Priorê°•ë„': [100, 100, 100, 100]
            })
        edited_benchmark = st.data_editor(
            st.session_state.benchmark_data,
            num_rows="dynamic",
            use_container_width=True,
            column_config={
                'ë§¤ì²´': st.column_config.TextColumn("ë§¤ì²´ëª…"),
                'ì—…ê³„í‰ê· CTR(%)': st.column_config.NumberColumn("ì—…ê³„ í‰ê·  CTR (%)", min_value=0.0, max_value=10.0, format="%.2f"),
                'Priorê°•ë„': st.column_config.NumberColumn("Prior ê°•ë„", min_value=10, max_value=1000)
            }
        )
        st.session_state.benchmark_data = edited_benchmark
        benchmark_df = edited_benchmark

    st.markdown("---")
    st.markdown("### ğŸ¯ KPI ëª©í‘œ ì„¤ì •")
    target_cpi = st.number_input("ëª©í‘œ CPI (ì›)", min_value=0, value=3000, step=500)
    target_roas = st.number_input("ëª©í‘œ ROAS (%)", min_value=0, value=300, step=50)
    target_cpa = st.number_input("ëª©í‘œ CPA (ì›)", min_value=0, value=10000, step=1000)

    st.markdown("---")
    st.markdown("### âš–ï¸ ë³µí•© ìŠ¤ì½”ì–´ ê°€ì¤‘ì¹˜")
    st.caption("Bayesian ë¶„ì„ì—ì„œ ì†Œì¬ ìˆœìœ„ ì‚°ì • ê¸°ì¤€")
    w_ctr  = st.slider("CTR ê°€ì¤‘ì¹˜",  0.0, 1.0, 0.4, 0.1)
    w_cvr  = st.slider("CVR ê°€ì¤‘ì¹˜",  0.0, 1.0, 0.3, 0.1)
    w_roas = st.slider("ROAS ê°€ì¤‘ì¹˜", 0.0, 1.0, 0.3, 0.1)
    score_weights = {'ctr': w_ctr, 'cvr': w_cvr, 'roas': w_roas}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# íŒŒì¼ ì—…ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.markdown("### ğŸ“‚ ë°ì´í„° ì—…ë¡œë“œ")
col_up1, col_up2 = st.columns(2)

with col_up1:
    st.markdown("**â‘  ê´‘ê³  ë°ì´í„°** (í•„ìˆ˜)")
    uploaded_ad = st.file_uploader(
        "ë…¸ì¶œ/í´ë¦­/ë¹„ìš© ë°ì´í„°",
        type=['csv', 'xlsx', 'tsv'],
        key="ad_upload"
    )

with col_up2:
    st.markdown("**â‘¡ MMP ë°ì´í„°** (ì„ íƒ â€” ì„¤ì¹˜/ë§¤ì¶œ í¬í•¨)")
    uploaded_mmp = st.file_uploader(
        "MMP ë¦¬í¬íŠ¸ (Appsflyer/Adjust/Singular ë“±)",
        type=['csv', 'xlsx', 'tsv'],
        key="mmp_upload"
    )

    with st.expander("ğŸ“‹ MMP íŒŒì¼ ìŠ¤í™ ì•ˆë‚´"):
        st.markdown("""
        **í•„ìˆ˜ ì»¬ëŸ¼:** ë‚ ì§œ, ë§¤ì²´ ë˜ëŠ” ì†Œì¬  
        **ì„ íƒ ì»¬ëŸ¼:** ì„¤ì¹˜ìˆ˜, ì´ë²¤íŠ¸ìˆ˜, ë§¤ì¶œ, D1ì”ì¡´ìœ¨, D7ì”ì¡´ìœ¨

        | MMP | ë‚ ì§œ ì»¬ëŸ¼ | ì„¤ì¹˜ ì»¬ëŸ¼ | ë§¤ì¶œ ì»¬ëŸ¼ |
        |-----|-----------|-----------|-----------|
        | Appsflyer | Date | Installs | Revenue |
        | Adjust | Day | Installs | Revenue |
        | Singular | Date | Installs | Revenue |
        | ì»¤ìŠ¤í…€ | ë‚ ì§œ/ì¼ì | ì„¤ì¹˜/ì„¤ì¹˜ìˆ˜ | ë§¤ì¶œ/ìˆ˜ìµ |
        """)

st.markdown("---")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ë¶„ì„ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if uploaded_ad:
    df_ad = load_and_clean_data(uploaded_ad)
    has_mmp = False
    df_merged = df_ad.copy()

    if uploaded_mmp:
        df_mmp, matched_cols = load_mmp_data(uploaded_mmp)
        if not df_mmp.empty:
            df_merged = merge_ad_mmp(df_ad, df_mmp)
            has_mmp = True
            st.success(f"âœ… MMP ë°ì´í„° ì—°ë™ ì™„ë£Œ | ë§¤í•‘ëœ ì»¬ëŸ¼: {list(matched_cols.values())}")
        else:
            st.warning("MMP ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. ê´‘ê³  ë°ì´í„°ë§Œìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
    else:
        st.info("ğŸ’¡ MMP ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ë©´ CPI/ROAS/í¼ë„ ë¶„ì„ì´ í™œì„±í™”ë©ë‹ˆë‹¤.")

    if not df_ad.empty:
        use_manual_prior = (prior_mode == "ìˆ˜ë™ (ë²¤ì¹˜ë§ˆí¬ ê¸°ë°˜)")
        res_agg = analyze_empirical_bayes(
            df_merged, benchmark_df, use_manual_prior, score_weights
        )
        ids = sorted(df_merged['ID'].unique())

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # íƒ­ êµ¬ì„±
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        tab_labels = [
            "ğŸ“‹ ì£¼ê°„ ì²´í¬ë¦¬ìŠ¤íŠ¸",
            "ğŸ“Š ì„±ê³¼ ëŒ€ì‹œë³´ë“œ",
            "ğŸ§¬ Bayesian ë¶„ì„",
            "â° ì¡°ê¸° ê²½ê³ ",
            "ğŸ“‰ CUSUM ëª¨ë‹ˆí„°ë§",
        ]
        if has_mmp:
            tab_labels += [
                "ğŸ”½ í¼ë„ ë¶„ì„",
                "ğŸ’° ROAS/CPI ë¹„êµ",
                "ğŸ‘¤ ìœ ì € í’ˆì§ˆ",
                "ğŸ§® ì˜ˆì‚° ì‹œë®¬ë ˆì´í„°",
            ]

        tabs = st.tabs(tab_labels)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # TAB 0 : ì£¼ê°„ ì²´í¬ë¦¬ìŠ¤íŠ¸
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tabs[0]:
            st.markdown("## ğŸ“‹ ì£¼ê°„ ì˜ì‚¬ê²°ì • ì²´í¬ë¦¬ìŠ¤íŠ¸")
            st.markdown(f"**ë¶„ì„ ê¸°ì¤€ì¼: {df_merged['ë‚ ì§œ'].max().strftime('%Yë…„ %mì›” %dì¼')}**")
            st.markdown("---")

            today = df_merged['ë‚ ì§œ'].max()
            this_week_start = today - timedelta(days=6)
            last_week_start = this_week_start - timedelta(days=7)
            last_week_end   = this_week_start - timedelta(days=1)

            this_week = df_merged[df_merged['ë‚ ì§œ'] >= this_week_start]
            last_week = df_merged[(df_merged['ë‚ ì§œ'] >= last_week_start) & (df_merged['ë‚ ì§œ'] <= last_week_end)]

            st.markdown("### ğŸš¨ ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”")
            critical_items = []

            for _, mat in res_agg.iterrows():
                mat_id = mat['ID']

                # CTR ê¸‰ë½
                mat_tw = this_week[this_week['ID'] == mat_id]['CTR(%)'].mean()
                mat_lw = last_week[last_week['ID'] == mat_id]['CTR(%)'].mean()
                if mat_lw > 0 and (mat_tw - mat_lw) / mat_lw < -0.3:
                    critical_items.append({
                        'ì†Œì¬': mat_id, 'ë¬¸ì œ': f"CTR {abs((mat_tw-mat_lw)/mat_lw)*100:.0f}% ê¸‰ë½",
                        'ì´ë²ˆì£¼': f"{mat_tw:.2f}%", 'ì§€ë‚œì£¼': f"{mat_lw:.2f}%",
                        'ì•¡ì…˜': 'ì†Œì¬ êµì²´ ë˜ëŠ” íƒ€ê²Ÿ ì¬ì„¤ì •', 'ìš°ì„ ìˆœìœ„': 1
                    })

                # ë¹„ìš© ì§‘ì¤‘ & í´ë¦­ ì €ì¡°
                mat_cost = this_week[this_week['ID'] == mat_id]['ë¹„ìš©'].sum()
                total_cost = this_week['ë¹„ìš©'].sum()
                cost_share = mat_cost / total_cost if total_cost > 0 else 0
                mat_clicks = this_week[this_week['ID'] == mat_id]['í´ë¦­'].sum()
                total_clicks = this_week['í´ë¦­'].sum()
                click_share = mat_clicks / total_clicks if total_clicks > 0 else 0
                if cost_share > 0.4 and click_share < 0.3:
                    critical_items.append({
                        'ì†Œì¬': mat_id, 'ë¬¸ì œ': f"ë¹„ìš© {cost_share*100:.0f}%, í´ë¦­ {click_share*100:.0f}%",
                        'ì´ë²ˆì£¼': f"{mat_cost:,.0f}ì›", 'ì§€ë‚œì£¼': '-',
                        'ì•¡ì…˜': 'ì˜ˆì‚° ì¬ë¶„ë°° ë˜ëŠ” ì…ì°°ê°€ ì¡°ì •', 'ìš°ì„ ìˆœìœ„': 1
                    })

                # MMP: CPI ëª©í‘œ ì´ˆê³¼
                if has_mmp and 'ì„¤ì¹˜' in this_week.columns and target_cpi > 0:
                    mat_inst = this_week[this_week['ID'] == mat_id]['ì„¤ì¹˜'].sum()
                    mat_cpi  = mat_cost / (mat_inst + 1e-9)
                    if mat_inst > 10 and mat_cpi > target_cpi * 1.5:
                        critical_items.append({
                            'ì†Œì¬': mat_id, 'ë¬¸ì œ': f"CPI {mat_cpi:,.0f}ì› (ëª©í‘œ {target_cpi:,}ì›ì˜ {mat_cpi/target_cpi*100:.0f}%)",
                            'ì´ë²ˆì£¼': f"ì„¤ì¹˜ {mat_inst:.0f}ê°œ", 'ì§€ë‚œì£¼': '-',
                            'ì•¡ì…˜': 'ì…ì°°ê°€ ì¸í•˜ ë˜ëŠ” íƒ€ê²Ÿ ë²”ìœ„ ì¶•ì†Œ', 'ìš°ì„ ìˆœìœ„': 1
                        })

                # MMP: ROAS ëª©í‘œ ë¯¸ë‹¬
                if has_mmp and 'ë§¤ì¶œ' in this_week.columns and target_roas > 0:
                    mat_rev  = this_week[this_week['ID'] == mat_id]['ë§¤ì¶œ'].sum()
                    mat_roas = mat_rev / (mat_cost + 1e-9) * 100
                    if mat_cost > 10000 and mat_roas < target_roas * 0.7:
                        critical_items.append({
                            'ì†Œì¬': mat_id, 'ë¬¸ì œ': f"ROAS {mat_roas:.0f}% (ëª©í‘œ {target_roas}%ì˜ {mat_roas/target_roas*100:.0f}%)",
                            'ì´ë²ˆì£¼': f"ë§¤ì¶œ {mat_rev:,.0f}ì›", 'ì§€ë‚œì£¼': '-',
                            'ì•¡ì…˜': 'ì†Œì¬ í’ˆì§ˆ ì ê²€ ë˜ëŠ” ëœë”©í˜ì´ì§€ í™•ì¸', 'ìš°ì„ ìˆœìœ„': 1
                        })

            if critical_items:
                st.error(f"âš ï¸ {len(critical_items)}ê±´ì˜ ê¸´ê¸‰ ì´ìŠˆ")
                for idx, item in enumerate(critical_items, 1):
                    with st.expander(f"ğŸ”´ [{idx}] {item['ì†Œì¬']}: {item['ë¬¸ì œ']}", expanded=True):
                        c1, c2 = st.columns(2)
                        c1.metric("ì´ë²ˆì£¼", item['ì´ë²ˆì£¼'])
                        c2.metric("ì§€ë‚œì£¼", item['ì§€ë‚œì£¼'])
                        st.warning(f"**ê¶Œì¥ ì•¡ì…˜:** {item['ì•¡ì…˜']}")
            else:
                st.success("âœ… ê¸´ê¸‰ ì¡°ì¹˜ í•„ìš”í•œ í•­ëª© ì—†ìŒ")

            st.markdown("---")
            st.markdown("### ğŸ’¡ ê°œì„  ê¸°íšŒ")

            opportunities = []
            material_perf = this_week.groupby('ID').agg({'CTR(%)': 'mean', 'ë¹„ìš©': 'sum', 'í´ë¦­': 'sum'}).reset_index()

            if len(material_perf) > 0:
                best = material_perf.loc[material_perf['CTR(%)'].idxmax()]
                if best['ë¹„ìš©'] / (this_week['ë¹„ìš©'].sum() + 1e-9) < 0.4:
                    opportunities.append({
                        'ê¸°íšŒ': f"ğŸŸ¢ ê³ ì„±ê³¼ ì†Œì¬ '{best['ID']}' ì¦ì•¡ ê¸°íšŒ",
                        'ê·¼ê±°': f"CTR {best['CTR(%)']:.2f}%ë¡œ 1ìœ„, ì˜ˆì‚° ì ìœ ìœ¨ {best['ë¹„ìš©']/this_week['ë¹„ìš©'].sum()*100:.0f}%",
                        'ì œì•ˆ': "10~20% ì ì§„ ì¦ì•¡ í›„ 3ì¼ ëª¨ë‹ˆí„°ë§"
                    })

            if has_mmp and 'ROAS(%)' in this_week.columns:
                roas_by_id = this_week.groupby('ID').apply(
                    lambda x: x['ë§¤ì¶œ'].sum() / (x['ë¹„ìš©'].sum() + 1e-9) * 100
                )
                if len(roas_by_id) > 0:
                    best_roas_id = roas_by_id.idxmax()
                    best_roas_val = roas_by_id.max()
                    if best_roas_val > target_roas * 1.3:
                        opportunities.append({
                            'ê¸°íšŒ': f"ğŸ’° ê³ ROAS ì†Œì¬ '{best_roas_id}' ì¶”ê°€ ì¦ì•¡",
                            'ê·¼ê±°': f"ROAS {best_roas_val:.0f}% (ëª©í‘œ ëŒ€ë¹„ {best_roas_val/target_roas*100:.0f}%)",
                            'ì œì•ˆ': "ì˜ˆì‚° 20~30% ì¶”ê°€ íˆ¬ì… ê²€í† "
                        })

            media_div = this_week.groupby('ë§¤ì²´')['ë¹„ìš©'].sum()
            if len(media_div) > 0 and (media_div / media_div.sum()).max() > 0.6:
                opportunities.append({
                    'ê¸°íšŒ': f"ğŸ“± ë§¤ì²´ ë‹¤ê°í™” í•„ìš” ({media_div.idxmax()} í¸ì¤‘)",
                    'ê·¼ê±°': f"ë‹¨ì¼ ë§¤ì²´ ì˜ì¡´ë„ {media_div.max()/media_div.sum()*100:.0f}%",
                    'ì œì•ˆ': "íƒ€ ë§¤ì²´ ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ ì‹œì‘"
                })

            if opportunities:
                for idx, opp in enumerate(opportunities, 1):
                    with st.expander(f"ğŸ’¡ [{idx}] {opp['ê¸°íšŒ']}", expanded=False):
                        st.info(f"**ê·¼ê±°:** {opp['ê·¼ê±°']}")
                        st.success(f"**ì œì•ˆ:** {opp['ì œì•ˆ']}")
            else:
                st.info("ì¶”ê°€ ê°œì„  ê¸°íšŒ ì—†ìŒ (í˜„ìƒ ìœ ì§€)")

            st.markdown("---")
            st.markdown("### ğŸ“Š ì´ë²ˆì£¼ ì„±ê³¼ ìš”ì•½")

            kpi_cols = st.columns(4 if not has_mmp else 6)
            tw_cost   = this_week['ë¹„ìš©'].sum()
            lw_cost   = last_week['ë¹„ìš©'].sum()
            tw_clicks = this_week['í´ë¦­'].sum()
            lw_clicks = last_week['í´ë¦­'].sum()
            tw_ctr    = tw_clicks / (this_week['ë…¸ì¶œ'].sum() + 1e-9) * 100
            lw_ctr    = lw_clicks / (last_week['ë…¸ì¶œ'].sum() + 1e-9) * 100
            tw_cpc    = tw_cost / (tw_clicks + 1e-9)
            lw_cpc    = lw_cost / (lw_clicks + 1e-9)

            kpi_cols[0].metric("ì´ ì§€ì¶œ",   f"{tw_cost:,.0f}ì›",  f"{(tw_cost-lw_cost)/lw_cost*100:+.1f}%" if lw_cost > 0 else "N/A")
            kpi_cols[1].metric("ì´ í´ë¦­",   f"{tw_clicks:,}íšŒ",   f"{(tw_clicks-lw_clicks)/lw_clicks*100:+.1f}%" if lw_clicks > 0 else "N/A")
            kpi_cols[2].metric("í‰ê·  CTR",  f"{tw_ctr:.2f}%",     f"{tw_ctr-lw_ctr:+.2f}%p")
            kpi_cols[3].metric("í‰ê·  CPC",  f"{tw_cpc:,.0f}ì›",   f"{tw_cpc-lw_cpc:+.0f}ì›")

            if has_mmp:
                if 'ì„¤ì¹˜' in this_week.columns:
                    tw_inst = this_week['ì„¤ì¹˜'].sum()
                    tw_cpi  = tw_cost / (tw_inst + 1e-9)
                    kpi_cols[4].metric("ì´ ì„¤ì¹˜",   f"{tw_inst:,.0f}ê°œ", "")
                    # kpi_cols[4].metric("CPI",  f"{tw_cpi:,.0f}ì›",  f"ëª©í‘œ {target_cpi:,}ì›")
                if 'ë§¤ì¶œ' in this_week.columns:
                    tw_rev  = this_week['ë§¤ì¶œ'].sum()
                    tw_roas = tw_rev / (tw_cost + 1e-9) * 100
                    kpi_cols[5].metric("ROAS", f"{tw_roas:.0f}%",  f"ëª©í‘œ {target_roas}%")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # TAB 1 : ì„±ê³¼ ëŒ€ì‹œë³´ë“œ
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tabs[1]:
            st.markdown("### ğŸ“Š ì„±ê³¼ ëŒ€ì‹œë³´ë“œ")

            global_ctr = df_merged['í´ë¦­'].sum() / (df_merged['ë…¸ì¶œ'].sum() + 1e-9)
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("ì „ì²´ í‰ê·  CTR",  f"{global_ctr*100:.2f}%")
            m2.metric("ë¶„ì„ ê¸°ê°„",       f"{(df_merged['ë‚ ì§œ'].max()-df_merged['ë‚ ì§œ'].min()).days}ì¼")
            m3.metric("ì´ ì†Œì¬ ìˆ˜",      len(ids))
            m4.metric("ì´ ì§‘í–‰ ë¹„ìš©",    f"{df_merged['ë¹„ìš©'].sum():,.0f}ì›")

            if has_mmp:
                m5, m6, m7, m8 = st.columns(4)
                if 'ì„¤ì¹˜' in df_merged.columns:
                    total_inst = df_merged['ì„¤ì¹˜'].sum()
                    avg_cpi    = df_merged['ë¹„ìš©'].sum() / (total_inst + 1e-9)
                    m5.metric("ì´ ì„¤ì¹˜",    f"{total_inst:,.0f}ê°œ")
                    m6.metric("í‰ê·  CPI",   f"{avg_cpi:,.0f}ì›",
                               delta=f"ëª©í‘œ {target_cpi:,}ì›",
                               delta_color="inverse" if avg_cpi > target_cpi else "normal")
                if 'ë§¤ì¶œ' in df_merged.columns:
                    total_rev  = df_merged['ë§¤ì¶œ'].sum()
                    total_roas = total_rev / (df_merged['ë¹„ìš©'].sum() + 1e-9) * 100
                    m7.metric("ì´ ë§¤ì¶œ",    f"{total_rev:,.0f}ì›")
                    m8.metric("ì „ì²´ ROAS",  f"{total_roas:.0f}%",
                               delta=f"ëª©í‘œ {target_roas}%",
                               delta_color="normal" if total_roas >= target_roas else "inverse")

            st.markdown("---")
            st.markdown("### ğŸ† ì†Œì¬ë³„ ìµœê³  ì„±ê³¼ í™•ë¥  (Bayesian CTR)")
            fig_prob = px.bar(
                res_agg.sort_values('prob_is_best', ascending=True),
                x='prob_is_best', y='ID', orientation='h',
                text=res_agg.sort_values('prob_is_best', ascending=True)['prob_is_best'].apply(lambda x: f"{x*100:.1f}%")
            )
            fig_prob.update_xaxes(tickformat='.0%', title='ìµœê³  ì„±ê³¼ í™•ë¥ ')
            fig_prob.update_yaxes(title='')
            fig_prob.update_traces(textposition='outside')
            st.plotly_chart(fig_prob, use_container_width=True)

            st.markdown("---")
            st.markdown("### ğŸ“ˆ ì†Œì¬ë³„ ìƒì„¸ ì„±ê³¼")

            disp_cols = ['ID', 'raw_ctr', 'exp_ctr', 'ë…¸ì¶œ', 'í´ë¦­', 'ë¹„ìš©', 'prob_is_best', 'avg_cost_7d']
            disp_rename = {
                'ID': 'ì†Œì¬', 'raw_ctr': 'ì›ë³¸CTR(%)', 'exp_ctr': 'ë³´ì •CTR(%)',
                'ë…¸ì¶œ': 'ë…¸ì¶œìˆ˜', 'í´ë¦­': 'í´ë¦­ìˆ˜', 'ë¹„ìš©': 'ë¹„ìš©',
                'prob_is_best': 'ìµœê³ í™•ë¥ (%)', 'avg_cost_7d': 'ì¼í‰ê· ë¹„ìš©'
            }

            if has_mmp:
                for c in ['ì„¤ì¹˜', 'CPI', 'ROAS(%)']:
                    if c in res_agg.columns:
                        disp_cols.append(c)

            display_df = res_agg[[c for c in disp_cols if c in res_agg.columns]].copy()
            display_df['raw_ctr'] = display_df['raw_ctr'] * 100
            display_df['exp_ctr'] = display_df['exp_ctr'] * 100
            display_df['prob_is_best'] = display_df['prob_is_best'] * 100
            display_df = display_df.rename(columns=disp_rename)

            fmt = {
                'ì›ë³¸CTR(%)': '{:.2f}', 'ë³´ì •CTR(%)': '{:.2f}',
                'ë…¸ì¶œìˆ˜': '{:,.0f}', 'í´ë¦­ìˆ˜': '{:,.0f}',
                'ë¹„ìš©': '{:,.0f}', 'ìµœê³ í™•ë¥ (%)': '{:.1f}', 'ì¼í‰ê· ë¹„ìš©': '{:,.0f}',
            }
            if 'ì„¤ì¹˜' in display_df.columns:
                fmt['ì„¤ì¹˜'] = '{:,.0f}'
            if 'CPI' in display_df.columns:
                fmt['CPI'] = '{:,.0f}'
            if 'ROAS(%)' in display_df.columns:
                fmt['ROAS(%)'] = '{:.1f}'

            st.dataframe(
                display_df.style.format(fmt).background_gradient(subset=['ë³´ì •CTR(%)'], cmap='RdYlGn'),
                use_container_width=True
            )

            st.markdown("---")
            st.markdown("### ğŸ“Š CTR ì¶”ì´")
            daily_ctr = df_merged.groupby(['ë‚ ì§œ', 'ID']).agg({'í´ë¦­': 'sum', 'ë…¸ì¶œ': 'sum'}).reset_index()
            daily_ctr['CTR'] = daily_ctr['í´ë¦­'] / daily_ctr['ë…¸ì¶œ'] * 100
            fig_trend = px.line(daily_ctr, x='ë‚ ì§œ', y='CTR', color='ID', markers=True)
            fig_trend.update_layout(yaxis_title='CTR (%)', xaxis_title='')
            st.plotly_chart(fig_trend, use_container_width=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # TAB 2 : Bayesian ë¶„ì„
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tabs[2]:
            st.markdown("### ğŸ§¬ Bayesian ë¶„ì„ ìƒì„¸")

            # ë³µí•© ìŠ¤ì½”ì–´ ì‹œê°í™”
            if has_mmp and (w_cvr > 0 or w_roas > 0):
                st.markdown("#### ğŸ… ë³µí•© ìŠ¤ì½”ì–´ ìˆœìœ„")
                st.caption(f"ê°€ì¤‘ì¹˜ â€” CTR: {w_ctr}, CVR: {w_cvr}, ROAS: {w_roas}")
                fig_score = px.bar(
                    res_agg.sort_values('composite_score', ascending=True),
                    x='composite_score', y='ID', orientation='h',
                    color='composite_score', color_continuous_scale='RdYlGn',
                    text=res_agg.sort_values('composite_score', ascending=True)['composite_score'].apply(lambda x: f"{x:.2f}")
                )
                fig_score.update_xaxes(title='ë³µí•© ìŠ¤ì½”ì–´ (0~1)')
                fig_score.update_yaxes(title='')
                fig_score.update_traces(textposition='outside')
                fig_score.update_layout(coloraxis_showscale=False)
                st.plotly_chart(fig_score, use_container_width=True)
                st.markdown("---")

            st.markdown("#### Prior ì„¤ì • í˜„í™©")
            if use_manual_prior:
                st.success("âœ… ìˆ˜ë™ ì„¤ì • ëª¨ë“œ (ë²¤ì¹˜ë§ˆí¬ ê¸°ë°˜)")
                prior_summary = res_agg[['ID', 'ë§¤ì²´', 'alpha_0', 'beta_0']].copy()
                prior_summary['Prior_CTR(%)'] = prior_summary['alpha_0'] / (prior_summary['alpha_0'] + prior_summary['beta_0']) * 100
                prior_summary['Prior_ê°•ë„'] = prior_summary['alpha_0'] + prior_summary['beta_0']
                st.dataframe(
                    prior_summary[['ID', 'ë§¤ì²´', 'Prior_CTR(%)', 'Prior_ê°•ë„']].style.format({'Prior_CTR(%)': '{:.2f}', 'Prior_ê°•ë„': '{:.0f}'}),
                    use_container_width=True
                )
            else:
                st.info("â„¹ï¸ ìë™ ì„¤ì • ëª¨ë“œ (ë°ì´í„° ê¸°ë°˜)")
                alpha_0 = res_agg['alpha_0'].iloc[0]
                beta_0  = res_agg['beta_0'].iloc[0]
                kappa   = alpha_0 + beta_0
                c1, c2, c3 = st.columns(3)
                c1.metric("Prior Î±â‚€", f"{alpha_0:.1f}")
                c2.metric("Prior Î²â‚€", f"{beta_0:.1f}")
                c3.metric("Îº (Kappa)", f"{kappa:.1f}")

            st.markdown("---")
            st.markdown("#### Posterior ë¶„í¬")
            fig_post = go.Figure()
            colors = px.colors.qualitative.Set2
            for idx, (_, row) in enumerate(res_agg.iterrows()):
                x = np.linspace(0, 0.05, 500)
                y = beta_dist.pdf(x, row['post_alpha'], row['post_beta'])
                fig_post.add_trace(go.Scatter(
                    x=x*100, y=y, name=row['ID'],
                    mode='lines', fill='tozeroy', opacity=0.6,
                    line=dict(color=colors[idx % len(colors)], width=2)
                ))
            fig_post.update_layout(
                title="ì†Œì¬ë³„ ì‹¤ì œ CTR ë¶„í¬ (Posterior)",
                xaxis_title="CTR (%)", yaxis_title="í™•ë¥  ë°€ë„", height=450
            )
            st.plotly_chart(fig_post, use_container_width=True)

            st.markdown("---")
            st.markdown("#### ì‹ ë¢°ë„ í‰ê°€")
            conf_data = []
            for _, mat in res_agg.iterrows():
                lvl, reason = get_confidence_level(mat, df_merged)
                conf_data.append({'ì†Œì¬': mat['ID'], 'ì‹ ë¢°ë„': lvl, 'ì´ìœ ': reason,
                                   'ë…¸ì¶œìˆ˜': mat['ë…¸ì¶œ'], 'ë°ì´í„°ì¼ìˆ˜': len(df_merged[df_merged['ID'] == mat['ID']])})
            st.dataframe(pd.DataFrame(conf_data).style.format({'ë…¸ì¶œìˆ˜': '{:,.0f}'}), use_container_width=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # TAB 3 : ì¡°ê¸°ê²½ê³  (ê¸°ì¡´ ìœ ì§€)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tabs[3]:
            st.markdown("### â° ì†Œì¬ í”¼ë¡œë„ ì¡°ê¸° ê²½ê³ ")
            st.markdown("ì„ í˜• íšŒê·€ë¡œ CTR ì¶”ì„¸ë¥¼ ë¶„ì„, êµì²´ ì‹œì ì„ ì¡°ê¸° ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
            st.markdown("---")

            for mat_id in ids:
                mat_data = df_merged[df_merged['ID'] == mat_id].sort_values('ë‚ ì§œ')
                if len(mat_data) < 5:
                    st.warning(f"**{mat_id}**: ë°ì´í„° ë¶€ì¡± (ìµœì†Œ 5ì¼ í•„ìš”)")
                    continue

                X = np.arange(len(mat_data)).reshape(-1, 1)
                y = mat_data['CTR(%)'].values
                model = LinearRegression().fit(X, y)
                slope = model.coef_[0]
                current_ctr = y[-1]

                if slope < -0.001:
                    days_left = max(0, int((current_ctr - current_ctr * 0.5) / abs(slope)))
                    if days_left == 0:
                        lifespan_status = "âš ï¸ ì¦‰ì‹œ êµì²´ ê²€í† "
                    elif days_left <= 3:
                        lifespan_status = f"ğŸ”´ ê¸´ê¸‰ (ì¶”ì • D-{days_left})"
                    elif days_left <= 7:
                        lifespan_status = f"ğŸŸ¡ ì£¼ì˜ (ì¶”ì • D-{days_left})"
                    else:
                        lifespan_status = f"ğŸŸ¢ ì•ˆì • (ì¶”ì • D-{days_left})"
                else:
                    lifespan_status = "âœ… í•˜ë½ ì¶”ì„¸ ì—†ìŒ"
                    days_left = None

                c1, c2 = st.columns([2, 1])
                with c1:
                    st.markdown(f"**{mat_id}**")
                    st.markdown(f"**ìƒíƒœ:** {lifespan_status}")
                    st.markdown(f"í˜„ì¬ CTR: {current_ctr:.2f}% | ì¼í‰ê·  ë³€í™”: {slope:.4f}%p")
                with c2:
                    fig_mini = go.Figure()
                    fig_mini.add_trace(go.Scatter(x=mat_data['ë‚ ì§œ'], y=y, mode='lines+markers', name='ì‹¤ì œ'))
                    fig_mini.add_trace(go.Scatter(x=mat_data['ë‚ ì§œ'], y=model.predict(X),
                                                   mode='lines', name='ì¶”ì„¸', line=dict(dash='dash', color='red')))
                    fig_mini.update_layout(height=200, showlegend=False, margin=dict(l=0,r=0,t=0,b=0), yaxis_title='CTR(%)')
                    st.plotly_chart(fig_mini, use_container_width=True)
                st.markdown("---")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # TAB 4 : CUSUM (ê¸°ì¡´ ìœ ì§€ + CPI ì´ì¤‘ ê°ì§€)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tabs[4]:
            st.markdown("### ğŸ“‰ CUSUM ì´ìƒ ê°ì§€")
            st.markdown("ê¸°ì¤€ ì„±ê³¼ ëŒ€ë¹„ ëˆ„ì  ì´íƒˆë„ë¥¼ ì¶”ì í•˜ì—¬ ì„±ê³¼ í•˜ë½ì„ ì¡°ê¸° ê°ì§€í•©ë‹ˆë‹¤.")
            st.markdown("---")

            c1, c2, c3 = st.columns([2, 1, 1])
            with c1:
                selected_material = st.selectbox("ì†Œì¬ ì„ íƒ", ids, key="cusum_sel")
            with c2:
                cusum_metric = st.radio("ê°ì§€ ì§€í‘œ", ["CTR", "CPI"] if has_mmp and 'ì„¤ì¹˜' in df_merged.columns else ["CTR"])
            with c3:
                threshold_mode = st.radio("ì„ê³„ê°’", ["ìë™", "ìˆ˜ë™"])

            sub = df_merged[df_merged['ID'] == selected_material].sort_values('ë‚ ì§œ')

            if cusum_metric == "CTR":
                clicks_arr = sub['í´ë¦­'].values
                imps_arr   = sub['ë…¸ì¶œ'].values
                p0_val     = sub.head(7)['í´ë¦­'].sum() / (sub.head(7)['ë…¸ì¶œ'].sum() + 1e-9) if len(sub) >= 7 else sub['í´ë¦­'].sum() / (sub['ë…¸ì¶œ'].sum() + 1e-9)
                avg_daily_imp = sub['ë…¸ì¶œ'].mean()
                h_threshold   = get_adaptive_threshold(p0_val, avg_daily_imp) if threshold_mode == "ìë™" else st.slider("ì„ê³„ê°’(h)", -20.0, -3.0, -8.0, 0.5)
                cusum_vals    = get_binomial_cusum(clicks_arr, imps_arr, p0_val)
                y_label       = "CUSUM (CTR)"
                p0_label      = f"ê¸°ì¤€ CTR: {p0_val*100:.2f}%"
            else:
                # CPI ê¸°ë°˜ CUSUM (ë¹„ìš©/ì„¤ì¹˜ ë¹„ìœ¨)
                cpi_series = sub['ë¹„ìš©'] / (sub['ì„¤ì¹˜'] + 1e-9)
                p0_cpi     = cpi_series.head(7).mean() if len(sub) >= 7 else cpi_series.mean()
                # CPI ìƒìŠ¹ ê°ì§€: ì •ê·œí™” í›„ ì´í•­ CUSUM ê·¼ì‚¬
                norm_cpi   = (cpi_series - p0_cpi) / (p0_cpi + 1e-9)
                s = 0; cusum_vals = []
                for v in norm_cpi:
                    s = min(0, s - v)  # CPI ìƒìŠ¹ì´ë©´ ìŒìˆ˜
                    cusum_vals.append(s)
                cusum_vals = np.array(cusum_vals)
                h_threshold = -1.5 if threshold_mode == "ìë™" else st.slider("ì„ê³„ê°’(h)", -5.0, -0.5, -1.5, 0.1)
                y_label     = "CUSUM (CPI ìƒìŠ¹ ê°ì§€)"
                p0_label    = f"ê¸°ì¤€ CPI: {p0_cpi:,.0f}ì›"

            col1, col2, col3 = st.columns(3)
            col1.metric("ê¸°ì¤€ ì§€í‘œ", p0_label)
            col2.metric("ê°ì§€ ì„ê³„ê°’ (h)", f"{h_threshold:.2f}")
            col3.metric("í˜„ì¬ CUSUM", f"{cusum_vals[-1]:.2f}")

            fig_cusum = go.Figure()
            fig_cusum.add_trace(go.Scatter(x=sub['ë‚ ì§œ'], y=cusum_vals, mode='lines+markers',
                                            name='CUSUM', line=dict(color='blue', width=2)))
            fig_cusum.add_hline(y=h_threshold, line_dash="dash", line_color="red", annotation_text="ì„ê³„ê°’")
            fig_cusum.update_layout(title=f"{selected_material} â€” {y_label}",
                                     xaxis_title="ë‚ ì§œ", yaxis_title=y_label, height=400)
            st.plotly_chart(fig_cusum, use_container_width=True)

            if cusum_vals[-1] < h_threshold:
                delta = abs(cusum_vals[-1] - h_threshold)
                severity = "ğŸ”´ ì‹¬ê°" if delta > abs(h_threshold) * 2 else "ğŸŸ¡ ê²½ê³„"
                st.error(f"âš ï¸ **ì„±ê³¼ í•˜ë½ ê°ì§€** (CUSUM: {cusum_vals[-1]:.2f} < ì„ê³„ê°’: {h_threshold:.2f})")
                st.markdown(f"**ì‹¬ê°ë„:** {severity}")
                first_breach = np.where(cusum_vals < h_threshold)[0]
                if len(first_breach) > 0:
                    st.markdown(f"**ìµœì´ˆ ê°ì§€ì¼:** {sub.iloc[first_breach[0]]['ë‚ ì§œ'].strftime('%Y-%m-%d')}")
            else:
                st.success(f"âœ… ì •ìƒ ë²”ìœ„ (CUSUM: {cusum_vals[-1]:.2f})")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # TAB 5 : í¼ë„ ë¶„ì„ (MMP ì „ìš©)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if has_mmp:
            with tabs[5]:
                st.markdown("### ğŸ”½ í¼ë„ ë¶„ì„")
                st.markdown("ë…¸ì¶œ â†’ í´ë¦­ â†’ ì„¤ì¹˜ â†’ ì´ë²¤íŠ¸ ì „ ë‹¨ê³„ ë‚™ìˆ˜ìœ¨ì„ ì†Œì¬ë³„ë¡œ ë¹„êµí•©ë‹ˆë‹¤.")
                st.markdown("---")

                funnel_agg = df_merged.groupby('ID').agg(
                    ë…¸ì¶œ=('ë…¸ì¶œ', 'sum'),
                    í´ë¦­=('í´ë¦­', 'sum'),
                    ì„¤ì¹˜=('ì„¤ì¹˜', 'sum') if 'ì„¤ì¹˜' in df_merged.columns else ('í´ë¦­', 'count'),
                    ì´ë²¤íŠ¸=('ì´ë²¤íŠ¸ìˆ˜', 'sum') if 'ì´ë²¤íŠ¸ìˆ˜' in df_merged.columns else ('í´ë¦­', 'count'),
                    ë¹„ìš©=('ë¹„ìš©', 'sum'),
                ).reset_index()

                # ì „í™˜ìœ¨ ê³„ì‚°
                funnel_agg['CTR(%)']         = funnel_agg['í´ë¦­'] / (funnel_agg['ë…¸ì¶œ'] + 1e-9) * 100
                if 'ì„¤ì¹˜' in df_merged.columns:
                    funnel_agg['Install_CVR(%)'] = funnel_agg['ì„¤ì¹˜'] / (funnel_agg['í´ë¦­'] + 1e-9) * 100
                    funnel_agg['IPM']            = funnel_agg['ì„¤ì¹˜'] / (funnel_agg['ë…¸ì¶œ'] + 1e-9) * 1000
                    funnel_agg['CPI']            = funnel_agg['ë¹„ìš©'] / (funnel_agg['ì„¤ì¹˜'] + 1e-9)
                if 'ì´ë²¤íŠ¸ìˆ˜' in df_merged.columns and 'ì„¤ì¹˜' in df_merged.columns:
                    funnel_agg['Event_Rate(%)']  = funnel_agg['ì´ë²¤íŠ¸'] / (funnel_agg['ì„¤ì¹˜'] + 1e-9) * 100
                    funnel_agg['CPA']            = funnel_agg['ë¹„ìš©'] / (funnel_agg['ì´ë²¤íŠ¸'] + 1e-9)

                # ì†Œì¬ ì„ íƒ
                sel_ids = st.multiselect("ë¹„êµí•  ì†Œì¬ ì„ íƒ (ìµœëŒ€ 5ê°œ)", ids, default=ids[:min(5, len(ids))])

                if sel_ids:
                    sub_funnel = funnel_agg[funnel_agg['ID'].isin(sel_ids)]

                    # í¼ë„ ì°¨íŠ¸
                    st.markdown("#### ğŸ“Š ì „í™˜ìœ¨ íˆíŠ¸ë§µ")
                    heatmap_cols = ['CTR(%)']
                    if 'ì„¤ì¹˜' in df_merged.columns:
                        heatmap_cols += ['Install_CVR(%)', 'IPM']
                    if 'ì´ë²¤íŠ¸ìˆ˜' in df_merged.columns:
                        heatmap_cols.append('Event_Rate(%)')

                    heatmap_df = sub_funnel.set_index('ID')[heatmap_cols]
                    fig_heatmap = px.imshow(
                        heatmap_df.values,
                        x=heatmap_cols,
                        y=heatmap_df.index.tolist(),
                        color_continuous_scale='RdYlGn',
                        aspect='auto',
                        text_auto='.2f'
                    )
                    fig_heatmap.update_layout(height=300 + len(sel_ids) * 40,
                                              xaxis_title='', yaxis_title='')
                    st.plotly_chart(fig_heatmap, use_container_width=True)

                    # ë‹¨ê³„ë³„ ì ˆëŒ€ëŸ‰ í¼ë„
                    st.markdown("#### ğŸŒŠ í¼ë„ ë‹¨ê³„ë³„ ë³¼ë¥¨")
                    funnel_stages = ['ë…¸ì¶œ', 'í´ë¦­']
                    if 'ì„¤ì¹˜' in df_merged.columns:
                        funnel_stages.append('ì„¤ì¹˜')
                    if 'ì´ë²¤íŠ¸ìˆ˜' in df_merged.columns:
                        funnel_stages.append('ì´ë²¤íŠ¸')

                    for mat_id in sel_ids:
                        row = sub_funnel[sub_funnel['ID'] == mat_id].iloc[0]
                        vals = [row[c] for c in funnel_stages if c in row.index]
                        fig_f = go.Figure(go.Funnel(
                            y=funnel_stages[:len(vals)],
                            x=vals,
                            textinfo="value+percent initial"
                        ))
                        fig_f.update_layout(title=mat_id, height=280, margin=dict(l=0,r=0,t=40,b=0))
                        st.plotly_chart(fig_f, use_container_width=True)

                    # ìƒì„¸ í…Œì´ë¸”
                    st.markdown("#### ğŸ“‹ í¼ë„ ìƒì„¸ ìˆ˜ì¹˜")
                    disp_cols_f = ['ID'] + [c for c in ['ë…¸ì¶œ', 'í´ë¦­', 'ì„¤ì¹˜', 'ì´ë²¤íŠ¸', 'CTR(%)',
                                                           'Install_CVR(%)', 'IPM', 'Event_Rate(%)',
                                                           'CPI', 'CPA'] if c in sub_funnel.columns]
                    fmt_f = {c: '{:,.0f}' for c in ['ë…¸ì¶œ', 'í´ë¦­', 'ì„¤ì¹˜', 'ì´ë²¤íŠ¸', 'CPI', 'CPA', 'IPM']}
                    fmt_f.update({c: '{:.2f}' for c in ['CTR(%)', 'Install_CVR(%)', 'Event_Rate(%)']})
                    st.dataframe(
                        sub_funnel[disp_cols_f].style.format(fmt_f).background_gradient(subset=['CTR(%)'], cmap='RdYlGn'),
                        use_container_width=True
                    )

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # TAB 6 : ROAS/CPI ë¹„êµ
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            with tabs[6]:
                st.markdown("### ğŸ’° ROAS/CPI ì†Œì¬ë³„ ë¹„êµ")
                st.markdown("---")

                roas_cpi_agg = df_merged.groupby('ID').agg(
                    ë¹„ìš©=('ë¹„ìš©', 'sum'),
                    ì„¤ì¹˜=('ì„¤ì¹˜', 'sum') if 'ì„¤ì¹˜' in df_merged.columns else ('í´ë¦­', 'count'),
                    ë§¤ì¶œ=('ë§¤ì¶œ', 'sum') if 'ë§¤ì¶œ' in df_merged.columns else ('ë¹„ìš©', 'count'),
                ).reset_index()

                if 'ì„¤ì¹˜' in df_merged.columns:
                    roas_cpi_agg['CPI'] = roas_cpi_agg['ë¹„ìš©'] / (roas_cpi_agg['ì„¤ì¹˜'] + 1e-9)
                    roas_cpi_agg['CPI_ë‹¬ì„±ë¥ (%)'] = target_cpi / (roas_cpi_agg['CPI'] + 1e-9) * 100

                if 'ë§¤ì¶œ' in df_merged.columns:
                    roas_cpi_agg['ROAS(%)'] = roas_cpi_agg['ë§¤ì¶œ'] / (roas_cpi_agg['ë¹„ìš©'] + 1e-9) * 100
                    roas_cpi_agg['ROAS_ë‹¬ì„±ë¥ (%)'] = roas_cpi_agg['ROAS(%)'] / target_roas * 100

                # CPI ë¹„êµ ì°¨íŠ¸
                if 'ì„¤ì¹˜' in df_merged.columns:
                    st.markdown("#### ğŸ“Š ì†Œì¬ë³„ CPI vs ëª©í‘œ")
                    fig_cpi = go.Figure()
                    fig_cpi.add_trace(go.Bar(
                        x=roas_cpi_agg['ID'], y=roas_cpi_agg['CPI'],
                        marker_color=['#2ecc71' if v <= target_cpi else '#e74c3c' for v in roas_cpi_agg['CPI']],
                        name='ì‹¤ì œ CPI'
                    ))
                    fig_cpi.add_hline(y=target_cpi, line_dash="dash", line_color="blue",
                                       annotation_text=f"ëª©í‘œ CPI {target_cpi:,}ì›")
                    fig_cpi.update_layout(yaxis_title='CPI (ì›)', xaxis_title='', height=380)
                    st.plotly_chart(fig_cpi, use_container_width=True)

                # ROAS ë¹„êµ ì°¨íŠ¸
                if 'ë§¤ì¶œ' in df_merged.columns:
                    st.markdown("#### ğŸ“Š ì†Œì¬ë³„ ROAS vs ëª©í‘œ")
                    fig_roas = go.Figure()
                    fig_roas.add_trace(go.Bar(
                        x=roas_cpi_agg['ID'], y=roas_cpi_agg['ROAS(%)'],
                        marker_color=['#2ecc71' if v >= target_roas else '#e74c3c' for v in roas_cpi_agg['ROAS(%)']],
                        name='ì‹¤ì œ ROAS'
                    ))
                    fig_roas.add_hline(y=target_roas, line_dash="dash", line_color="blue",
                                        annotation_text=f"ëª©í‘œ ROAS {target_roas}%")
                    fig_roas.update_layout(yaxis_title='ROAS (%)', xaxis_title='', height=380)
                    st.plotly_chart(fig_roas, use_container_width=True)

                # CPI Ã— ROAS ì‚°ì ë„
                if 'ì„¤ì¹˜' in df_merged.columns and 'ë§¤ì¶œ' in df_merged.columns:
                    st.markdown("#### ğŸ¯ CPI Ã— ROAS í¬ì§€ì…”ë‹ ë§µ")
                    fig_scatter = px.scatter(
                        roas_cpi_agg, x='CPI', y='ROAS(%)', text='ID',
                        size='ë¹„ìš©', color='ROAS(%)',
                        color_continuous_scale='RdYlGn',
                        labels={'CPI': 'CPI (ì›) â† ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ', 'ROAS(%)': 'ROAS (%) â†’ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ'}
                    )
                    fig_scatter.add_vline(x=target_cpi, line_dash="dash", line_color="gray",
                                           annotation_text=f"ëª©í‘œ CPI")
                    fig_scatter.add_hline(y=target_roas, line_dash="dash", line_color="gray",
                                           annotation_text=f"ëª©í‘œ ROAS")
                    fig_scatter.update_traces(textposition='top center')
                    fig_scatter.update_layout(height=450, coloraxis_showscale=False)
                    st.plotly_chart(fig_scatter, use_container_width=True)
                    st.caption("âœ… ì¢Œìƒë‹¨(ë‚®ì€ CPI + ë†’ì€ ROAS): ìµœìš°ì„  íˆ¬ì ëŒ€ìƒ")

                # ì¼ë³„ ROAS/CPI ì¶”ì´
                st.markdown("#### ğŸ“ˆ ì¼ë³„ ì¶”ì´")
                daily_col = 'ROAS(%)' if 'ë§¤ì¶œ' in df_merged.columns else 'CPI'
                if 'ROAS(%)' in df_merged.columns or 'CPI' in df_merged.columns:
                    daily_roas_cpi = df_merged.groupby(['ë‚ ì§œ', 'ID']).apply(
                        lambda x: x['ë§¤ì¶œ'].sum() / (x['ë¹„ìš©'].sum() + 1e-9) * 100
                        if 'ë§¤ì¶œ' in df_merged.columns
                        else x['ë¹„ìš©'].sum() / (x['ì„¤ì¹˜'].sum() + 1e-9)
                    ).reset_index(name=daily_col)
                    fig_daily = px.line(daily_roas_cpi, x='ë‚ ì§œ', y=daily_col, color='ID', markers=True)
                    if 'ë§¤ì¶œ' in df_merged.columns:
                        fig_daily.add_hline(y=target_roas, line_dash="dash", line_color="red",
                                             annotation_text=f"ëª©í‘œ {target_roas}%")
                    fig_daily.update_layout(height=380)
                    st.plotly_chart(fig_daily, use_container_width=True)

                # ìš”ì•½ í…Œì´ë¸”
                st.markdown("#### ğŸ“‹ ìˆ˜ìµì„± ìš”ì•½")
                perf_cols = ['ID', 'ë¹„ìš©', 'ì„¤ì¹˜', 'CPI', 'CPI_ë‹¬ì„±ë¥ (%)', 'ë§¤ì¶œ', 'ROAS(%)', 'ROAS_ë‹¬ì„±ë¥ (%)']
                avail_cols = [c for c in perf_cols if c in roas_cpi_agg.columns]
                fmt_roas = {c: '{:,.0f}' for c in ['ë¹„ìš©', 'ì„¤ì¹˜', 'CPI', 'ë§¤ì¶œ'] if c in roas_cpi_agg.columns}
                fmt_roas.update({c: '{:.1f}' for c in ['ROAS(%)', 'CPI_ë‹¬ì„±ë¥ (%)', 'ROAS_ë‹¬ì„±ë¥ (%)'] if c in roas_cpi_agg.columns})

                grad_col = 'ROAS(%)' if 'ROAS(%)' in roas_cpi_agg.columns else ('CPI_ë‹¬ì„±ë¥ (%)' if 'CPI_ë‹¬ì„±ë¥ (%)' in roas_cpi_agg.columns else None)
                styled = roas_cpi_agg[avail_cols].style.format(fmt_roas)
                if grad_col:
                    styled = styled.background_gradient(subset=[grad_col], cmap='RdYlGn')
                st.dataframe(styled, use_container_width=True)

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # TAB 7 : ìœ ì € í’ˆì§ˆ
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            with tabs[7]:
                st.markdown("### ğŸ‘¤ ìœ ì € í’ˆì§ˆ ë¶„ì„")
                st.markdown("ì†Œì¬ë³„ë¡œ íšë“í•œ ìœ ì €ì˜ ì§ˆ â€” ì”ì¡´ìœ¨, ì´ë²¤íŠ¸ ì „í™˜ìœ¨, LTVë¥¼ ë¹„êµí•©ë‹ˆë‹¤.")
                st.markdown("---")

                quality_agg = df_merged.groupby('ID').agg(
                    ì„¤ì¹˜=('ì„¤ì¹˜', 'sum') if 'ì„¤ì¹˜' in df_merged.columns else ('í´ë¦­', 'count'),
                    ì´ë²¤íŠ¸ìˆ˜=('ì´ë²¤íŠ¸ìˆ˜', 'sum') if 'ì´ë²¤íŠ¸ìˆ˜' in df_merged.columns else ('í´ë¦­', 'count'),
                    ë§¤ì¶œ=('ë§¤ì¶œ', 'sum') if 'ë§¤ì¶œ' in df_merged.columns else ('ë¹„ìš©', 'count'),
                    ë¹„ìš©=('ë¹„ìš©', 'sum'),
                ).reset_index()

                if 'ì„¤ì¹˜' in df_merged.columns and 'ì´ë²¤íŠ¸ìˆ˜' in df_merged.columns:
                    quality_agg['Event_Rate(%)'] = quality_agg['ì´ë²¤íŠ¸ìˆ˜'] / (quality_agg['ì„¤ì¹˜'] + 1e-9) * 100
                if 'ì„¤ì¹˜' in df_merged.columns and 'ë§¤ì¶œ' in df_merged.columns:
                    quality_agg['LTV_per_Install'] = quality_agg['ë§¤ì¶œ'] / (quality_agg['ì„¤ì¹˜'] + 1e-9)

                has_retention = any(c in df_merged.columns for c in ['D1ì”ì¡´ìœ¨', 'D7ì”ì¡´ìœ¨'])

                # ì”ì¡´ìœ¨ íˆíŠ¸ë§µ
                if has_retention:
                    st.markdown("#### ğŸ“Š D1/D7 ì”ì¡´ìœ¨ ë¹„êµ")
                    ret_cols = [c for c in ['D1ì”ì¡´ìœ¨', 'D7ì”ì¡´ìœ¨'] if c in df_merged.columns]
                    ret_agg  = df_merged.groupby('ID')[ret_cols].mean().reset_index()

                    fig_ret = go.Figure()
                    for col in ret_cols:
                        fig_ret.add_trace(go.Bar(name=col, x=ret_agg['ID'], y=ret_agg[col]))
                    fig_ret.update_layout(barmode='group', yaxis_title='ì”ì¡´ìœ¨ (%)', height=380)
                    st.plotly_chart(fig_ret, use_container_width=True)

                # ì´ë²¤íŠ¸ ì „í™˜ìœ¨
                if 'Event_Rate(%)' in quality_agg.columns:
                    st.markdown("#### ğŸ“Š ì„¤ì¹˜ í›„ í•µì‹¬ ì´ë²¤íŠ¸ ì „í™˜ìœ¨")
                    fig_evt = px.bar(
                        quality_agg.sort_values('Event_Rate(%)', ascending=True),
                        x='Event_Rate(%)', y='ID', orientation='h',
                        color='Event_Rate(%)', color_continuous_scale='Blues',
                        text=quality_agg.sort_values('Event_Rate(%)', ascending=True)['Event_Rate(%)'].apply(lambda x: f"{x:.1f}%")
                    )
                    fig_evt.update_traces(textposition='outside')
                    fig_evt.update_layout(height=350, coloraxis_showscale=False)
                    st.plotly_chart(fig_evt, use_container_width=True)

                # LTV per Install
                if 'LTV_per_Install' in quality_agg.columns:
                    st.markdown("#### ğŸ’ ì„¤ì¹˜ë‹¹ ë§¤ì¶œ (LTV Proxy)")
                    fig_ltv = px.bar(
                        quality_agg.sort_values('LTV_per_Install', ascending=True),
                        x='LTV_per_Install', y='ID', orientation='h',
                        color='LTV_per_Install', color_continuous_scale='Greens',
                        text=quality_agg.sort_values('LTV_per_Install', ascending=True)['LTV_per_Install'].apply(lambda x: f"{x:,.0f}ì›")
                    )
                    fig_ltv.update_traces(textposition='outside')
                    fig_ltv.update_layout(height=350, coloraxis_showscale=False)
                    st.plotly_chart(fig_ltv, use_container_width=True)

                # ìœ ì € í’ˆì§ˆ ì¢…í•© í…Œì´ë¸”
                st.markdown("#### ğŸ“‹ ìœ ì € í’ˆì§ˆ ì¢…í•©")
                q_cols = ['ID', 'ì„¤ì¹˜', 'ì´ë²¤íŠ¸ìˆ˜', 'ë§¤ì¶œ', 'Event_Rate(%)', 'LTV_per_Install']
                if has_retention:
                    ret_table = df_merged.groupby('ID')[[c for c in ['D1ì”ì¡´ìœ¨', 'D7ì”ì¡´ìœ¨'] if c in df_merged.columns]].mean().reset_index()
                    quality_agg = quality_agg.merge(ret_table, on='ID', how='left')
                    q_cols += [c for c in ['D1ì”ì¡´ìœ¨', 'D7ì”ì¡´ìœ¨'] if c in df_merged.columns]

                avail_q = [c for c in q_cols if c in quality_agg.columns]
                fmt_q = {c: '{:,.0f}' for c in ['ì„¤ì¹˜', 'ì´ë²¤íŠ¸ìˆ˜', 'ë§¤ì¶œ', 'LTV_per_Install'] if c in quality_agg.columns}
                fmt_q.update({c: '{:.1f}' for c in ['Event_Rate(%)', 'D1ì”ì¡´ìœ¨', 'D7ì”ì¡´ìœ¨'] if c in quality_agg.columns})
                st.dataframe(quality_agg[avail_q].style.format(fmt_q), use_container_width=True)

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # TAB 8 : ì˜ˆì‚° ì‹œë®¬ë ˆì´í„°
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            with tabs[8]:
                st.markdown("### ğŸ§® ì˜ˆì‚° ì‹œë®¬ë ˆì´í„°")
                st.markdown("ëª©í‘œ CPI/ROASë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì†Œì¬ë³„ ìµœì  ì˜ˆì‚° ë°°ë¶„ì„ ì¶”ì²œí•©ë‹ˆë‹¤.")
                st.markdown("---")

                sim_agg = df_merged.groupby('ID').agg(
                    ë¹„ìš©=('ë¹„ìš©', 'sum'),
                    ì„¤ì¹˜=('ì„¤ì¹˜', 'sum') if 'ì„¤ì¹˜' in df_merged.columns else ('í´ë¦­', 'count'),
                    ë§¤ì¶œ=('ë§¤ì¶œ', 'sum') if 'ë§¤ì¶œ' in df_merged.columns else ('ë¹„ìš©', 'count'),
                    í´ë¦­=('í´ë¦­', 'sum'),
                    ë…¸ì¶œ=('ë…¸ì¶œ', 'sum'),
                ).reset_index()

                sim_agg['CPI']     = sim_agg['ë¹„ìš©'] / (sim_agg['ì„¤ì¹˜'] + 1e-9)
                sim_agg['ROAS(%)'] = sim_agg['ë§¤ì¶œ'] / (sim_agg['ë¹„ìš©'] + 1e-9) * 100 if 'ë§¤ì¶œ' in df_merged.columns else 0.0
                sim_agg['CTR(%)']  = sim_agg['í´ë¦­'] / (sim_agg['ë…¸ì¶œ'] + 1e-9) * 100

                # ëª©í‘œ ì„¤ì •
                st.markdown("#### âš™ï¸ ì‹œë®¬ë ˆì´ì…˜ íŒŒë¼ë¯¸í„°")
                s1, s2, s3 = st.columns(3)
                total_budget  = s1.number_input("ì´ ì˜ˆì‚° (ì›)", min_value=100000, value=int(df_merged['ë¹„ìš©'].sum()), step=100000)
                sim_target_cpi  = s2.number_input("ëª©í‘œ CPI (ì›) [ì‹œë®¬]", min_value=0, value=target_cpi, step=500)
                sim_target_roas = s3.number_input("ëª©í‘œ ROAS (%) [ì‹œë®¬]", min_value=0, value=target_roas, step=50)

                st.markdown("#### ğŸ… ì¶”ì²œ ë°°ë¶„ ë°©ì‹ ì„ íƒ")
                alloc_mode = st.radio(
                    "ë°°ë¶„ ê¸°ì¤€",
                    ["CPI ì„±ê³¼ ë¹„ë¡€", "ROAS ì„±ê³¼ ë¹„ë¡€", "ë³µí•© ìŠ¤ì½”ì–´ ë¹„ë¡€"],
                    horizontal=True
                )

                # ìŠ¤ì½”ì–´ ì‚°ì¶œ
                if alloc_mode == "CPI ì„±ê³¼ ë¹„ë¡€":
                    inv_cpi = 1 / (sim_agg['CPI'] + 1e-9)
                    sim_agg['alloc_score'] = inv_cpi / inv_cpi.sum()
                elif alloc_mode == "ROAS ì„±ê³¼ ë¹„ë¡€":
                    roas_pos = np.clip(sim_agg['ROAS(%)'], 0, None)
                    sim_agg['alloc_score'] = (roas_pos + 1e-9) / (roas_pos.sum() + 1e-9)
                else:
                    sim_agg['alloc_score'] = res_agg.set_index('ID')['composite_score'].reindex(sim_agg['ID']).fillna(1/len(sim_agg)).values
                    sim_agg['alloc_score'] = sim_agg['alloc_score'] / (sim_agg['alloc_score'].sum() + 1e-9)

                sim_agg['ì¶”ì²œ_ì˜ˆì‚°'] = sim_agg['alloc_score'] * total_budget

                # ëª©í‘œ ë‹¬ì„± ì˜ˆì¸¡
                sim_agg['ì˜ˆìƒ_ì„¤ì¹˜'] = sim_agg['ì¶”ì²œ_ì˜ˆì‚°'] / (sim_agg['CPI'] + 1e-9)
                sim_agg['ì˜ˆìƒ_ë§¤ì¶œ'] = sim_agg['ì¶”ì²œ_ì˜ˆì‚°'] * sim_agg['ROAS(%)'] / 100 if 'ë§¤ì¶œ' in df_merged.columns else 0

                # ì‹œê°í™”
                st.markdown("#### ğŸ’° ì¶”ì²œ ì˜ˆì‚° ë°°ë¶„")
                fig_alloc = px.pie(
                    sim_agg, values='ì¶”ì²œ_ì˜ˆì‚°', names='ID',
                    hole=0.4,
                    color_discrete_sequence=px.colors.qualitative.Set2
                )
                fig_alloc.update_traces(textinfo='label+percent')
                fig_alloc.update_layout(height=400)
                st.plotly_chart(fig_alloc, use_container_width=True)

                # í˜„ì¬ vs ì¶”ì²œ ë¹„êµ
                st.markdown("#### ğŸ“Š í˜„ì¬ vs ì¶”ì²œ ì˜ˆì‚° ë¹„êµ")
                fig_compare = go.Figure()
                fig_compare.add_trace(go.Bar(name='í˜„ì¬ ì˜ˆì‚°', x=sim_agg['ID'], y=sim_agg['ë¹„ìš©']))
                fig_compare.add_trace(go.Bar(name='ì¶”ì²œ ì˜ˆì‚°', x=sim_agg['ID'], y=sim_agg['ì¶”ì²œ_ì˜ˆì‚°']))
                fig_compare.update_layout(barmode='group', yaxis_title='ì˜ˆì‚° (ì›)', height=380)
                st.plotly_chart(fig_compare, use_container_width=True)

                # ì˜ˆìƒ ì„±ê³¼
                st.markdown("#### ğŸ¯ ë°°ë¶„ ì‹œ ì˜ˆìƒ ì„±ê³¼")
                pred_inst  = sim_agg['ì˜ˆìƒ_ì„¤ì¹˜'].sum()
                pred_rev   = sim_agg['ì˜ˆìƒ_ë§¤ì¶œ'].sum()
                pred_cpi   = total_budget / (pred_inst + 1e-9)
                pred_roas  = pred_rev / (total_budget + 1e-9) * 100

                p1, p2, p3, p4 = st.columns(4)
                p1.metric("ì˜ˆìƒ ì´ ì„¤ì¹˜",   f"{pred_inst:,.0f}ê°œ")
                p2.metric("ì˜ˆìƒ í‰ê·  CPI",  f"{pred_cpi:,.0f}ì›",
                           delta=f"ëª©í‘œ {sim_target_cpi:,}ì›",
                           delta_color="normal" if pred_cpi <= sim_target_cpi else "inverse")
                if 'ë§¤ì¶œ' in df_merged.columns:
                    p3.metric("ì˜ˆìƒ ì´ ë§¤ì¶œ",   f"{pred_rev:,.0f}ì›")
                    p4.metric("ì˜ˆìƒ ROAS",      f"{pred_roas:.0f}%",
                               delta=f"ëª©í‘œ {sim_target_roas}%",
                               delta_color="normal" if pred_roas >= sim_target_roas else "inverse")

                # ìƒì„¸ í…Œì´ë¸”
                st.markdown("#### ğŸ“‹ ì†Œì¬ë³„ ì˜ˆì‚° ë°°ë¶„ ìƒì„¸")
                sim_display = sim_agg[['ID', 'ë¹„ìš©', 'ì¶”ì²œ_ì˜ˆì‚°', 'alloc_score', 'CPI', 'ROAS(%)', 'ì˜ˆìƒ_ì„¤ì¹˜', 'ì˜ˆìƒ_ë§¤ì¶œ']].copy()
                sim_display.columns = ['ì†Œì¬', 'í˜„ì¬ì˜ˆì‚°', 'ì¶”ì²œì˜ˆì‚°', 'ë°°ë¶„ë¹„ì¤‘', 'CPI', 'ROAS(%)', 'ì˜ˆìƒì„¤ì¹˜', 'ì˜ˆìƒë§¤ì¶œ']
                fmt_sim = {'í˜„ì¬ì˜ˆì‚°': '{:,.0f}', 'ì¶”ì²œì˜ˆì‚°': '{:,.0f}', 'ë°°ë¶„ë¹„ì¤‘': '{:.1%}',
                            'CPI': '{:,.0f}', 'ROAS(%)': '{:.1f}', 'ì˜ˆìƒì„¤ì¹˜': '{:,.0f}', 'ì˜ˆìƒë§¤ì¶œ': '{:,.0f}'}
                st.dataframe(
                    sim_display.style.format(fmt_sim).background_gradient(subset=['ë°°ë¶„ë¹„ì¤‘'], cmap='Blues'),
                    use_container_width=True
                )

                st.caption("âš ï¸ ì˜ˆìƒ ì„±ê³¼ëŠ” ê³¼ê±° ì„±ê³¼ ê¸°ë°˜ ì„ í˜• ì¶”ì •ì¹˜ì´ë©°, ì‹¤ì œ ê²°ê³¼ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ë°ì´í„° í•œê³„ ì•ˆë‚´
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.markdown("---")
        with st.expander("ğŸ” í˜„ì¬ ë°ì´í„°ë¡œ ë‹µí•  ìˆ˜ ì—†ëŠ” ì§ˆë¬¸", expanded=False):
            st.markdown("""
            ### âŒ í˜„ì¬ ë°ì´í„°ì˜ í•œê³„

            **1. ì¸ê³¼ ê´€ê³„ ì¶”ì • ë¶ˆê°€**
            - "ì˜ˆì‚° 2ë°° ì¦ì•¡ ì‹œ ì„¤ì¹˜ ëª‡ ê°œ ì¦ê°€?"ëŠ” ì„ í˜• ê°€ì • ê¸°ë°˜ ì¶”ì •ë§Œ ê°€ëŠ¥
            - í•„ìš”: ê³¼ê±° ì˜ˆì‚° ë³€ê²½ ì‹¤í—˜ ë°ì´í„° (A/B í…ŒìŠ¤íŠ¸)

            **2. ì¥ê¸° LTV ì˜ˆì¸¡ ë¶ˆê°€**
            - í˜„ì¬ ë§¤ì¶œ = ë‹¨ê¸° ìˆ˜ìµ, ì§„ì§œ LTVëŠ” 6~12ê°œì›” ì½”í˜¸íŠ¸ í•„ìš”
            - ì§€ê¸ˆì€ "ì„¤ì¹˜ë‹¹ ë‹¨ê¸° ë§¤ì¶œ"ë§Œ ì¸¡ì • ê°€ëŠ¥

            **3. ì™¸ë¶€ ìš”ì¸ ë¯¸ë°˜ì˜**
            - ì‹œì¦Œì„±, ê²½ìŸì‚¬ ì…ì°°, í”Œë«í¼ ì•Œê³ ë¦¬ì¦˜ ë³€í™” ë¯¸í†µì œ
            - CUSUM ì´ìƒ ê°ì§€ ì‹œ ì™¸ë¶€ ìš”ì¸ ë³„ë„ í™•ì¸ í•„ìš”

            **4. ì–´íŠ¸ë¦¬ë·°ì…˜ ìœˆë„ìš°**
            - ì„¤ì¹˜~ì´ë²¤íŠ¸ ì‚¬ì´ ì‹œê°„ ì°¨ë¡œ ë‹¨ê¸° ì§€í‘œ ê³¼ì†Œ ì¸¡ì • ê°€ëŠ¥

            ### âœ… ì´ ì‹œìŠ¤í…œìœ¼ë¡œ ë‹µí•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸

            - ì§€ê¸ˆ ë‹¹ì¥ ì–´ë–¤ ì†Œì¬ì— ì˜ˆì‚°ì„ ë” ì¨ì•¼ í•˜ë‚˜?
            - ì–´ë–¤ ì†Œì¬ê°€ ëª©í‘œ CPI/ROASë¥¼ ì´ˆê³¼/ë¯¸ë‹¬ ì¤‘ì¸ê°€?
            - ì–´ë–¤ ì†Œì¬ì˜ ìœ ì € í’ˆì§ˆì´ ê°€ì¥ ì¢‹ì€ê°€?
            - ì„±ê³¼ í•˜ë½ì´ ì‹œì‘ëœ ì†Œì¬ëŠ” ì–´ë””ì¸ê°€?
            """)
    else:
        st.warning("ê´‘ê³  ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

else:
    st.markdown("### ğŸ“‹ ì‹œìŠ¤í…œ ì†Œê°œ")
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("""
        #### âœ¨ í•µì‹¬ ê¸°ëŠ¥ (v2)

        **ê´‘ê³  ë°ì´í„°ë§Œ ìˆì„ ë•Œ**
        - Bayesian CTR ë¶„ì„ (Prior ìë™/ìˆ˜ë™)
        - ì†Œì¬ í”¼ë¡œë„ ì¡°ê¸° ê²½ê³  (ì„ í˜• íšŒê·€)
        - CUSUM ì´ìƒ ê°ì§€
        - ì£¼ê°„ ì˜ì‚¬ê²°ì • ì²´í¬ë¦¬ìŠ¤íŠ¸

        **MMP ë°ì´í„° ì¶”ê°€ ì‹œ í™œì„±í™”**
        - ğŸ”½ í¼ë„ ë¶„ì„ (ë…¸ì¶œ â†’ í´ë¦­ â†’ ì„¤ì¹˜ â†’ ì´ë²¤íŠ¸)
        - ğŸ’° ROAS/CPI ì†Œì¬ë³„ ë¹„êµ + ëª©í‘œ ëŒ€ë¹„ ë‹¬ì„±ë¥ 
        - ğŸ‘¤ ìœ ì € í’ˆì§ˆ (D1/D7 ì”ì¡´ìœ¨, Event Rate, LTV)
        - ğŸ§® ì˜ˆì‚° ì‹œë®¬ë ˆì´í„° (ìµœì  ë°°ë¶„ ì¶”ì²œ)
        """)
    with c2:
        st.markdown("""
        #### ğŸ“‚ ë°ì´í„° íŒŒì¼ í˜•ì‹

        **ê´‘ê³  ë°ì´í„° í•„ìˆ˜ ì»¬ëŸ¼**
        ```
        ë‚ ì§œ, ë§¤ì²´, ìƒí’ˆ, ì†Œì¬, ë…¸ì¶œ, í´ë¦­, ë¹„ìš©
        ```

        **MMP ë°ì´í„° ì„ íƒ ì»¬ëŸ¼**
        ```
        ë‚ ì§œ, ë§¤ì²´, ì†Œì¬ (ì¡°ì¸ í‚¤)
        ì„¤ì¹˜ìˆ˜, ì´ë²¤íŠ¸ìˆ˜, ë§¤ì¶œ     (ìˆ˜ìµì„±)
        D1ì”ì¡´ìœ¨, D7ì”ì¡´ìœ¨         (ìœ ì € í’ˆì§ˆ)
        ```

        **ì§€ì› MMP:** Appsflyer Â· Adjust Â· Singular Â· ì»¤ìŠ¤í…€ CSV
        """)

    st.markdown("---")
    st.caption("ğŸ’¡ Tip: ì‚¬ì´ë“œë°”ì—ì„œ ëª©í‘œ CPI/ROASì™€ ë³µí•© ìŠ¤ì½”ì–´ ê°€ì¤‘ì¹˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”")