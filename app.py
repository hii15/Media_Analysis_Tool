import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from prophet import Prophet
from scipy.optimize import minimize
from datetime import datetime, timedelta  # timedelta ì¶”ê°€
import logging

# 1. ì„¤ì • ë° ë¡œê·¸ ì œì–´
logging.getLogger('prophet').setLevel(logging.WARNING)
st.set_page_config(page_title="Marketing Analytics & Optimizer", layout="wide")

# --- [ì—”ì§„ 1: ë°ì´í„° ì²˜ë¦¬ ë° ë² ì´ì§€ì•ˆ ë³´ì •] ---
def clean_and_process_pro(df):
    mapping = {
        'ë‚ ì§œ': ['ë‚ ì§œ', 'ì¼ì', 'Date'],
        'ë§¤ì²´': ['ë§¤ì²´', 'ì±„ë„', 'Media'],
        'ìƒí’ˆëª…': ['ìƒí’ˆëª…', 'ìƒí’ˆ', 'Product'],
        'ì†Œì¬ëª…': ['ì†Œì¬ëª…', 'ì†Œì¬', 'Creative'],
        'ë…¸ì¶œìˆ˜': ['ë…¸ì¶œìˆ˜', 'ë…¸ì¶œ', 'Impression'],
        'í´ë¦­ìˆ˜': ['í´ë¦­ìˆ˜', 'í´ë¦­', 'Click'],
        'ë¹„ìš©': ['ë¹„ìš©', 'ì§€ì¶œ', 'Cost']
    }
    final_df = pd.DataFrame()
    for std_key, patterns in mapping.items():
        found = [c for c in df.columns if str(c).strip() in patterns]
        if found: final_df[std_key] = df[found[0]]
        else:
            found_sub = [c for c in df.columns if any(p in str(c) for p in patterns)]
            if found_sub: final_df[std_key] = df[found_sub[0]]
    
    if len(final_df.columns) < len(mapping): return pd.DataFrame()

    final_df['ë‚ ì§œ'] = pd.to_datetime(final_df['ë‚ ì§œ'], errors='coerce')
    for col in ['ë…¸ì¶œìˆ˜', 'í´ë¦­ìˆ˜', 'ë¹„ìš©']:
        final_df[col] = pd.to_numeric(final_df[col].astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce').fillna(0)
    
    # ê¸°ë³¸ ì§€í‘œ ê³„ì‚°
    final_df['CTR(%)'] = np.where(final_df['ë…¸ì¶œìˆ˜'] > 0, (final_df['í´ë¦­ìˆ˜'] / final_df['ë…¸ì¶œìˆ˜'] * 100), 0.0)
    
    # ë² ì´ì§€ì•ˆ ë³´ì • CTR
    global_mean = final_df['í´ë¦­ìˆ˜'].sum() / (final_df['ë…¸ì¶œìˆ˜'].sum() + 1e-6)
    K = 100 
    final_df['Adj_CTR'] = (final_df['í´ë¦­ìˆ˜'] + K * global_mean) / (final_df['ë…¸ì¶œìˆ˜'] + K) * 100
    final_df['ID'] = "[" + final_df['ìƒí’ˆëª…'].astype(str) + "] " + final_df['ì†Œì¬ëª…'].astype(str)
    
    return final_df.dropna(subset=['ë‚ ì§œ'])

# --- [ì—”ì§„ 2: ì˜ˆì¸¡ ë° ìµœì í™” ë¡œì§] ---
def get_forecast_and_slope(data):
    valid_df = data[data['ë…¸ì¶œìˆ˜'] >= 10].sort_values('ë‚ ì§œ').copy()
    if len(valid_df) < 7: return None, 0
    
    try:
        # Logit ë³€í™˜ ì˜ˆì¸¡
        p = np.clip(valid_df['Adj_CTR'].values / 100, 0.0001, 0.9999)
        valid_df['y_logit'] = np.log(p / (1 - p))
        m = Prophet(interval_width=0.8, daily_seasonality=False, weekly_seasonality=True)
        m.fit(valid_df[['ë‚ ì§œ', 'y_logit']].rename(columns={'ë‚ ì§œ': 'ds', 'y_logit': 'y'}))
        
        future = m.make_future_dataframe(periods=7)
        forecast = m.predict(future)
        slope = (forecast['yhat'].values[-1] - forecast['yhat'].values[-7]) / 7
        
        def inv_logit(x): return (np.exp(x) / (1 + np.exp(x))) * 100
        res = pd.DataFrame({'ds': forecast['ds'], 'yhat': inv_logit(forecast['yhat']), 
                            'yhat_lower': inv_logit(forecast['yhat_lower']), 'yhat_upper': inv_logit(forecast['yhat_upper'])})
        return res, slope
    except: return None, 0

def hill_model(budget, current_spend, avg_cpc, slope):
    if budget <= 0 or avg_cpc <= 0: return 0
    base_clicks = budget / avg_cpc
    penalty = 1.0 + abs(min(0, slope)) * 3.0
    efficiency = 1.0 / (1.0 + (0.15 * penalty * (max(0, budget/(current_spend+1e-6) - 1.0))**1.2))
    return base_clicks * efficiency

# --- [UI ë©”ì¸] ---
st.title("ğŸ”¬ ë§ˆì¼€íŒ… ì‚¬ì´ì–¸ìŠ¤ í†µí•© ì˜ì‚¬ê²°ì • ì‹œìŠ¤í…œ")

# 1. ì´ˆê¸°í™” (NameError ë°©ì§€ í•µì‹¬)
full_df = pd.DataFrame() 

uploaded_file = st.file_uploader("ë°ì´í„° ì—…ë¡œë“œ", type=['csv', 'xlsx'])

if uploaded_file:
    if uploaded_file.name.endswith('xlsx'): df_raw = pd.read_excel(uploaded_file)
    else: df_raw = pd.read_csv(uploaded_file)
    full_df = clean_and_process_pro(df_raw)

# 2. ë°ì´í„° ìœ ë¬´ ì²´í¬ ë¡œì§ ìˆ˜ì •
if not full_df.empty:
    ids = sorted(full_df['ID'].unique())
    forecast_cache = {}
    for i in ids:
        f_res, f_slope = get_forecast_and_slope(full_df[full_df['ID'] == i])
        forecast_cache[i] = {'res': f_res, 'slope': f_slope}

    tabs = st.tabs(["ğŸ“Š ì„±ê³¼", "ğŸ“ˆ ìˆ˜ëª…", "ğŸ•¹ï¸ ì‹œë®¬ë ˆì´ì…˜", "ğŸ¯ ìµœì í™”"])

    with tabs[0]: # ì„±ê³¼
        st.header("ğŸ“Š ì „ì£¼ ëŒ€ë¹„ ì„±ê³¼(WoW)")
        max_date = full_df['ë‚ ì§œ'].max()
        this_week = full_df[full_df['ë‚ ì§œ'] > max_date - timedelta(days=7)]
        last_week = full_df[(full_df['ë‚ ì§œ'] <= max_date - timedelta(days=7)) & (full_df['ë‚ ì§œ'] > max_date - timedelta(days=14))]
        
        c1, c2 = st.columns(2)
        c1.metric("ì´ë²ˆ ì£¼ ì§€ì¶œ", f"{this_week['ë¹„ìš©'].sum():,.0f}ì›")
        st.plotly_chart(px.bar(full_df.groupby('ID')['Adj_CTR'].mean().reset_index(), x='ID', y='Adj_CTR', title="ë³´ì •ëœ ì†Œì¬ë³„ í‰ê·  ì„±ê³¼"), use_container_width=True)

    with tabs[1]: # ìˆ˜ëª… (KeyError ë°©ì§€ ìˆ˜ì • ì™„ë£Œ)
        st.header("ğŸ“ˆ í™•ë¥ ì  ìˆ˜ëª… ë¶„ì„")
        sel_id = st.selectbox("ì†Œì¬ ì„ íƒ", ids)
        target_df = full_df[full_df['ID'] == sel_id]
        f_data = forecast_cache[sel_id]['res']
        
        if f_data is not None:
            fig = go.Figure()
            # KeyError ë°œìƒ ì§€ì  ìˆ˜ì •: 'CTR(%)' ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
            fig.add_trace(go.Scatter(x=target_df['ë‚ ì§œ'], y=target_df['CTR(%)'], name="ì›ì‹œ ì‹¤ì ", mode='markers'))
            fig.add_trace(go.Scatter(x=f_data['ds'], y=f_data['yhat'], name="ì¶”ì„¸ì„ ", line=dict(color='red', dash='dash')))
            fig.add_trace(go.Scatter(x=f_data['ds'], y=f_data['yhat_upper'], line=dict(width=0), showlegend=False))
            fig.add_trace(go.Scatter(x=f_data['ds'], y=f_data['yhat_lower'], fill='tonexty', fillcolor='rgba(255,0,0,0.1)', line=dict(width=0), name="ì˜ˆì¸¡ ë²”ìœ„"))
            st.plotly_chart(fig, use_container_width=True)

    with tabs[2]: # ì‹œë®¬ë ˆì´ì…˜
        st.header("ğŸ•¹ï¸ What-If ì‹œë®¬ë ˆì´í„°")
        sim_id = st.selectbox("ì‹œë®¬ë ˆì´ì…˜ ëŒ€ìƒ", ids, key="sim")
        t_data = full_df[full_df['ID'] == sim_id]
        c_spend = t_data['ë¹„ìš©'].sum()
        c_cpc = c_spend / (t_data['í´ë¦­ìˆ˜'].sum() + 1e-6)
        
        n_spend = st.slider("ì˜ˆì‚° ë³€ê²½ (ì›)", 0.0, c_spend * 3.0, float(c_spend))
        p_clicks = hill_model(n_spend, c_spend, c_cpc, forecast_cache[sim_id]['slope'])
        st.metric("ì˜ˆìƒ í´ë¦­ìˆ˜", f"{p_clicks:,.0f}", f"{p_clicks - t_data['í´ë¦­ìˆ˜'].sum():,.0f}")

    with tabs[3]: # ìµœì í™”
        st.header("ğŸ¯ ì˜ˆì‚° ìµœì í™” ì œì•ˆ")
        if st.button("ğŸš€ ìµœì  ë°°ë¶„ ê³„ì‚°"):
            total_b = full_df['ë¹„ìš©'].sum()
            summary = full_df.groupby('ID').agg({'ë¹„ìš©':'sum', 'í´ë¦­ìˆ˜':'sum'}).reset_index()
            def objective(b_list):
                total_clicks = 0
                for idx, b in enumerate(b_list):
                    target_id = ids[idx]
                    cur_s = summary[summary['ID']==target_id]['ë¹„ìš©'].iloc[0]
                    cur_cpc = cur_s / (summary[summary['ID']==target_id]['í´ë¦­ìˆ˜'].iloc[0] + 1e-6)
                    total_clicks += hill_model(b, cur_s, cur_cpc, forecast_cache[target_id]['slope'])
                return -total_clicks
            
            res = minimize(objective, [total_b/len(ids)]*len(ids), method='SLSQP', 
                           bounds=[(0, s*3) for s in summary['ë¹„ìš©']], constraints={'type':'eq', 'fun': lambda b: sum(b)-total_b})
            
            res_df = pd.DataFrame({'ID': ids, 'í˜„ì¬ ì˜ˆì‚°': summary['ë¹„ìš©'], 'ìµœì í™” ì œì•ˆ': res.x})
            st.dataframe(res_df.style.format({'í˜„ì¬ ì˜ˆì‚°':'{:,.0f}', 'ìµœì í™” ì œì•ˆ':'{:,.0f}'}))
else:
    st.info("ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")